{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "biblical-extreme",
   "metadata": {},
   "source": [
    "# \"Stable baselines 3 - 1st steps\"\n",
    "> \"installation, 1st experimentations\"\n",
    "- show_tags: true\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [reinforcement learning, pytorch, sb3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-wayne",
   "metadata": {},
   "source": [
    "# What is stable baselines 3 (sb3)\n",
    "\n",
    "I have just read about this new release. This is a complete rewrite of stable baselines 2, without any reference to tensorflow, and based on pytorch (>1.4+).\n",
    "\n",
    "There is a lot of running implementations of RL algorithms, based on gym.\n",
    "A very good introduction in this [blog entry](https://araffin.github.io/post/sb3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-paraguay",
   "metadata": {},
   "source": [
    "[Stable-Baselines3: Reliable Reinforcement Learning Implementations | Antonin Raffin | Homepage](https://araffin.github.io/post/sb3/)\n",
    "\n",
    "> ## Links\n",
    "> \n",
    "> GitHub repository: [https://github.com/DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3)\n",
    "\n",
    "> Documentation: [https://stable-baselines3.readthedocs.io/](https://stable-baselines3.readthedocs.io/)\n",
    "\n",
    "> RL Baselines3 Zoo: [https://github.com/DLR-RM/rl-baselines3-zoo](https://github.com/DLR-RM/rl-baselines3-zoo)\n",
    "\n",
    "> Contrib: [https://github.com/Stable-Baselines-Team/stable-baselines3-contrib](https://github.com/Stable-Baselines-Team/stable-baselines3-contrib)\n",
    "\n",
    "> RL Tutorial: [https://github.com/araffin/rl-tutorial-jnrr19](https://github.com/araffin/rl-tutorial-jnrr19)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-ballot",
   "metadata": {},
   "source": [
    "# My installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-input",
   "metadata": {},
   "source": [
    "Standard installation\n",
    "```bash\n",
    "conda create --name stablebaselines3 python=3.7\n",
    "conda activate stablebaselines3\n",
    "pip install stable-baselines3[extra]\n",
    "conda install -c conda-forge jupyter_contrib_nbextensions\n",
    "conda install nb_conda\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atlantic-situation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T10:38:38.693215Z",
     "start_time": "2021-03-24T10:38:37.827031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/explore/miniconda3/envs/stablebaselines3:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_libgcc_mutex             0.1                        main  \r\n",
      "absl-py                   0.12.0                   pypi_0    pypi\r\n",
      "atari-py                  0.2.6                    pypi_0    pypi\r\n",
      "attrs                     20.3.0             pyhd3deb0d_0    conda-forge\r\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\r\n",
      "backports                 1.0                        py_2    conda-forge\r\n",
      "backports.functools_lru_cache 1.6.1                      py_0    conda-forge\r\n",
      "bleach                    3.3.0              pyh44b312d_0    conda-forge\r\n",
      "box2d                     2.3.10                   pypi_0    pypi\r\n",
      "box2d-py                  2.3.8                    pypi_0    pypi\r\n",
      "ca-certificates           2021.1.19            h06a4308_1  \r\n",
      "cachetools                4.2.1                    pypi_0    pypi\r\n",
      "certifi                   2020.12.5        py37h06a4308_0  \r\n",
      "chardet                   4.0.0                    pypi_0    pypi\r\n",
      "cloudpickle               1.6.0                    pypi_0    pypi\r\n",
      "cycler                    0.10.0                   pypi_0    pypi\r\n",
      "decorator                 4.4.2                      py_0    conda-forge\r\n",
      "defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\r\n",
      "entrypoints               0.3             pyhd8ed1ab_1003    conda-forge\r\n",
      "future                    0.18.2                   pypi_0    pypi\r\n",
      "google-auth               1.28.0                   pypi_0    pypi\r\n",
      "google-auth-oauthlib      0.4.3                    pypi_0    pypi\r\n",
      "grpcio                    1.36.1                   pypi_0    pypi\r\n",
      "gym                       0.18.0                   pypi_0    pypi\r\n",
      "icu                       58.2              hf484d3e_1000    conda-forge\r\n",
      "idna                      2.10                     pypi_0    pypi\r\n",
      "importlib-metadata        3.7.3            py37h89c1867_0    conda-forge\r\n",
      "ipykernel                 5.5.0            py37h888b3d9_1    conda-forge\r\n",
      "ipython                   7.21.0           py37h888b3d9_0    conda-forge\r\n",
      "ipython_genutils          0.2.0                      py_1    conda-forge\r\n",
      "jedi                      0.18.0           py37h89c1867_2    conda-forge\r\n",
      "jinja2                    2.11.3             pyh44b312d_0    conda-forge\r\n",
      "jsonschema                3.2.0              pyhd8ed1ab_3    conda-forge\r\n",
      "jupyter_client            6.1.12             pyhd8ed1ab_0    conda-forge\r\n",
      "jupyter_contrib_core      0.3.3                      py_2    conda-forge\r\n",
      "jupyter_contrib_nbextensions 0.5.1              pyhd8ed1ab_2    conda-forge\r\n",
      "jupyter_core              4.7.1            py37h89c1867_0    conda-forge\r\n",
      "jupyter_highlight_selected_word 0.2.0           py37h89c1867_1002    conda-forge\r\n",
      "jupyter_latex_envs        1.4.6           pyhd8ed1ab_1002    conda-forge\r\n",
      "jupyter_nbextensions_configurator 0.4.1            py37h89c1867_2    conda-forge\r\n",
      "kiwisolver                1.3.1                    pypi_0    pypi\r\n",
      "ld_impl_linux-64          2.33.1               h53a641e_7  \r\n",
      "libffi                    3.3                  he6710b0_2  \r\n",
      "libgcc-ng                 9.1.0                hdf63c60_0  \r\n",
      "libsodium                 1.0.18               h36c2ea0_1    conda-forge\r\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0  \r\n",
      "libxml2                   2.9.10               hb55368b_3  \r\n",
      "libxslt                   1.1.34               hc22bd24_0  \r\n",
      "lxml                      4.6.3            py37h9120a33_0  \r\n",
      "markdown                  3.3.4                    pypi_0    pypi\r\n",
      "markupsafe                1.1.1            py37hb5d75c8_2    conda-forge\r\n",
      "matplotlib                3.3.4                    pypi_0    pypi\r\n",
      "mistune                   0.8.4           py37h4abf009_1002    conda-forge\r\n",
      "nb_conda                  2.2.1                    py37_0  \r\n",
      "nb_conda_kernels          2.3.1            py37h06a4308_0  \r\n",
      "nbconvert                 5.6.1            py37hc8dfbb8_1    conda-forge\r\n",
      "nbformat                  5.1.2              pyhd8ed1ab_1    conda-forge\r\n",
      "ncurses                   6.2                  he6710b0_1  \r\n",
      "notebook                  5.7.10           py37hc8dfbb8_0    conda-forge\r\n",
      "numpy                     1.20.1                   pypi_0    pypi\r\n",
      "oauthlib                  3.1.0                    pypi_0    pypi\r\n",
      "opencv-python             4.5.1.48                 pypi_0    pypi\r\n",
      "openssl                   1.1.1j               h27cfd23_0  \r\n",
      "packaging                 20.9               pyh44b312d_0    conda-forge\r\n",
      "pandas                    1.2.3                    pypi_0    pypi\r\n",
      "pandoc                    2.12                 h7f98852_0    conda-forge\r\n",
      "pandocfilters             1.4.2                      py_1    conda-forge\r\n",
      "parso                     0.8.1              pyhd8ed1ab_0    conda-forge\r\n",
      "pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\r\n",
      "pickleshare               0.7.5                   py_1003    conda-forge\r\n",
      "pillow                    7.2.0                    pypi_0    pypi\r\n",
      "pip                       21.0.1           py37h06a4308_0  \r\n",
      "prometheus_client         0.9.0              pyhd3deb0d_0    conda-forge\r\n",
      "prompt-toolkit            3.0.18             pyha770c72_0    conda-forge\r\n",
      "protobuf                  3.15.6                   pypi_0    pypi\r\n",
      "psutil                    5.8.0                    pypi_0    pypi\r\n",
      "ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\r\n",
      "pyasn1                    0.4.8                    pypi_0    pypi\r\n",
      "pyasn1-modules            0.2.8                    pypi_0    pypi\r\n",
      "pyglet                    1.5.0                    pypi_0    pypi\r\n",
      "pygments                  2.8.1              pyhd8ed1ab_0    conda-forge\r\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\r\n",
      "pyrsistent                0.17.3           py37h4abf009_1    conda-forge\r\n",
      "python                    3.7.10               hdb3f193_0  \r\n",
      "python-dateutil           2.8.1                      py_0    conda-forge\r\n",
      "python_abi                3.7                     1_cp37m    conda-forge\r\n",
      "pytz                      2021.1                   pypi_0    pypi\r\n",
      "pyyaml                    5.3.1            py37hb5d75c8_1    conda-forge\r\n",
      "pyzmq                     19.0.2           py37hac76be4_2    conda-forge\r\n",
      "readline                  8.1                  h27cfd23_0  \r\n",
      "requests                  2.25.1                   pypi_0    pypi\r\n",
      "requests-oauthlib         1.3.0                    pypi_0    pypi\r\n",
      "rsa                       4.7.2                    pypi_0    pypi\r\n",
      "scipy                     1.6.1                    pypi_0    pypi\r\n",
      "send2trash                1.5.0                      py_0    conda-forge\r\n",
      "setuptools                52.0.0           py37h06a4308_0  \r\n",
      "six                       1.15.0             pyh9f0ad1d_0    conda-forge\r\n",
      "sqlite                    3.35.2               hdfb4753_0  \r\n",
      "stable-baselines3         1.0                      pypi_0    pypi\r\n",
      "tensorboard               2.4.1                    pypi_0    pypi\r\n",
      "tensorboard-plugin-wit    1.8.0                    pypi_0    pypi\r\n",
      "terminado                 0.9.3            py37h89c1867_0    conda-forge\r\n",
      "testpath                  0.4.4                      py_0    conda-forge\r\n",
      "tk                        8.6.10               hbc83047_0  \r\n",
      "torch                     1.8.0                    pypi_0    pypi\r\n",
      "tornado                   6.1              py37h4abf009_0    conda-forge\r\n",
      "traitlets                 5.0.5                      py_0    conda-forge\r\n",
      "typing_extensions         3.7.4.3                    py_0    conda-forge\r\n",
      "urllib3                   1.26.4                   pypi_0    pypi\r\n",
      "wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\r\n",
      "webencodings              0.5.1                      py_1    conda-forge\r\n",
      "werkzeug                  1.0.1                    pypi_0    pypi\r\n",
      "wheel                     0.36.2             pyhd3eb1b0_0  \r\n",
      "xz                        5.2.5                h7b6447c_0  \r\n",
      "yaml                      0.2.5                h516909a_0    conda-forge\r\n",
      "zeromq                    4.3.4                h2531618_0  \r\n",
      "zipp                      3.4.1              pyhd8ed1ab_0    conda-forge\r\n",
      "zlib                      1.2.11               h7b6447c_3  \r\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-salvation",
   "metadata": {},
   "source": [
    "# SB3 tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unable-lithuania",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T08:46:04.406020Z",
     "start_time": "2021-03-25T08:44:44.531596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'LunarLander-v2'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 97.6     |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 484      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | -0.0391  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -5.3     |\n",
      "|    value_loss         | 17.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | -249     |\n",
      "| time/                 |          |\n",
      "|    fps                | 499      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0.00593  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 2.79     |\n",
      "|    value_loss         | 16.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 108      |\n",
      "|    ep_rew_mean        | -277     |\n",
      "| time/                 |          |\n",
      "|    fps                | 502      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | -0.00474 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -2.79    |\n",
      "|    value_loss         | 9.45     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=-1534.45 +/- 783.96\n",
      "Episode length: 184.80 +/- 74.13\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 185       |\n",
      "|    mean_reward        | -1.53e+03 |\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 117       |\n",
      "|    ep_rew_mean        | -296      |\n",
      "| time/                 |           |\n",
      "|    fps                | 414       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.1      |\n",
      "|    explained_variance | 0.0118    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -1.07     |\n",
      "|    value_loss         | 5.93      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 131      |\n",
      "|    ep_rew_mean        | -299     |\n",
      "| time/                 |          |\n",
      "|    fps                | 426      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 0.00582  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 2.68     |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 133       |\n",
      "|    ep_rew_mean        | -309      |\n",
      "| time/                 |           |\n",
      "|    fps                | 428       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.902    |\n",
      "|    explained_variance | -1.94e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -5.9      |\n",
      "|    value_loss         | 38.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 133       |\n",
      "|    ep_rew_mean        | -286      |\n",
      "| time/                 |           |\n",
      "|    fps                | 437       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.13     |\n",
      "|    explained_variance | -0.000943 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 1.34      |\n",
      "|    value_loss         | 5.43      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-2461.14 +/- 815.61\n",
      "Episode length: 450.40 +/- 58.92\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 450       |\n",
      "|    mean_reward        | -2.46e+03 |\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 137       |\n",
      "|    ep_rew_mean        | -276      |\n",
      "| time/                 |           |\n",
      "|    fps                | 343       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.763    |\n",
      "|    explained_variance | -0.00105  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 1.13      |\n",
      "|    value_loss         | 24.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 140      |\n",
      "|    ep_rew_mean        | -274     |\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.87    |\n",
      "|    explained_variance | -0.00024 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 11.7     |\n",
      "|    value_loss         | 349      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 151       |\n",
      "|    ep_rew_mean        | -270      |\n",
      "| time/                 |           |\n",
      "|    fps                | 363       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.949    |\n",
      "|    explained_variance | -0.000288 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -3.85     |\n",
      "|    value_loss         | 6.77      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 152      |\n",
      "|    ep_rew_mean        | -262     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.836   |\n",
      "|    explained_variance | 0.000152 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -2.77    |\n",
      "|    value_loss         | 4.58     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=-1441.51 +/- 344.51\n",
      "Episode length: 470.00 +/- 216.72\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 470       |\n",
      "|    mean_reward        | -1.44e+03 |\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 154       |\n",
      "|    ep_rew_mean        | -246      |\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.655    |\n",
      "|    explained_variance | 4.6e-05   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -3.96     |\n",
      "|    value_loss         | 10        |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 158       |\n",
      "|    ep_rew_mean        | -242      |\n",
      "| time/                 |           |\n",
      "|    fps                | 323       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.799    |\n",
      "|    explained_variance | -0.000516 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -4.78     |\n",
      "|    value_loss         | 91.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 162       |\n",
      "|    ep_rew_mean        | -238      |\n",
      "| time/                 |           |\n",
      "|    fps                | 330       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.623    |\n",
      "|    explained_variance | -0.000611 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 8.3       |\n",
      "|    value_loss         | 88.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 171      |\n",
      "|    ep_rew_mean        | -227     |\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.956   |\n",
      "|    explained_variance | 1.63e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -3.67    |\n",
      "|    value_loss         | 41.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-684.75 +/- 100.33\n",
      "Episode length: 490.60 +/- 85.08\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 491      |\n",
      "|    mean_reward        | -685     |\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 174      |\n",
      "|    ep_rew_mean        | -223     |\n",
      "| time/                 |          |\n",
      "|    fps                | 302      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.144   |\n",
      "|    explained_variance | 0.00724  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.162   |\n",
      "|    value_loss         | 61.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 176      |\n",
      "|    ep_rew_mean        | -220     |\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.528   |\n",
      "|    explained_variance | 9.72e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 2        |\n",
      "|    value_loss         | 7.58     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 175       |\n",
      "|    ep_rew_mean        | -219      |\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.726    |\n",
      "|    explained_variance | -0.000773 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 9.47      |\n",
      "|    value_loss         | 243       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 179       |\n",
      "|    ep_rew_mean        | -218      |\n",
      "| time/                 |           |\n",
      "|    fps                | 320       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.609    |\n",
      "|    explained_variance | -0.000227 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 2.69      |\n",
      "|    value_loss         | 145       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-1105.99 +/- 697.41\n",
      "Episode length: 859.40 +/- 72.91\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 859       |\n",
      "|    mean_reward        | -1.11e+03 |\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 181       |\n",
      "|    ep_rew_mean        | -218      |\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.03     |\n",
      "|    explained_variance | -0.11     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -3.99     |\n",
      "|    value_loss         | 29.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 181      |\n",
      "|    ep_rew_mean        | -218     |\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.895   |\n",
      "|    explained_variance | 0.191    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.0962   |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 198       |\n",
      "|    ep_rew_mean        | -212      |\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.706    |\n",
      "|    explained_variance | -5.46e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 7.79      |\n",
      "|    value_loss         | 206       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -213      |\n",
      "| time/                 |           |\n",
      "|    fps                | 283       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.797    |\n",
      "|    explained_variance | -0.000233 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -5.37     |\n",
      "|    value_loss         | 22.2      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=-175.07 +/- 257.78\n",
      "Episode length: 767.20 +/- 287.16\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 767       |\n",
      "|    mean_reward        | -175      |\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 202       |\n",
      "|    ep_rew_mean        | -210      |\n",
      "| time/                 |           |\n",
      "|    fps                | 253       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.999    |\n",
      "|    explained_variance | -0.000878 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -0.454    |\n",
      "|    value_loss         | 3.24      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 208      |\n",
      "|    ep_rew_mean        | -210     |\n",
      "| time/                 |          |\n",
      "|    fps                | 256      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0409  |\n",
      "|    explained_variance | -0.00201 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.00709 |\n",
      "|    value_loss         | 1.45     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 206       |\n",
      "|    ep_rew_mean        | -206      |\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.394    |\n",
      "|    explained_variance | -0.000404 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -3.02     |\n",
      "|    value_loss         | 27.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 209       |\n",
      "|    ep_rew_mean        | -202      |\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.727    |\n",
      "|    explained_variance | -0.000365 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 4.28      |\n",
      "|    value_loss         | 52.3      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=14000, episode_reward=-45.13 +/- 159.96\n",
      "Episode length: 595.40 +/- 209.59\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 595       |\n",
      "|    mean_reward        | -45.1     |\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 210       |\n",
      "|    ep_rew_mean        | -200      |\n",
      "| time/                 |           |\n",
      "|    fps                | 251       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.482    |\n",
      "|    explained_variance | -3.78e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 8.53      |\n",
      "|    value_loss         | 126       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 213       |\n",
      "|    ep_rew_mean        | -199      |\n",
      "| time/                 |           |\n",
      "|    fps                | 256       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.692    |\n",
      "|    explained_variance | -0.000127 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -0.475    |\n",
      "|    value_loss         | 3.51      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 213      |\n",
      "|    ep_rew_mean        | -197     |\n",
      "| time/                 |          |\n",
      "|    fps                | 260      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.373   |\n",
      "|    explained_variance | 0.0614   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.592    |\n",
      "|    value_loss         | 61.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 217      |\n",
      "|    ep_rew_mean        | -192     |\n",
      "| time/                 |          |\n",
      "|    fps                | 263      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.827   |\n",
      "|    explained_variance | 0.000454 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -4.96    |\n",
      "|    value_loss         | 167      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=-212.05 +/- 90.82\n",
      "Episode length: 606.80 +/- 136.16\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 607      |\n",
      "|    mean_reward        | -212     |\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 219      |\n",
      "|    ep_rew_mean        | -192     |\n",
      "| time/                 |          |\n",
      "|    fps                | 250      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.397   |\n",
      "|    explained_variance | -0.0068  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.713    |\n",
      "|    value_loss         | 4.8      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 222       |\n",
      "|    ep_rew_mean        | -187      |\n",
      "| time/                 |           |\n",
      "|    fps                | 253       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.691    |\n",
      "|    explained_variance | -0.000298 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -3.58     |\n",
      "|    value_loss         | 29.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 222       |\n",
      "|    ep_rew_mean        | -185      |\n",
      "| time/                 |           |\n",
      "|    fps                | 257       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.678    |\n",
      "|    explained_variance | -6.87e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 4.88      |\n",
      "|    value_loss         | 58.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 222      |\n",
      "|    ep_rew_mean        | -183     |\n",
      "| time/                 |          |\n",
      "|    fps                | 260      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.973   |\n",
      "|    explained_variance | -0.46    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -1.88    |\n",
      "|    value_loss         | 100      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=1.73 +/- 344.63\n",
      "Episode length: 609.20 +/- 210.81\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 609      |\n",
      "|    mean_reward        | 1.73     |\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 228      |\n",
      "|    ep_rew_mean        | -177     |\n",
      "| time/                 |          |\n",
      "|    fps                | 245      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.149   |\n",
      "|    explained_variance | 0.0186   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.198    |\n",
      "|    value_loss         | 31.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 228      |\n",
      "|    ep_rew_mean        | -173     |\n",
      "| time/                 |          |\n",
      "|    fps                | 248      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.369   |\n",
      "|    explained_variance | 0.0153   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.175    |\n",
      "|    value_loss         | 2.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 228      |\n",
      "|    ep_rew_mean        | -171     |\n",
      "| time/                 |          |\n",
      "|    fps                | 252      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0.00332  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -5.61    |\n",
      "|    value_loss         | 94.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 228      |\n",
      "|    ep_rew_mean        | -172     |\n",
      "| time/                 |          |\n",
      "|    fps                | 255      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.441   |\n",
      "|    explained_variance | -17.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.701    |\n",
      "|    value_loss         | 23.8     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=2.77 +/- 147.98\n",
      "Episode length: 394.00 +/- 204.93\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 394      |\n",
      "|    mean_reward        | 2.77     |\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 227      |\n",
      "|    ep_rew_mean        | -170     |\n",
      "| time/                 |          |\n",
      "|    fps                | 250      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.353   |\n",
      "|    explained_variance | 0.221    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.00796  |\n",
      "|    value_loss         | 0.0138   |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "\n",
    "# Save a checkpoint every 1000 steps\n",
    "checkpoint_callback = CheckpointCallback(save_freq=5000, save_path=\"/home/explore/git/guillaume/stable_baselines_3/logs/\",\n",
    "                                         name_prefix=\"rl_model\")\n",
    "\n",
    "# Evaluate the model periodically\n",
    "# and auto-save the best model and evaluations\n",
    "# Use a monitor wrapper to properly report episode stats\n",
    "eval_env = Monitor(gym.make(\"LunarLander-v2\"))\n",
    "# Use deterministic actions for evaluation\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=\"/home/explore/git/guillaume/stable_baselines_3/logs/\",\n",
    "                             log_path=\"/home/explore/git/guillaume/stable_baselines_3/logs/\", eval_freq=2000,\n",
    "                             deterministic=True, render=False)\n",
    "\n",
    "# Train an agent using A2C on LunarLander-v2\n",
    "model = A2C(\"MlpPolicy\", \"LunarLander-v2\", verbose=1)\n",
    "model.learn(total_timesteps=20000, callback=[checkpoint_callback, eval_callback])\n",
    "\n",
    "# Retrieve and reset the environment\n",
    "env = model.get_env()\n",
    "obs = env.reset()\n",
    "\n",
    "# Query the agent (stochastic action here)\n",
    "action, _ = model.predict(obs, deterministic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-miracle",
   "metadata": {},
   "source": [
    "# Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-rough",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CUDA error: CUBLAS_STATUS_INTERNAL_ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-domain",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Downgrade pytorch to 1.7.1 \n",
    "\n",
    "to avoid `RuntimeError: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling cublasCreate(handle)`\n",
    "\n",
    "```bash\n",
    "pip install torch==1.7.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-cursor",
   "metadata": {},
   "source": [
    "## RuntimeError: CUDA error: invalid device function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-ottawa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T08:13:49.478091Z",
     "start_time": "2021-03-25T08:13:49.327901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 25 09:13:49 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Quadro RTX 4000     Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| N/A   41C    P5    18W /  N/A |   2104MiB /  7982MiB |     32%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1153      G   /usr/lib/xorg/Xorg                162MiB |\r\n",
      "|    0   N/A  N/A      1904      G   /usr/lib/xorg/Xorg                268MiB |\r\n",
      "|    0   N/A  N/A      2076      G   /usr/bin/gnome-shell              403MiB |\r\n",
      "|    0   N/A  N/A      2697      G   ...gAAAAAAAAA --shared-files       54MiB |\r\n",
      "|    0   N/A  N/A      7220      G   ...AAAAAAAAA= --shared-files       84MiB |\r\n",
      "|    0   N/A  N/A     57454      G   /usr/lib/firefox/firefox            2MiB |\r\n",
      "|    0   N/A  N/A     59274      C   ...ablebaselines3/bin/python     1051MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-satellite",
   "metadata": {},
   "source": [
    "CUDA version is 11.0 on my workstation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "choice-lunch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T08:26:50.487508Z",
     "start_time": "2021-03-25T08:26:50.374864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\r\n",
      "Cuda compilation tools, release 10.1, V10.1.243\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suited-wedding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T08:46:19.654343Z",
     "start_time": "2021-03-25T08:46:15.568070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=11.0 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-quarterly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stablebaselines3] *",
   "language": "python",
   "name": "conda-env-stablebaselines3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
