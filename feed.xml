<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://castorfou.github.io/guillaume_blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://castorfou.github.io/guillaume_blog/" rel="alternate" type="text/html" /><updated>2021-06-14T10:20:31-05:00</updated><id>https://castorfou.github.io/guillaume_blog/feed.xml</id><title type="html">Guillaume’s blog</title><subtitle>Journey for a datascientist</subtitle><entry><title type="html">Reinforcement Learning Specialization - Coursera - course 4 - A Complete Reinforcement Learning System (Capstone)</title><link href="https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course4.html" rel="alternate" type="text/html" title="Reinforcement Learning Specialization - Coursera - course 4 - A Complete Reinforcement Learning System (Capstone)" /><published>2021-06-14T00:00:00-05:00</published><updated>2021-06-14T00:00:00-05:00</updated><id>https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course4</id><content type="html" xml:base="https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course4.html">&lt;p&gt;Coursera website:  &lt;a href=&quot;https://www.coursera.org/learn/complete-reinforcement-learning-system?specialization=reinforcement-learning&quot;&gt;course 4 - A Complete Reinforcement Learning System (Capstone)&lt;/a&gt; of &lt;a href=&quot;https://www.coursera.org/specializations/reinforcement-learning&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;my notes on &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html&quot;&gt;course 1 - Fundamentals of Reinforcement Learning&lt;/a&gt;, &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html&quot;&gt;course 2 - Sample-based Learning Methods&lt;/a&gt;, &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course3.html&quot;&gt;course 3 - Prediction and Control with Function Approximation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;specialization roadmap&lt;/strong&gt; - course 4 - &lt;strong&gt;A Complete Reinforcement Learning System (Capstone)&lt;/strong&gt; &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/blob/main/course%204%20-%20complete%20reinforcement%20learning%20system/A-Complete-Reinforcement-Learning-System-Capstone-_-Learning-Objectives.pdf&quot;&gt;(syllabus)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Week 1 - Welcome to the Course
Week 2 - Formalize Word Problem as MDP
Week 3 - Choosing The Right Algorithm
Week 4 - Identify Key Performance Parameters
Week 5 - Implement Your Agent
Week 6 - Submit Your Parameter Study!&lt;/p&gt;

&lt;h2 id=&quot;course-4---week-2---formalize-word-problem-as-mdp&quot;&gt;Course 4 - Week 2 - Formalize Word Problem as MDP&lt;/h2&gt;

&lt;h6 id=&quot;final-project-milestone-1&quot;&gt;Final Project: Milestone 1&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Initial Project Meeting with Martha: Formalizing the Problem&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C4W2_reward_function.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Andy Barto on What are Eligibility Traces and Why are they so named?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll &lt;em&gt;understand&lt;/em&gt; the &lt;strong&gt;origin&lt;/strong&gt; of the idea of &lt;strong&gt;eligibility traces&lt;/strong&gt; and you’ll actually &lt;em&gt;see&lt;/em&gt; that you’ve been &lt;strong&gt;using a variant of eligibility traces&lt;/strong&gt; all along.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C4W2_actor_critic_architecture.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;project-resources&quot;&gt;Project Resources&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Let’s Review: Markov Decision Processes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;understand&lt;/em&gt; &lt;strong&gt;Markov decision processes or MDPs&lt;/strong&gt; and &lt;em&gt;describe&lt;/em&gt; how the &lt;strong&gt;dynamics of MDP&lt;/strong&gt; are defined.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Let’s Review: Examples of Episodic and Continuing Tasks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; when to formalize a task as &lt;strong&gt;episodic or continuing&lt;/strong&gt;.&lt;/p&gt;

&lt;h6 id=&quot;assignment&quot;&gt;Assignment&lt;/h6&gt;

&lt;p&gt;MoonShot Technologies&lt;/p&gt;

&lt;p&gt;notebooks in &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/tree/main/assignements/course%203%20week%204&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;course-4---week-3---choosing-the-right-algorithm&quot;&gt;Course 4 - Week 3 - Choosing The Right Algorithm&lt;/h2&gt;

&lt;h6 id=&quot;weekly-learning-goals&quot;&gt;Weekly Learning Goals&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Meeting with Niko: Choosing the Learning Algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C4W3_expected_sarsa.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;project-resources-1&quot;&gt;Project Resources&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Let’s Review: Expected Sarsa&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W3_3_summary.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Let’s Review: What is Q-learning?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Let’s Review: Average Reward- A New Way of Formulating Control Problems&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Let’s Review: Actor-Critic Algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Csaba Szepesvari on Problem Landscape&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Andy and Rich: Advice for Students&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;course-4---week-4---identify-key-performance-parameters&quot;&gt;Course 4 - Week 4 - Identify Key Performance Parameters&lt;/h2&gt;

&lt;h6 id=&quot;weekly-learning-goals-1&quot;&gt;Weekly Learning Goals&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Agent Architecture Meeting with Martha: Overview of Design Choices&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now, let’s discuss the meta parameter choices that you will have to make to fully implement the agent. This means we need to decide on the &lt;strong&gt;function approximator&lt;/strong&gt;, choices in the optimizer for &lt;strong&gt;updating the action values&lt;/strong&gt;, and how to &lt;strong&gt;do exploration&lt;/strong&gt;.&lt;/p&gt;</content><author><name></name></author><category term="reinforcement learning" /><category term="deepmind" /><summary type="html">Coursera website: course 4 - A Complete Reinforcement Learning System (Capstone) of Reinforcement Learning Specialization</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://castorfou.github.io/guillaume_blog/images/RL.png" /><media:content medium="image" url="https://castorfou.github.io/guillaume_blog/images/RL.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Reinforcement Learning Specialization - Coursera - course 3 - Prediction and Control with Function Approximation</title><link href="https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course3.html" rel="alternate" type="text/html" title="Reinforcement Learning Specialization - Coursera - course 3 - Prediction and Control with Function Approximation" /><published>2021-06-07T00:00:00-05:00</published><updated>2021-06-07T00:00:00-05:00</updated><id>https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course3</id><content type="html" xml:base="https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course3.html">&lt;p&gt;Coursera website:  &lt;a href=&quot;https://www.coursera.org/learn/prediction-control-function-approximation/home/welcome&quot;&gt;course 3 - Prediction and Control with Function Approximation&lt;/a&gt; of &lt;a href=&quot;https://www.coursera.org/specializations/reinforcement-learning&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;my notes on &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html&quot;&gt;course 1 - Fundamentals of Reinforcement Learning&lt;/a&gt;, &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html&quot;&gt;course 2 - Sample-based Learning Methods&lt;/a&gt;, &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course4.html&quot;&gt;course 4 - A Complete Reinforcement Learning System (Capstone)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;specialization roadmap&lt;/strong&gt; - course 3 - &lt;strong&gt;Prediction and Control with Function Approximation&lt;/strong&gt; &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/blob/main/course%203%20-%20function%20approximation/Course-3_Prediction-and-Control-with-Function-Approximation-Learning-Objectives.pdf&quot;&gt;(syllabus)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;course 3&lt;/strong&gt; - In Course 3, we leave the relative comfort of small finite MDPs and investigate RL with &lt;strong&gt;function approximation&lt;/strong&gt;. Here we will see that the main concepts from Courses 1 and 2 transferred to problems with larger &lt;strong&gt;infinite state spaces&lt;/strong&gt;. We will cover &lt;strong&gt;feature construction&lt;/strong&gt;, &lt;strong&gt;neural network learning&lt;/strong&gt;, &lt;strong&gt;policy gradient methods&lt;/strong&gt;, and other particularities of the function approximation setting.&lt;/p&gt;

&lt;p&gt;Week 1 - On-policy Prediction with Approximation&lt;/p&gt;

&lt;p&gt;Week 2 - Constructing Features for Prediction&lt;/p&gt;

&lt;p&gt;Week 3 - Control with Approximation&lt;/p&gt;

&lt;p&gt;Week 4 - Policy Gradient&lt;/p&gt;

&lt;h6 id=&quot;course-introduction&quot;&gt;Course introduction&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video by Adam and Martha&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/RL_algo_in_a_tree.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In course 2:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/RL_with_a_table.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In course 3:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/RL_without_a_table.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;course-3---week-1---on-policy-prediction-with-approximation&quot;&gt;Course 3 - Week 1 - On-policy Prediction with Approximation&lt;/h2&gt;

&lt;h6 id=&quot;module-1-learning-objectives&quot;&gt;Module 1 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: Estimating Value Functions as Supervised Learning&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand how we can use parameterized functions to approximate value functions&lt;/li&gt;
  &lt;li&gt;Explain the meaning of linear value function approximation&lt;/li&gt;
  &lt;li&gt;Recognize that the tabular case is a special case of linear value function approximation.&lt;/li&gt;
  &lt;li&gt;Understand that there are many ways to parameterize an approximate value function&lt;/li&gt;
  &lt;li&gt;Understand what is meant by generalization and discrimination&lt;/li&gt;
  &lt;li&gt;Understand how generalization can be beneficial&lt;/li&gt;
  &lt;li&gt;Explain why we want both generalization and discrimination from our function approximation&lt;/li&gt;
  &lt;li&gt;Understand how value estimation can be framed as a supervised learning problem&lt;/li&gt;
  &lt;li&gt;Recognize not all function approximation methods are well suited for reinforcement learning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: The Objective for On-policy Prediction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand the mean-squared value error objective for policy evaluation&lt;/li&gt;
  &lt;li&gt;Explain the role of the state distribution in the objective&lt;/li&gt;
  &lt;li&gt;Understand the idea behind gradient descent and stochastic gradient descent&lt;/li&gt;
  &lt;li&gt;Outline the gradient Monte Carlo algorithm for value estimation&lt;/li&gt;
  &lt;li&gt;Understand how state aggregation can be used to approximate the value function&lt;/li&gt;
  &lt;li&gt;Apply Gradient Monte-Carlo with state aggregation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 3: The Objective for TD&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand the TD-update for function approximation&lt;/li&gt;
  &lt;li&gt;Highlight the advantages of TD compared to Monte-Carlo&lt;/li&gt;
  &lt;li&gt;Outline the Semi-gradient TD(0) algorithm for value estimation&lt;/li&gt;
  &lt;li&gt;Understand that TD converges to a biased value estimate&lt;/li&gt;
  &lt;li&gt;Understand that TD converges much faster than Gradient Monte Carlo&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 4: Linear TD&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Derive the TD-update with linear function approximation&lt;/li&gt;
  &lt;li&gt;Understand that tabular TD(0) is a special case of linear semi-gradient TD(0)&lt;/li&gt;
  &lt;li&gt;Highlight the advantages of linear value function approximation over nonlinear&lt;/li&gt;
  &lt;li&gt;Understand the fixed point of linear TD learning&lt;/li&gt;
  &lt;li&gt;Describe a theoretical guarantee on the mean squared value error at the TD fixed point&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lesson-1-estimating-value-functions-as-supervised-learning&quot;&gt;Lesson 1: Estimating Value Functions as Supervised Learning&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; Chapter 9.1-9.4 &lt;strong&gt;(pp. 197-209)&lt;/strong&gt;  in the Reinforcement Learning textbook&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In many of the tasks to which we would like to apply reinforcement learning the state space is combinatorial and enormous; the number of possible camera images, for example, is much larger than the number of atoms in the universe.&lt;/p&gt;

  &lt;p&gt;In many of our target tasks, almost every state encountered will never have been seen before. To make sensible decisions in such states it is necessary to generalize from previous encounters with different states that are in some sense similar to the current one. In other words, the key issue is that of &lt;strong&gt;generalization&lt;/strong&gt;. How can experience with a limited subset of the state space be usefully generalized to produce a good approximation over a much larger subset?&lt;/p&gt;

  &lt;p&gt;Fortunately, generalization from examples has already been extensively studied, and
we do not need to invent totally new methods for use in reinforcement learning. To some extent we need only combine reinforcement learning methods with existing generalization methods. The kind of generalization we require is often called function approximation because it takes examples from a desired function (e.g., a value function) and attempts to generalize from them to construct an approximation of the entire function. Function approximation is an instance of supervised learning, the primary topic studied in machine learning, artificial neural networks, pattern recognition, and statistical curve fitting.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Video Moving to Parameterized Functions&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;understand&lt;/em&gt; how we can use &lt;strong&gt;parameterized functions&lt;/strong&gt; to approximate values, &lt;em&gt;explain&lt;/em&gt; &lt;strong&gt;linear value function approximation&lt;/strong&gt;, &lt;em&gt;recognize&lt;/em&gt; that the tabular case is a special case of linear value function approximation, and &lt;em&gt;understand&lt;/em&gt; that there are many ways to parameterize an approximate value function.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Generalization and Discrimination&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; what is meant by &lt;strong&gt;generalization&lt;/strong&gt; and &lt;strong&gt;discrimination&lt;/strong&gt;, &lt;em&gt;understand&lt;/em&gt; how generalization can be beneficial, and &lt;em&gt;explain&lt;/em&gt; why we want both generalization and discrimination from our function approximation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Framing Value Estimation as Supervised Learning&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; how value estimation can be framed as a &lt;strong&gt;supervised learning&lt;/strong&gt; problem, and &lt;em&gt;recognize&lt;/em&gt; that not all function approximation methods are well suited for reinforcement learning.&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-the-objective-for-on-policy-prediction&quot;&gt;&lt;strong&gt;Lesson 2: The Objective for On-policy Prediction&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video The Value Error Objective&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video you will be able to &lt;em&gt;understand&lt;/em&gt; the &lt;strong&gt;Mean Squared Value Error objective&lt;/strong&gt; for policy evaluation and &lt;em&gt;explain&lt;/em&gt; the role of the &lt;strong&gt;state distribution&lt;/strong&gt; in the objective.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mover accent=&quot;true&quot;&gt;&lt;mrow&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;true&quot;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/munder&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mover accent=&quot;true&quot;&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\overline{VE}=\displaystyle\sum_{s}\mu(s)[v_\pi(s)-\hat{v}(s,w)]^2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8833300000000001em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord overline&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8833300000000001em;&quot;&gt;&lt;span style=&quot;top:-3em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.22222em;&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05764em;&quot;&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.80333em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;overline-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.3000100000000003em;vertical-align:-1.250005em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.050005em;&quot;&gt;&lt;span style=&quot;top:-1.8999949999999999em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.0500049999999996em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.250005em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;μ&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.1141079999999999em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord accent&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.69444em;&quot;&gt;&lt;span style=&quot;top:-3em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;accent-body&quot; style=&quot;left:-0.22222em;&quot;&gt;^&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02691em;&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8641079999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
This is the &lt;strong&gt;Mean Squared Value Error Objective&lt;/strong&gt; where $\mu$ reflects how much we care about each state (a probability distribution)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Introducing Gradient Descent&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; the idea of &lt;strong&gt;gradient descent&lt;/strong&gt;, and &lt;em&gt;understand&lt;/em&gt; that gradient descent converges to stationary points.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Gradient Monte for Policy Evaluation&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; how to use gradient descent and &lt;strong&gt;stochastic gradient descent&lt;/strong&gt; to minimize value error and &lt;em&gt;outline&lt;/em&gt; the &lt;strong&gt;Gradient Monte Carlo&lt;/strong&gt; algorithm for value estimation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C3W1_gradient_monte_carlo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video State Aggregation with Monte Carlo&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; how &lt;strong&gt;state aggregation&lt;/strong&gt; can be used to approximate the value function and &lt;em&gt;apply&lt;/em&gt; gradient Monte Carlo with state aggregation.&lt;/p&gt;

&lt;h6 id=&quot;lesson-3-the-objective-for-td&quot;&gt;&lt;strong&gt;Lesson 3: The Objective for TD&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Semi-Gradient TD for Policy Evaluation&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video you will be able to &lt;em&gt;understand&lt;/em&gt; the &lt;strong&gt;TD update&lt;/strong&gt; for function approximation, and &lt;em&gt;outline&lt;/em&gt; the &lt;strong&gt;semi-gradient TD(0)&lt;/strong&gt; algorithm for value estimation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C3W1_semi_gradient_TD0.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Comparing TD and Monte Carlo with State Aggregation&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;understand&lt;/em&gt; that TD converges to a bias value estimate and &lt;em&gt;understand&lt;/em&gt; that TD can learn faster than Gradient Monte Carlo.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Doina Precup: Building Knowledge for AI Agents with Reinforcement Learning&lt;/strong&gt;&lt;/p&gt;

&lt;h6 id=&quot;lesson-4-linear-td&quot;&gt;&lt;strong&gt;Lesson 4: Linear TD&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video The Linear TD Update&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;derive&lt;/em&gt; the TD update with linear function approximation, &lt;em&gt;understand&lt;/em&gt; that tabular TD(0) as a special case of &lt;strong&gt;linear semi gradient TD(0)&lt;/strong&gt;, and &lt;em&gt;understand&lt;/em&gt; why we care about linear TD as a special case.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video The True Objective for TD&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; the &lt;strong&gt;fixed point&lt;/strong&gt; of linear TD and &lt;em&gt;describe&lt;/em&gt; a theoretical guarantee on the mean squared value error at the TD fixed point.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Week 1 Summary&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;h6 id=&quot;assignment&quot;&gt;Assignment&lt;/h6&gt;

&lt;p&gt;TD with State Aggregation&lt;/p&gt;

&lt;p&gt;notebooks in &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/tree/main/assignements/course%203%20week%201&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;course-3---week-2---constructing-features-for-prediction&quot;&gt;Course 3 - Week 2 - Constructing Features for Prediction&lt;/h2&gt;

&lt;h6 id=&quot;module-2-learning-objectives&quot;&gt;Module 2 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: Feature Construction for Linear Methods&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Describe the difference between coarse coding and tabular representations&lt;/li&gt;
  &lt;li&gt;Explain the trade-off when designing representations between discrimination and generalization&lt;/li&gt;
  &lt;li&gt;Understand how different coarse coding schemes affect the functions that can be represented&lt;/li&gt;
  &lt;li&gt;Explain how tile coding is a (computationally?) convenient case of coarse coding&lt;/li&gt;
  &lt;li&gt;Describe how designing the tilings affects the resultant representation&lt;/li&gt;
  &lt;li&gt;Understand that tile coding is a computationally efficient implementation of coarse coding&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: Neural Networks&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define a neural network&lt;/li&gt;
  &lt;li&gt;Define activation functions&lt;/li&gt;
  &lt;li&gt;Define a feedforward architecture&lt;/li&gt;
  &lt;li&gt;Understand how neural networks are doing feature construction&lt;/li&gt;
  &lt;li&gt;Understand how neural networks are a non-linear function of state&lt;/li&gt;
  &lt;li&gt;Understand how deep networks are a composition of layers&lt;/li&gt;
  &lt;li&gt;Understand the tradeoff between learning capacity and challenges presented by deeper networks&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 3: Training Neural Networks&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Compute the gradient of a single hidden layer neural network&lt;/li&gt;
  &lt;li&gt;Understand how to compute the gradient for arbitrarily deep networks&lt;/li&gt;
  &lt;li&gt;Understand the importance of initialization for neural networks&lt;/li&gt;
  &lt;li&gt;Describe strategies for initializing neural networks&lt;/li&gt;
  &lt;li&gt;Describe optimization techniques for training neural networks&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lesson-1-feature-construction-for-linear-methods&quot;&gt;&lt;strong&gt;Lesson 1: Feature Construction for Linear Methods&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; Chapter 9.4-9.5.0 &lt;strong&gt;(pp. 204-210)&lt;/strong&gt;, 9.5.3-9.5.4 &lt;strong&gt;(pp. 215-222)&lt;/strong&gt; and 9.7 &lt;strong&gt;(pp. 223-228)&lt;/strong&gt; in the Reinforcement Learning textbook&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Coarse Coding&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;describe&lt;/em&gt; &lt;strong&gt;coarse coding&lt;/strong&gt; and &lt;em&gt;describe&lt;/em&gt; how it relates to &lt;strong&gt;state aggregation&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C3W2_coarse_coding.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Generalization Properties of Coarse Coding&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;describe&lt;/em&gt; how &lt;strong&gt;coarse coding parameters&lt;/strong&gt; affect &lt;strong&gt;generalization&lt;/strong&gt; and &lt;strong&gt;discrimination&lt;/strong&gt;, and &lt;em&gt;understand&lt;/em&gt; how that affects &lt;strong&gt;learning speed and accuracy&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Tile Coding&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;explain&lt;/em&gt; how &lt;strong&gt;tile coding&lt;/strong&gt; achieves both &lt;strong&gt;generalization&lt;/strong&gt; and &lt;strong&gt;discrimination&lt;/strong&gt;, and &lt;em&gt;understand&lt;/em&gt; the benefits and limitations of tile coding.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Using Tile Coding in TD&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;explain&lt;/em&gt; how to use &lt;strong&gt;tile coding&lt;/strong&gt; with &lt;strong&gt;TD learning&lt;/strong&gt; and &lt;em&gt;identify&lt;/em&gt; important properties of &lt;strong&gt;tile code representations&lt;/strong&gt;.&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-neural-networks&quot;&gt;&lt;strong&gt;Lesson 2: Neural Networks&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video What is a Neural Network?&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;define&lt;/em&gt; a &lt;strong&gt;neural network&lt;/strong&gt;, &lt;em&gt;define&lt;/em&gt; an &lt;strong&gt;activation function&lt;/strong&gt; and &lt;em&gt;understand&lt;/em&gt; how a neural network is a &lt;strong&gt;parameterized function&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Non-linear Approximation with Neural Networks&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will &lt;em&gt;understand&lt;/em&gt; how neural networks do &lt;strong&gt;feature construction&lt;/strong&gt;, and &lt;em&gt;understand&lt;/em&gt; how neural networks are a &lt;strong&gt;non-linear function&lt;/strong&gt; of state.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Deep Neural Networks&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you will &lt;em&gt;understand&lt;/em&gt; how &lt;strong&gt;deep neural networks&lt;/strong&gt; are composed of &lt;strong&gt;many layers&lt;/strong&gt; and &lt;em&gt;understand&lt;/em&gt; that &lt;strong&gt;depth&lt;/strong&gt; can facilitate learning &lt;strong&gt;features&lt;/strong&gt; through &lt;strong&gt;composition&lt;/strong&gt; and &lt;strong&gt;abstraction&lt;/strong&gt;.&lt;/p&gt;

&lt;h6 id=&quot;lesson-3-training-neural-networks&quot;&gt;&lt;strong&gt;Lesson 3: Training Neural Networks&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Gradient Descent for Training Neural Networks&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;derive&lt;/em&gt; the &lt;strong&gt;gradient&lt;/strong&gt; of a neural network and &lt;em&gt;implement&lt;/em&gt; &lt;strong&gt;gradient descent&lt;/strong&gt; on a neural network.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Optimization Strategies for NNs&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; the importance of &lt;strong&gt;initialization&lt;/strong&gt; for neural networks and &lt;em&gt;describe&lt;/em&gt; &lt;strong&gt;optimization techniques&lt;/strong&gt; for training neural networks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video David Silver on Deep Learning + RL = AI?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Week 2 Review&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;h6 id=&quot;assignment-1&quot;&gt;Assignment&lt;/h6&gt;

&lt;p&gt;Semi-gradient TD with a Neural Network&lt;/p&gt;

&lt;p&gt;notebooks in &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/tree/main/assignements/course%203%20week%202&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;course-3---week-3---control-with-approximation&quot;&gt;Course 3 - Week 3 - Control with Approximation&lt;/h2&gt;

&lt;h6 id=&quot;module-3-learning-objectives&quot;&gt;Module 3 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: Episodic Sarsa with Function Approximation&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Explain the update for Episodic Sarsa with function approximation&lt;/li&gt;
  &lt;li&gt;Introduce the feature choices, including passing actions to features or stacking state features&lt;/li&gt;
  &lt;li&gt;Visualize value function and learning curves&lt;/li&gt;
  &lt;li&gt;Discuss how this extends to Q-learning easily, since it is a subset of Expected Sarsa&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: Exploration under Function Approximation&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understanding optimistically initializing your value function as a form of exploration&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 3: Average Reward&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Describe the average reward setting&lt;/li&gt;
  &lt;li&gt;Explain when average reward optimal policies are different from discounted solutions&lt;/li&gt;
  &lt;li&gt;Understand how differential value functions are different from discounted value functions&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lesson-1-episodic-sarsa-with-function-approximation&quot;&gt;&lt;strong&gt;Lesson 1: Episodic Sarsa with Function Approximation&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; Chapter 10 &lt;strong&gt;(pp. 243-246)&lt;/strong&gt; and 10.3 &lt;strong&gt;(pp. 249-252)&lt;/strong&gt; in the Reinforcement Learning textbook&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Episodic Sarsa with Function Approximation&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;understand&lt;/em&gt; how to construct &lt;strong&gt;action-dependent features&lt;/strong&gt; for approximate action values and &lt;em&gt;explain&lt;/em&gt; how to use &lt;strong&gt;Sarsa&lt;/strong&gt; in &lt;strong&gt;episodic tasks&lt;/strong&gt; with &lt;strong&gt;function approximation&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C3W3_episodic_sarsa_appro.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Episodic Sarsa in Mountain Car&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you will &lt;em&gt;gain experience&lt;/em&gt; analyzing the performance of an &lt;strong&gt;approximate TD control&lt;/strong&gt; method.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Expected Sarsa with Function Approximation&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;explain&lt;/em&gt; the update for &lt;strong&gt;expected Sarsa&lt;/strong&gt; with &lt;strong&gt;function approximation&lt;/strong&gt;, and &lt;em&gt;explain&lt;/em&gt; the update for &lt;strong&gt;Q-learning&lt;/strong&gt; with &lt;strong&gt;function approximation&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C3W3_expected_sarsa_q_learning.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-exploration-under-function-approximation&quot;&gt;&lt;strong&gt;Lesson 2: Exploration under Function Approximation&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Exploration under Function Approximation&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;describe&lt;/em&gt; how &lt;strong&gt;optimistic initial values&lt;/strong&gt; and &lt;strong&gt;$\epsilon$-greedy&lt;/strong&gt; can be used with &lt;strong&gt;function approximation&lt;/strong&gt;.&lt;/p&gt;

&lt;h6 id=&quot;lesson-3-average-reward&quot;&gt;&lt;strong&gt;Lesson 3: Average Reward&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Average Reward: A New Way of Formulating Control Problems&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;describe&lt;/em&gt; the &lt;strong&gt;average reward&lt;/strong&gt; setting, &lt;em&gt;explain&lt;/em&gt; when &lt;strong&gt;average reward&lt;/strong&gt; optimal policies are different from policies obtained under discounting and &lt;em&gt;understand&lt;/em&gt; &lt;strong&gt;differential value functions&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Satinder Singh on Intrinsic Rewards&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Week 3 Review&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;h6 id=&quot;assignment-2&quot;&gt;Assignment&lt;/h6&gt;

&lt;p&gt;Function Approximation and Control&lt;/p&gt;

&lt;p&gt;notebooks in &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/tree/main/assignements/course%203%20week%203&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;course-3---week-4---policy-gradient&quot;&gt;Course 3 - Week 4 - Policy Gradient&lt;/h2&gt;

&lt;h6 id=&quot;module-4-learning-objectives&quot;&gt;Module 4 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: Learning Parameterized Policies&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand how to define policies as parameterized functions&lt;/li&gt;
  &lt;li&gt;Define one class of parameterized policies based on the softmax function&lt;/li&gt;
  &lt;li&gt;Understand the advantages of using parameterized policies over action-value based methods&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: Policy Gradient for Continuing Tasks&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Describe the objective for policy gradient algorithms&lt;/li&gt;
  &lt;li&gt;Describe the results of the policy gradient theorem&lt;/li&gt;
  &lt;li&gt;Understand the importance of the policy gradient theorem&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 3: Actor-Critic for Continuing Tasks&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Derive a sample-based estimate for the gradient of the average reward objective&lt;/li&gt;
  &lt;li&gt;Describe the actor-critic algorithm for control with function approximation, for continuing tasks&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 4: Policy Parameterizations&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Derive the actor-critic update for a softmax policy with linear action preferences&lt;/li&gt;
  &lt;li&gt;Implement this algorithm&lt;/li&gt;
  &lt;li&gt;Design concrete function approximators for an average reward actor-critic algorithm&lt;/li&gt;
  &lt;li&gt;Analyze the performance of an average reward agent&lt;/li&gt;
  &lt;li&gt;Derive the actor-critic update for a gaussian policy&lt;/li&gt;
  &lt;li&gt;Apply average reward actor-critic with a gaussian policy to a particular task with continuous actions&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lesson-1-learning-parameterized-policies&quot;&gt;&lt;strong&gt;Lesson 1: Learning Parameterized Policies&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; Chapter 13 &lt;strong&gt;(pp. 321-336)&lt;/strong&gt; in the Reinforcement Learning textbook&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Learning Policies Directly&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;understand&lt;/em&gt; how to define policies as &lt;strong&gt;parameterized functions&lt;/strong&gt; and &lt;em&gt;define&lt;/em&gt; one class of parametrized policies based on the &lt;strong&gt;softmax&lt;/strong&gt; function.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Advantages of Policy Parameterization&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;understand&lt;/em&gt; some of the advantages of using parameterized policies.&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-policy-gradient-for-continuing-tasks&quot;&gt;&lt;strong&gt;Lesson 2: Policy Gradient for Continuing Tasks&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video The Objective for Learning Policies&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;describe&lt;/em&gt; the objective for &lt;strong&gt;policy gradient algorithms&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C3W4_objective_policy_gradient.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video The Policy Gradient Theorem&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;describe&lt;/em&gt; the result of the &lt;strong&gt;policy gradient theorem&lt;/strong&gt; and &lt;em&gt;understand&lt;/em&gt; the importance of the policy gradient theorem.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C3W4_policy_gradient_theorem.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;lesson-3-actor-critic-for-continuing-tasks&quot;&gt;&lt;strong&gt;Lesson 3: Actor-Critic for Continuing Tasks&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Estimating the Policy Gradient&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;derive&lt;/em&gt; a &lt;strong&gt;sample-based estimate&lt;/strong&gt; for the gradient of the average reward objective.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C3W4_stochastic_gradient_ascent.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Actor-Critic Algorithm&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;describe&lt;/em&gt; the &lt;strong&gt;actor-critic algorithm&lt;/strong&gt; for control with function approximation for continuing tasks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C3W4_actor_critic_algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;lesson-4-policy-parameterizations&quot;&gt;&lt;strong&gt;Lesson 4: Policy Parameterizations&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Actor-Critic with Softmax Policies&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video you’ll be able to &lt;em&gt;derive&lt;/em&gt; the actor critic update for a Softmax policy with linear action preferences and &lt;em&gt;implement&lt;/em&gt; this algorithm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Demonstration with Actor-Critic&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;design&lt;/em&gt; a function approximator for an average reward actor-critic algorithm and &lt;em&gt;analyze&lt;/em&gt; the performance of an average reward agent.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Gaussian Policies for Continuous Actions&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;derive&lt;/em&gt; the actor-critic update for a &lt;strong&gt;Gaussian policy&lt;/strong&gt; and &lt;em&gt;apply&lt;/em&gt; average reward actor-critic with a Gaussian policy to task with continuous actions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Week 4 Summary&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C3W4_actor_critic_actions.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;assignment-3&quot;&gt;Assignment&lt;/h6&gt;

&lt;p&gt;Average Reward Softmax Actor-Critic using Tile-coding&lt;/p&gt;

&lt;p&gt;notebooks in &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/tree/main/assignements/course%203%20week%204&quot;&gt;github&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="reinforcement learning" /><category term="deepmind" /><summary type="html">Coursera website: course 3 - Prediction and Control with Function Approximation of Reinforcement Learning Specialization</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://castorfou.github.io/guillaume_blog/images/RL.png" /><media:content medium="image" url="https://castorfou.github.io/guillaume_blog/images/RL.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Logbook for June 21</title><link href="https://castorfou.github.io/guillaume_blog/blog/logbook-June.html" rel="alternate" type="text/html" title="Logbook for June 21" /><published>2021-06-01T00:00:00-05:00</published><updated>2021-06-01T00:00:00-05:00</updated><id>https://castorfou.github.io/guillaume_blog/blog/logbook-June</id><content type="html" xml:base="https://castorfou.github.io/guillaume_blog/blog/logbook-June.html">&lt;h2 id=&quot;week-22---june-21&quot;&gt;Week 22 - June 21&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Tuesday 6/1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn.html&quot;&gt;Machine learning in python with scikit-learn&lt;/a&gt; end of module 3. Hyperparameter tuning&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C2W3 - Temporal Difference for Control - start&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Wednesday 6/2&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;SHAP: &lt;a href=&quot;https://github.com/castorfou/shap/blob/master/notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.ipynb&quot;&gt;An introduction to explainable AI with Shapley values&lt;/a&gt;, &lt;a href=&quot;https://github.com/castorfou/shap/blob/master/notebooks/overviews/Be%20careful%20when%20interpreting%20predictive%20models%20in%20search%20of%20causal%C2%A0insights.ipynb&quot;&gt;Be careful when interpreting predictive models in search of causal insights&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn.html&quot;&gt;Machine learning in python with scikit-learn&lt;/a&gt; module 4. Linear models&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thursday 6/3&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Talk (30’) from Michael Bronstein on &lt;a href=&quot;https://slideslive.com/38956431/invited-talk-michael-bronstein&quot;&gt;Geometric Deep Learning&lt;/a&gt; - permutations invariant is a domain research I could use&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn.html&quot;&gt;Machine learning in python with scikit-learn&lt;/a&gt; end of module 4. Linear models&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Friday 6/4&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C2W4 - Planning, Learning and Acting&lt;/p&gt;

&lt;p&gt;End of course 2 of &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;week-23---june-21&quot;&gt;Week 23 - June 21&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Monday 6/7&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course3.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C3W1 - On-policy Prediction with Approximation&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thursday 6/10&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course3.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C3W2 - Constructing Features for Prediction&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Friday 6/11&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn.html&quot;&gt;Machine learning in python with scikit-learn&lt;/a&gt; module 5. Decision tree models&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course3.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C3W3 - Control with Approximation&lt;/p&gt;

&lt;h2 id=&quot;week-24---june-21&quot;&gt;Week 24 - June 21&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Monday 6/14&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course3.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C3W4 - Policy Gradient&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course4.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C4W1 - start of course 4. A Complete Reinforcement Learning System (Capstone) - week 1 to week 4&lt;/p&gt;</content><author><name></name></author><category term="logbook" /><summary type="html">Week 22 - June 21</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://castorfou.github.io/guillaume_blog/images/logbook.jpg" /><media:content medium="image" url="https://castorfou.github.io/guillaume_blog/images/logbook.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Reinforcement Learning Specialization - Coursera - course 2 - Sample-based Learning Methods</title><link href="https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html" rel="alternate" type="text/html" title="Reinforcement Learning Specialization - Coursera - course 2 - Sample-based Learning Methods" /><published>2021-05-25T00:00:00-05:00</published><updated>2021-05-25T00:00:00-05:00</updated><id>https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2</id><content type="html" xml:base="https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html">&lt;p&gt;Coursera website:  &lt;a href=&quot;https://www.coursera.org/learn/sample-based-learning-methods/home/welcome&quot;&gt;course 2 - Sample-based Learning Methods&lt;/a&gt; of &lt;a href=&quot;https://www.coursera.org/specializations/reinforcement-learning&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;my notes on &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html&quot;&gt;course 1 - Fundamentals of Reinforcement Learning&lt;/a&gt;, &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course3.html&quot;&gt;course 3 - Prediction and Control with Function Approximation&lt;/a&gt;, &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course4.html&quot;&gt;course 4 - A Complete Reinforcement Learning System (Capstone)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;specialization roadmap&lt;/strong&gt; - course 2 - &lt;strong&gt;Sample-based Learning Methods&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;course 2&lt;/strong&gt; - In Course 2, we built on these ideas and design algorithms for learning &lt;strong&gt;without a model&lt;/strong&gt; of the world. We study three classes of methods designed for learning from trial and error interaction. We start with &lt;strong&gt;Monte Carlo&lt;/strong&gt; methods and then move on to &lt;strong&gt;temporal difference&lt;/strong&gt; learning, including Q learning. We conclude Course 2 with an investigation of methods for &lt;strong&gt;planning&lt;/strong&gt; with learned models.&lt;/p&gt;

&lt;p&gt;Week 1 - Monte-Carlo Methods for Prediction &amp;amp; Control&lt;/p&gt;

&lt;p&gt;Week 2 - Temporal Difference Learning Methods for Prediction&lt;/p&gt;

&lt;p&gt;Week 3 - Temporal Difference Learning Methods for Control&lt;/p&gt;

&lt;p&gt;Week 4 - Planning, Learning &amp;amp; Acting&lt;/p&gt;

&lt;h2 id=&quot;course-2---week-1---monte-carlo-methods-for-prediction--control&quot;&gt;Course 2 - Week 1 - Monte-Carlo Methods for Prediction &amp;amp; Control&lt;/h2&gt;

&lt;h6 id=&quot;module-1-learning-objectives&quot;&gt;Module 1 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: Introduction to Monte-Carlo Methods&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand how Monte-Carlo methods can be used to estimate value functions from sampled interaction&lt;/li&gt;
  &lt;li&gt;Identify problems that can be solved using Monte-Carlo methods&lt;/li&gt;
  &lt;li&gt;Use Monte-Carlo prediction to estimate the value function for a given policy.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: Monte-Carlo for Control&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Estimate action-value functions using Monte-Carlo&lt;/li&gt;
  &lt;li&gt;Understand the importance of maintaining exploration in Monte-Carlo algorithms&lt;/li&gt;
  &lt;li&gt;Understand how to use Monte-Carlo methods to implement a GPI algorithm&lt;/li&gt;
  &lt;li&gt;Apply Monte-Carlo with exploring starts to solve an MDP&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 3: Exploration Methods for Monte-Carlo&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand why exploring starts can be problematic in real problems&lt;/li&gt;
  &lt;li&gt;Describe an alternative exploration method for Monte-Carlo control&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 4: Off-policy learning for prediction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand how off-policy learning can help deal with the exploration problem&lt;/li&gt;
  &lt;li&gt;Produce examples of target policies and examples of behavior policies&lt;/li&gt;
  &lt;li&gt;Understand importance sampling&lt;/li&gt;
  &lt;li&gt;Use importance sampling to estimate the expected value of a target distribution using samples from a different distribution&lt;/li&gt;
  &lt;li&gt;Understand how to use importance sampling to correct returns&lt;/li&gt;
  &lt;li&gt;Understand how to modify the Monte-Carlo prediction algorithm for off-policy learning.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lesson-1-introduction-to-monte-carlo-methods&quot;&gt;Lesson 1: Introduction to Monte Carlo Methods&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; Chapter 5.0-5.5 &lt;strong&gt;(pp. 91-104)&lt;/strong&gt;  in the Reinforcement Learning textbook&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Although a model is required, the model need only generate sample transitions, not the complete probability distributions of all possible transitions that is required for dynamic programming (DP).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Video What is Monte Carlo&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video you will be able to &lt;em&gt;understand&lt;/em&gt; how &lt;strong&gt;Monte Carlo&lt;/strong&gt; methods can be used to estimate value functions from sampled interaction and &lt;em&gt;identify&lt;/em&gt; problems that can be solved using Monte Carlo methods.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Using Monte Carlo for Prediction&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;use&lt;/em&gt; &lt;strong&gt;Monte Carlo prediction&lt;/strong&gt; to estimate the value function for a given policy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W1_1_mc_algo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-monte-carlo-for-control&quot;&gt;Lesson 2: Monte Carlo for Control&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Using Monte Carlo for Action Values&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;estimate&lt;/em&gt; &lt;strong&gt;action-value functions&lt;/strong&gt; using Monte Carlo and &lt;em&gt;understand&lt;/em&gt; the importance of &lt;strong&gt;maintaining exploration&lt;/strong&gt; in Monte Carlo algorithms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Using Monte Carlo methods for generalized policy iteration&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you will &lt;em&gt;understand&lt;/em&gt; how to use Monte Carlo methods to implement a &lt;strong&gt;generalized policy iteration&lt;/strong&gt; GPI algorithm.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W1_1_gpi.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Solving the BlackJack Example&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;apply&lt;/em&gt; &lt;strong&gt;Monte Carlo with Exploring Starts&lt;/strong&gt; to solve an example MDP.&lt;/p&gt;

&lt;h6 id=&quot;lesson-3-exploration-methods-for-monte-carlo&quot;&gt;Lesson 3: Exploration Methods for Monte Carlo&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Epsilon-soft policies&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video you will &lt;em&gt;understand&lt;/em&gt; why exploring starts can be problematic in real problems and you will be able to &lt;em&gt;describe&lt;/em&gt; an alternative expiration method to &lt;strong&gt;maintain exploration&lt;/strong&gt; in Monte Carlo control.&lt;/p&gt;

&lt;h6 id=&quot;lesson-4-off-policy-learning-for-prediction&quot;&gt;Lesson 4: Off-policy Learning for Prediction&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Why does off-policy learning matter?&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video you will be able to &lt;em&gt;understand&lt;/em&gt; how &lt;strong&gt;off policy learning&lt;/strong&gt; can help deal with the expiration problem. You will also be able to &lt;em&gt;produce&lt;/em&gt; examples of Target policies and examples of &lt;strong&gt;behavior policies&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The key points to take away from today are that &lt;strong&gt;off policy learning&lt;/strong&gt; is another way to obtain &lt;em&gt;continual exploration&lt;/em&gt;. The policy that we are &lt;em&gt;learning&lt;/em&gt; is called the &lt;strong&gt;target policy&lt;/strong&gt; and the policy that we are choosing &lt;em&gt;actions&lt;/em&gt; from is the &lt;strong&gt;behavior policy&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Importance Sampling&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;use&lt;/em&gt; &lt;strong&gt;importance sampling&lt;/strong&gt; to estimate the expected value of a target distribution using samples from a different distribution.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Off-Policy Monte Carlo Prediction&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; how to use &lt;strong&gt;important sampling&lt;/strong&gt; to correct returns, and you will &lt;em&gt;understand&lt;/em&gt; how to modify the &lt;strong&gt;Monte Carlo prediction algorithm&lt;/strong&gt; for off-policy learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Emma Brunskill: Batch Reinforcement Learning&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Week 1 Summary&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; Chapter 5.10 &lt;strong&gt;(pp. 115-116)&lt;/strong&gt;  in the Reinforcement Learning textbook&lt;/p&gt;

&lt;h2 id=&quot;course-2---week-2---temporal-difference-learning-methods-for-prediction&quot;&gt;Course 2 - Week 2 - Temporal Difference Learning Methods for Prediction&lt;/h2&gt;

&lt;h6 id=&quot;module-2-learning-objectives&quot;&gt;Module 2 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: Introduction to Temporal Difference Learning&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define temporal-difference learning&lt;/li&gt;
  &lt;li&gt;Define the temporal-difference error&lt;/li&gt;
  &lt;li&gt;Understand the TD(0) algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: Advantages of TD&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand the benefits of learning online with TD&lt;/li&gt;
  &lt;li&gt;Identify key advantages of TD methods over Dynamic Programming and Monte Carlo methods&lt;/li&gt;
  &lt;li&gt;Identify the empirical benefits of TD learning&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lesson-1-introduction-to-temporal-difference-learning&quot;&gt;Lesson 1: Introduction to Temporal Difference Learning&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; Chapter 6-6.3 &lt;strong&gt;(pp. 116-128)&lt;/strong&gt;  in the Reinforcement Learning textbook&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video What is Temporal Difference (TD) learning?&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;define&lt;/em&gt; &lt;strong&gt;temporal difference learning&lt;/strong&gt;, &lt;em&gt;define&lt;/em&gt; the &lt;strong&gt;temporal difference error&lt;/strong&gt;, and &lt;em&gt;understand&lt;/em&gt; the &lt;strong&gt;TD(0) algorithm&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W2_1_td0_algo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Rich Sutton: The Importance of TD Learning&lt;/strong&gt; by Richard Sutton&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-advantages-of-td&quot;&gt;Lesson 2: Advantages of TD&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video The advantages of temporal difference learning&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; the benefits of &lt;strong&gt;learning online with TD&lt;/strong&gt; and &lt;em&gt;identify&lt;/em&gt; key advantages of TD methods over dynamic programming and Monte Carlo.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Comparing TD and Monte Carlo&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;identify&lt;/em&gt; the &lt;strong&gt;empirical benefits&lt;/strong&gt; of &lt;strong&gt;TD Learning&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Andy Barto and Rich Sutton: More on the History of RL&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Week 2 Summary&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;h6 id=&quot;assignment&quot;&gt;Assignment&lt;/h6&gt;

&lt;p&gt;Policy Evaluation in Cliff Walking Environment&lt;/p&gt;

&lt;p&gt;notebooks in &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/tree/main/assignements/course%202%20week%202&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;course-2---week-3---temporal-difference-learning-methods-for-control&quot;&gt;Course 2 - Week 3 - Temporal Difference Learning Methods for Control&lt;/h2&gt;

&lt;h6 id=&quot;module-3-learning-objectives&quot;&gt;Module 3 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: TD for Control&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Explain how generalized policy iteration can be used with TD to find improved policies&lt;/li&gt;
  &lt;li&gt;Describe the Sarsa control algorithm&lt;/li&gt;
  &lt;li&gt;Understand how the Sarsa control algorithm operates in an example MDP&lt;/li&gt;
  &lt;li&gt;Analyze the performance of a learning algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: Off-policy TD Control: Q-learning&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Describe the Q-learning algorithm&lt;/li&gt;
  &lt;li&gt;Explain the relationship between Q-learning and the Bellman optimality equations.&lt;/li&gt;
  &lt;li&gt;Apply Q-learning to an MDP to find the optimal policy&lt;/li&gt;
  &lt;li&gt;Understand how Q-learning performs in an example MDP&lt;/li&gt;
  &lt;li&gt;Understand the differences between Q-learning and Sarsa&lt;/li&gt;
  &lt;li&gt;Understand how Q-learning can be off-policy without using importance sampling&lt;/li&gt;
  &lt;li&gt;Describe how the on-policy nature of Sarsa and the off-policy nature of Q-learning affect their relative performance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 3: Expected Sarsa&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Describe the Expected Sarsa algorithm&lt;/li&gt;
  &lt;li&gt;Describe Expected Sarsa’s behaviour in an example MDP&lt;/li&gt;
  &lt;li&gt;Understand how Expected Sarsa compares to Sarsa control&lt;/li&gt;
  &lt;li&gt;Understand how Expected Sarsa can do off-policy learning without using importance sampling&lt;/li&gt;
  &lt;li&gt;Explain how Expected Sarsa generalizes Q-learning&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lesson-1-td-for-control&quot;&gt;&lt;strong&gt;Lesson 1: TD for Control&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; Chapter 6.4-6.6 &lt;strong&gt;(pp. 129-134)&lt;/strong&gt;  in the Reinforcement Learning textbook&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W3_1_sarsa_algo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W3_2_qlearning_algo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video&lt;/strong&gt; &lt;strong&gt;Sarsa: GPI with TD&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;explain&lt;/em&gt; how generalized policy iteration can be used with TD to find &lt;strong&gt;improved policies&lt;/strong&gt;, as well as &lt;em&gt;describe&lt;/em&gt; the &lt;strong&gt;Sarsa control algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Sarsa in the Windy Grid World&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you will &lt;em&gt;understand&lt;/em&gt; how the &lt;strong&gt;Sarsa&lt;/strong&gt; control algorithm operates in an example &lt;strong&gt;MDP&lt;/strong&gt;. You will also &lt;em&gt;gain experience&lt;/em&gt; analyzing the &lt;strong&gt;performance&lt;/strong&gt; of a learning algorithm.&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-off-policy-td-control-q-learning&quot;&gt;&lt;strong&gt;Lesson 2: Off-policy TD Control: Q-learning&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video What is Q-learning?&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;describe&lt;/em&gt; the &lt;strong&gt;Q-learning&lt;/strong&gt; algorithm, and &lt;em&gt;explain&lt;/em&gt; the relationship between &lt;strong&gt;Q-learning&lt;/strong&gt; and the &lt;strong&gt;Bellman optimality equations&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Q-learning in the Windy Grid World&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you will &lt;em&gt;gain insight&lt;/em&gt; into how &lt;strong&gt;Q-Learning&lt;/strong&gt; performs in an example &lt;strong&gt;MDP&lt;/strong&gt;. And &lt;em&gt;gain experience&lt;/em&gt; comparing the &lt;strong&gt;performance&lt;/strong&gt; of multiple learning algorithms on a single MDP.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video How is Q-learning off-policy?&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will &lt;em&gt;understand&lt;/em&gt; how Q-learning can be &lt;strong&gt;off-policy&lt;/strong&gt; without using &lt;strong&gt;important sampling&lt;/strong&gt; and be able to &lt;em&gt;describe&lt;/em&gt; how learning &lt;strong&gt;on-policy or off-policy&lt;/strong&gt; might affect performance in &lt;strong&gt;control&lt;/strong&gt;.&lt;/p&gt;

&lt;h6 id=&quot;lesson-3-expected-sarsa&quot;&gt;&lt;strong&gt;Lesson 3: Expected Sarsa&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Expected Sarsa&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;explain&lt;/em&gt; the &lt;strong&gt;expected Sarsa&lt;/strong&gt; algorithm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Expected Sarsa in the Cliff World&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;describe&lt;/em&gt; &lt;strong&gt;expected Sarsas&lt;/strong&gt;’s behavior in an example &lt;strong&gt;MDP&lt;/strong&gt; and &lt;em&gt;empirically&lt;/em&gt; compare &lt;strong&gt;expected Sarsa&lt;/strong&gt; and &lt;strong&gt;Sarsa&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Generality of Expected Sarsa&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will &lt;em&gt;understand&lt;/em&gt; how Expected Sarsa can do &lt;strong&gt;off-policy&lt;/strong&gt; learning without using &lt;strong&gt;importance sampling&lt;/strong&gt; and &lt;em&gt;explain&lt;/em&gt; how &lt;strong&gt;Expected Sarsa&lt;/strong&gt; generalizes &lt;strong&gt;Q-learning&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Week 3 summary&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W3_3_summary.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Sarsa uses a sample based version of the Bellman equation. It learns Q-pi.&lt;/p&gt;

&lt;p&gt;Q-learning uses the Bellman optimality equation. It learns Q-star.&lt;/p&gt;

&lt;p&gt;Expected sarsa uses the same Bellman equation as Sarsa, but samples it differently. It takes an expectation over the next action values.&lt;/p&gt;

&lt;p&gt;What’s the story with on-policy and off-policy learning?&lt;/p&gt;

&lt;p&gt;Sarsa is a on-policy algorithm that learns the action values for the policy it’s currently following. Q-learning is an off-policy algorithm that learns the optimal action values. And Expected Sarsa is both an on-policy and an off-policy algorithm that can learn the action values for any policy.&lt;/p&gt;

&lt;h6 id=&quot;assignment-1&quot;&gt;Assignment&lt;/h6&gt;

&lt;p&gt;Q-Learning and Expected Sarsa&lt;/p&gt;

&lt;p&gt;notebooks in &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/tree/main/assignements/course%202%20week%203&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;course-2---week-4---planning-learning--acting&quot;&gt;Course 2 - Week 4 - Planning, Learning &amp;amp; Acting&lt;/h2&gt;

&lt;h6 id=&quot;module-4-learning-objectives&quot;&gt;Module 4 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: What is a model?&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Describe what a model is and how they can be used&lt;/li&gt;
  &lt;li&gt;Classify models as distribution models or sample models&lt;/li&gt;
  &lt;li&gt;Identify when to use a distribution model or sample model&lt;/li&gt;
  &lt;li&gt;Describe the advantages and disadvantages of sample models and distribution models&lt;/li&gt;
  &lt;li&gt;Explain why sample models can be represented more compactly than distribution models&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: Planning&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Explain how planning is used to improve policies&lt;/li&gt;
  &lt;li&gt;Describe random-sample one-step tabular Q-planning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 3: Dyna as a formalism for planning&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Recognize that direct RL updates use experience from the environment to improve a policy or value function&lt;/li&gt;
  &lt;li&gt;Recognize that planning updates use experience from a model to improve a policy or value function&lt;/li&gt;
  &lt;li&gt;Describe how both direct RL and planning updates can be combined through the Dyna architecture&lt;/li&gt;
  &lt;li&gt;Describe the Tabular Dyna-Q algorithm&lt;/li&gt;
  &lt;li&gt;Identify the direct-RL and planning updates in Tabular Dyna-Q&lt;/li&gt;
  &lt;li&gt;Identify the model learning and search control components of Tabular Dyna-Q&lt;/li&gt;
  &lt;li&gt;Describe how learning from both direct and simulated experience impacts performance&lt;/li&gt;
  &lt;li&gt;Describe how simulated experience can be useful when the model is accurate&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 4: Dealing with inaccurate models&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Identify ways in which models can be inaccurate&lt;/li&gt;
  &lt;li&gt;Explain the effects of planning with an inaccurate model&lt;/li&gt;
  &lt;li&gt;Describe how Dyna can plan successfully with a partially inaccurate model&lt;/li&gt;
  &lt;li&gt;Explain how model inaccuracies produce another exploration-exploitation trade-off&lt;/li&gt;
  &lt;li&gt;Describe how Dyna-Q+ proposes a way to address this trade-off&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 5: Course wrap-up&lt;/strong&gt;&lt;/p&gt;

&lt;h6 id=&quot;lesson-1-what-is-a-model&quot;&gt;&lt;strong&gt;Lesson 1: What is a model?&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; Chapter 8.1-8.3 &lt;strong&gt;(pp. 159-166)&lt;/strong&gt;  in the Reinforcement Learning textbook&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Model-based methods rely on planning as their primary component, while model-free methods primarily rely on learning.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Video What is a Model?&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of the video, you will be able to &lt;em&gt;describe&lt;/em&gt; a &lt;strong&gt;model&lt;/strong&gt; and how it can be used, &lt;em&gt;classify&lt;/em&gt; models as &lt;strong&gt;distribution models&lt;/strong&gt; or &lt;strong&gt;sample models&lt;/strong&gt;, and &lt;em&gt;identify&lt;/em&gt; when to use a &lt;strong&gt;distribution model&lt;/strong&gt; or &lt;strong&gt;sample model&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Comparing Sample and Distribution Models&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;describe&lt;/em&gt; the &lt;strong&gt;advantages and disadvantages&lt;/strong&gt; of &lt;strong&gt;sample models&lt;/strong&gt; and &lt;strong&gt;distribution models&lt;/strong&gt;, and you will also be able to &lt;em&gt;explain&lt;/em&gt; why &lt;strong&gt;sample models&lt;/strong&gt; can be represented &lt;strong&gt;more compactly&lt;/strong&gt; than &lt;strong&gt;distribution models&lt;/strong&gt;.&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-planning&quot;&gt;&lt;strong&gt;Lesson 2: Planning&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Random Tabular Q-planning&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;explain&lt;/em&gt; how &lt;strong&gt;planning&lt;/strong&gt; is used to &lt;strong&gt;improve policies&lt;/strong&gt; and &lt;em&gt;describe&lt;/em&gt; &lt;strong&gt;random-sample one-step tabular Q-planning&lt;/strong&gt;.&lt;/p&gt;

&lt;h6 id=&quot;lesson-3-dyna-as-a-formalism-for-planning&quot;&gt;&lt;strong&gt;Lesson 3: Dyna as a formalism for planning&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video The Dyna Architecture&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; how &lt;strong&gt;simulate experience&lt;/strong&gt; from the model differs from &lt;strong&gt;interacting with the environment&lt;/strong&gt;. You will also &lt;em&gt;understand&lt;/em&gt; how the &lt;strong&gt;Dyna architecture&lt;/strong&gt; mixes &lt;strong&gt;direct RL&lt;/strong&gt; updates and &lt;strong&gt;planning&lt;/strong&gt; updates.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W4_1_dyna_arch.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video The Dyna Algorithm&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you should be able to &lt;em&gt;describe&lt;/em&gt; how &lt;strong&gt;Tabular Dyna-Q&lt;/strong&gt; works. You will also be able to &lt;em&gt;identify&lt;/em&gt; the &lt;strong&gt;direct-RL&lt;/strong&gt;, &lt;strong&gt;planning&lt;/strong&gt; updates in &lt;strong&gt;Tabular Dyna-Q&lt;/strong&gt;, and identify the &lt;strong&gt;model learning&lt;/strong&gt; and &lt;strong&gt;search control&lt;/strong&gt; components of &lt;strong&gt;Tabular Dyna-Q&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W4_2_dyna_algo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Dyna &amp;amp; Q-learning in a Simple Maze&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video you will be able to &lt;em&gt;describe&lt;/em&gt; how learning from both &lt;strong&gt;environment-real&lt;/strong&gt; and &lt;strong&gt;model&lt;/strong&gt; experience impacts performance. You will also be able to &lt;em&gt;explain&lt;/em&gt; how an &lt;strong&gt;accurate model&lt;/strong&gt; allows the agent to learn from &lt;strong&gt;fewer environment interactions&lt;/strong&gt;.&lt;/p&gt;

&lt;h6 id=&quot;lesson-4-dealing-with-inaccurate-models&quot;&gt;&lt;strong&gt;Lesson 4: Dealing with inaccurate models&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video What if the model is inaccurate?&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video you will be able to &lt;em&gt;identify&lt;/em&gt; ways in which &lt;strong&gt;models&lt;/strong&gt; can be &lt;strong&gt;inaccurate&lt;/strong&gt;, &lt;em&gt;explain&lt;/em&gt; the effects of &lt;strong&gt;planning&lt;/strong&gt; with an &lt;strong&gt;inaccurate model&lt;/strong&gt;, and &lt;em&gt;describe&lt;/em&gt; how &lt;strong&gt;Dyna&lt;/strong&gt; can plan  successfully with an &lt;strong&gt;incomplete model&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video In-depth with changing environments&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;explain&lt;/em&gt; how model inaccuracies produce another &lt;strong&gt;exploration-exploitation trade-off&lt;/strong&gt;, and &lt;em&gt;describe&lt;/em&gt; how &lt;strong&gt;Dyna-Q+&lt;/strong&gt; addresses this trade-off.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W4_3_dyna_q_plus_algo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Video Drew Bagnell: &lt;strong&gt;self-driving, robotics, and Model Based RL&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video week 4 summary&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;h6 id=&quot;assignment-2&quot;&gt;Assignment&lt;/h6&gt;

&lt;p&gt;Dyna-Q and Dyna-Q+&lt;/p&gt;

&lt;p&gt;notebooks in  &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/tree/main/assignements/course%202%20week%204&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chapter summary &lt;strong&gt;Chapter 8.12 (pp. 188)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C2W4_4_planning_learning.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Planning, acting, and model-learning interact in a circular fashion (as in
the figure above), each producing what the other needs to improve; no other
interaction among them is either required or prohibited.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;h1 id=&quot;text-book-part-1-summary&quot;&gt;Text Book Part 1 Summary&lt;/h1&gt;

  &lt;hr /&gt;

  &lt;p&gt;For a summary of what we’ve covered in the specialization so far, read: &lt;strong&gt;pp. 189-191&lt;/strong&gt; in Reinforcement Learning: an introduction .&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;All of the methods we have explored so far in this book have three key ideas in common:
first, they all seek to estimate value functions; second, they all operate by backing up
values along actual or possible state trajectories; and third, they all follow the general
strategy of generalized policy iteration (GPI), meaning that they maintain an approximate
value function and an approximate policy, and they continually try to improve each on the
basis of the other. These three ideas are central to the subjects covered in this book. We
suggest that value functions, backing up value updates, and GPI are powerful organizing
principles potentially relevant to any model of intelligence, whether artificial or natural.&lt;/p&gt;

&lt;h6 id=&quot;course-wrap-up&quot;&gt;Course wrap-up&lt;/h6&gt;</content><author><name></name></author><category term="reinforcement learning" /><category term="deepmind" /><summary type="html">Coursera website: course 2 - Sample-based Learning Methods of Reinforcement Learning Specialization</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://castorfou.github.io/guillaume_blog/images/RL.png" /><media:content medium="image" url="https://castorfou.github.io/guillaume_blog/images/RL.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Machine learning in python with scikit-learn</title><link href="https://castorfou.github.io/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn.html" rel="alternate" type="text/html" title="Machine learning in python with scikit-learn" /><published>2021-05-21T00:00:00-05:00</published><updated>2021-05-21T00:00:00-05:00</updated><id>https://castorfou.github.io/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn</id><content type="html" xml:base="https://castorfou.github.io/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn.html">&lt;p&gt;This is a &lt;a href=&quot;https://lms.fun-mooc.fr/courses/course-v1:inria+41026+session01/info&quot;&gt;MOOC&lt;/a&gt; by Inria team, in charge of scikit-learn.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;After a fair amount of pedagogical and technical preparation work, we offer you today a practical course with:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;7 modules + 1 introductory module&lt;/li&gt;
    &lt;li&gt;9 video lessons to explain the main machine learning concepts&lt;/li&gt;
    &lt;li&gt;71 programming notebooks (you don’t have to install anything) to get hands-on skills&lt;/li&gt;
    &lt;li&gt;27 quizzes, 7 wrap-up quizzes and 23 exercises to train and deepen your practice&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://lms.fun-mooc.fr/courses/course-v1:inria+41026+session01/496272d6f8444957a7014122a4646116/&quot;&gt;Syllabus&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Introduction:  Machine Learning concepts, then&lt;/p&gt;

&lt;p&gt;Module 1. The Predictive Modeling Pipeline&lt;/p&gt;

&lt;p&gt;Module 2. Selecting the best model&lt;/p&gt;

&lt;p&gt;Module 3. Hyperparameter tuning&lt;/p&gt;

&lt;p&gt;Module 4. Linear Models&lt;/p&gt;

&lt;p&gt;Module 5. Decision tree models&lt;/p&gt;

&lt;p&gt;Module 6. Ensemble of models&lt;/p&gt;

&lt;p&gt;Module 7. Evaluating model performance&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/INRIA/scikit-learn-mooc&quot;&gt;INRIA github&lt;/a&gt; contains everything of this mooc: slides, datasets, notebooks (not videos)&lt;/p&gt;

&lt;p&gt;I have forked it, and I use local envt for assignments.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;~/git/guillaume&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git clone git@github.com:castorfou/scikit-learn-mooc.git
~/git/guillaume&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;scikit-learn-mooc/
~/git/guillaume/scikit-learn-mooc&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda &lt;span class=&quot;nb&quot;&gt;env &lt;/span&gt;create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; environment.yml
conda activate scikit-learn-course
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;introduction---machine-learning-concepts&quot;&gt;Introduction - Machine Learning concepts&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://inria.github.io/scikit-learn-mooc/slides/?file=ml_concepts.md#1&quot;&gt;slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;module-1-the-predictive-modeling-pipeline&quot;&gt;Module 1. The Predictive Modeling Pipeline&lt;/h2&gt;

&lt;h6 id=&quot;tabular-data-exploration&quot;&gt;Tabular data exploration&lt;/h6&gt;

&lt;p&gt;exploration of data: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/01_tabular_data_exploration.ipynb&quot;&gt;01_tabular_data_exploration.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;exercise M1.01: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/01_tabular_data_exploration_ex_01.ipynb&quot;&gt;01_tabular_data_exploration_ex_01.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;fitting-a-scikit-learn-model-on-numerical-data&quot;&gt;Fitting a scikit-learn model on numerical data&lt;/h6&gt;

&lt;p&gt;first model with scikit-learn: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/02_numerical_pipeline_introduction.ipynb&quot;&gt;02_numerical_pipeline_introduction.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;exercise M1.02: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/02_numerical_pipeline_ex_00.ipynb&quot;&gt;02_numerical_pipeline_ex_00.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;working with numerical data: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/02_numerical_pipeline_hands_on.ipynb&quot;&gt;02_numerical_pipeline_hands_on.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;exercise M1.03: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/02_numerical_pipeline_ex_01.ipynb&quot;&gt;02_numerical_pipeline_ex_01.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;preprocessing for numerical features: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/02_numerical_pipeline_scaling.ipynb&quot;&gt;02_numerical_pipeline_scaling.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;handling-categorical-data&quot;&gt;Handling categorical data&lt;/h6&gt;

&lt;p&gt;Encoding of categorical variables: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/03_categorical_pipeline.ipynb&quot;&gt;03_categorical_pipeline.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Thus, in general &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OneHotEncoder&lt;/code&gt; is the encoding strategy used when the downstream models are &lt;strong&gt;linear models&lt;/strong&gt; while &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OrdinalEncoder&lt;/code&gt; is used with &lt;strong&gt;tree-based models&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Exercise M1.04: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/03_categorical_pipeline_ex_01.ipynb&quot;&gt;03_categorical_pipeline_ex_01.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Using numerical and categorical variables together: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/03_categorical_pipeline_column_transformer.ipynb&quot;&gt;03_categorical_pipeline_column_transformer.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Exercise M1.05: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/03_categorical_pipeline_ex_02.ipynb&quot;&gt;03_categorical_pipeline_ex_02.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;wrap-up-quiz&quot;&gt;Wrap-up quiz&lt;/h6&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/jupyter-book/predictive_modeling_pipeline/module%201%20-%20wrap-up%20quizz.ipynb&quot;&gt;module 1 - wrap-up quizz.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;module-2-selecting-the-best-model&quot;&gt;Module 2. Selecting the best model&lt;/h2&gt;

&lt;h6 id=&quot;overfitting-and-underfitting&quot;&gt;Overfitting and Underfitting&lt;/h6&gt;

&lt;p&gt;video and &lt;a href=&quot;https://inria.github.io/scikit-learn-mooc/slides/?file=overfitting_vs_underfitting.md#1&quot;&gt;slides&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The framework and why do we need it: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/cross_validation_train_test.ipynb&quot;&gt;cross_validation_train_test.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;validation-and-learning-curves&quot;&gt;Validation and learning curves&lt;/h6&gt;

&lt;p&gt;video and &lt;a href=&quot;https://inria.github.io/scikit-learn-mooc/slides/?file=learning_validation_curves.md#1&quot;&gt;slides&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Overfit-generalization-underfit: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/cross_validation_validation_curve.ipynb&quot;&gt;cross_validation_validation_curve.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Effect of the sample size in cross-validation: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/cross_validation_learning_curve.ipynb&quot;&gt;cross_validation_learning_curve.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Exercise M2.01: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/cross_validation_ex_01.ipynb&quot;&gt;cross_validation_ex_01.ipynb&lt;/a&gt; &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/cross_validation_sol_01.ipynb&quot;&gt;solution&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;bias-versus-variance-trade-off&quot;&gt;Bias versus variance trade-off&lt;/h6&gt;

&lt;p&gt;video and &lt;a href=&quot;https://inria.github.io/scikit-learn-mooc/slides/?file=bias_vs_variance.md#1&quot;&gt;slides&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/sklearn_bias_variance.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;wrap-up-quiz-1&quot;&gt;Wrap-up quiz&lt;/h6&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/jupyter-book/overfit/overfit_wrap_up_quiz.ipynb&quot;&gt;module 2 - wrap-up quizz.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;Overfitting&lt;/strong&gt; is caused by the &lt;strong&gt;limited size of the training set&lt;/strong&gt;, the &lt;strong&gt;noise&lt;/strong&gt; in the data, and the &lt;strong&gt;high flexibility&lt;/strong&gt; of common machine learning models.&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Underfitting&lt;/strong&gt; happens when the learnt prediction functions suffer from &lt;strong&gt;systematic errors&lt;/strong&gt;. This can be caused by a choice of model family and parameters, which leads to a &lt;strong&gt;lack of flexibility&lt;/strong&gt; to capture the repeatable structure of the true data generating process.&lt;/li&gt;
    &lt;li&gt;For a fixed training set, the objective is to &lt;strong&gt;minimize the test error&lt;/strong&gt; by adjusting the model family and its parameters to find the &lt;strong&gt;best trade-off between overfitting for underfitting&lt;/strong&gt;.&lt;/li&gt;
    &lt;li&gt;For a given choice of model family and parameters, &lt;strong&gt;increasing the training set size will decrease overfitting&lt;/strong&gt; but can also cause an increase of underfitting.&lt;/li&gt;
    &lt;li&gt;The test error of a model that is neither overfitting nor underfitting can still be high if the variations of the target variable cannot be fully determined by the input features. This irreducible error is caused by what we sometimes call label noise. In practice, this often happens when we do not have access to important features for one reason or another.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;module-3-hyperparameter-tuning&quot;&gt;Module 3. Hyperparameter tuning&lt;/h2&gt;

&lt;h6 id=&quot;manual-tuning&quot;&gt;Manual tuning&lt;/h6&gt;

&lt;p&gt;Set and get hyperparameters in scikit-learn: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/parameter_tuning_manual.ipynb&quot;&gt;parameter_tuning_manual.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Exercise M3.01: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/parameter_tuning_ex_02.ipynb&quot;&gt;parameter_tuning_ex_02.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;automated-tuning&quot;&gt;Automated tuning&lt;/h6&gt;

&lt;p&gt;Hyperparameter tuning by grid-search: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/parameter_tuning_grid_search.ipynb&quot;&gt;parameter_tuning_grid_search.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hyperparameter tuning by randomized-search: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/parameter_tuning_randomized_search.ipynb&quot;&gt;parameter_tuning_randomized_search.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Cross-validation and hyperparameter tuning: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/parameter_tuning_nested.ipynb&quot;&gt;parameter_tuning_nested.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Exercise M3.01: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/parameter_tuning_ex_03.ipynb&quot;&gt;parameter_tuning_ex_03.ipynb&lt;/a&gt; &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/parameter_tuning_sol_03.ipynb&quot;&gt;solution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/sklearn_plotly_parallel_ccordinates.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Nice to play with interactive plotly parallel_coordinates to identify best params.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plotly.express&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;px&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shorten_param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rsplit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_name&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cv_results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;../figures/randomized_search_results.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                         &lt;span class=&quot;n&quot;&gt;index_col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parallel_coordinates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cv_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shorten_param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;learning_rate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;max_leaf_nodes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;max_bins&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;min_samples_leaf&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;l2_regularization&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;mean_test_score&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mean_test_score&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;color_continuous_scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Viridis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h6 id=&quot;wrap-up-quiz-2&quot;&gt;Wrap-up quiz&lt;/h6&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/jupyter-book/tuning/tuning_questions.ipynb&quot;&gt;module 3 - wrap-up quizz.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Hyperparameters have an impact on the models’ performance and should be wisely chosen;&lt;/li&gt;
    &lt;li&gt;The search for the best hyperparameters can be automated with a grid-search approach or a randomized search approach;&lt;/li&gt;
    &lt;li&gt;A grid-search is expensive and does not scale when the number of hyperparameters to optimize increase. Besides, the combination are sampled only on a regular grid.&lt;/li&gt;
    &lt;li&gt;A randomized-search allows a search with a fixed budget even with an increasing number of hyperparameters. Besides, the combination are sampled on a non-regular grid.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;module-4-linear-models&quot;&gt;Module 4. Linear models&lt;/h2&gt;

&lt;h6 id=&quot;intuitions-on-linear-models&quot;&gt;Intuitions on linear models&lt;/h6&gt;

&lt;p&gt;video and &lt;a href=&quot;https://inria.github.io/scikit-learn-mooc/slides/?file=linear_models.md#1&quot;&gt;slides&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For regression: linear regression&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearRegression&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;linear_regression&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;linear_regression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For classification: logistic regression&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;log_reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;log_reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h6 id=&quot;linear-regression&quot;&gt;Linear regression&lt;/h6&gt;

&lt;p&gt;Linear regression without scikit-learn: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_regression_without_sklearn.ipynb&quot;&gt;linear_regression_without_sklearn.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Exercise M4.01: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_ex_01.ipynb&quot;&gt;linear_models_ex_01.ipynb&lt;/a&gt; &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_sol_01.ipynb&quot;&gt;solution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;usage of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;np.ravel&lt;/code&gt; in&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;goodness_fit_measure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# we compute the error between the true values and the predictions of our model
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Linear regression using scjkit-learn: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_regression_in_sklearn.ipynb&quot;&gt;linear_regression_in_sklearn.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;inferred_body_mass&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_regression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inferred_body_mass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;The mean squared error of the optimal model is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h6 id=&quot;modeling-non-linear-features-target-relationships&quot;&gt;Modeling non-linear features-target relationships&lt;/h6&gt;

&lt;p&gt;Exercise M4.02: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_ex_02.ipynb&quot;&gt;linear_models_ex_02.ipynb&lt;/a&gt; &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_sol_02.ipynb&quot;&gt;solution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Linear regression with non-linear link between data and target: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_regression_non_linear_link.ipynb&quot;&gt;linear_regression_non_linear_link.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Exercise M4.03: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_ex_03.ipynb&quot;&gt;linear_models_ex_03.ipynb&lt;/a&gt; &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_sol_03.ipynb&quot;&gt;solution&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;regularization-in-linear-model&quot;&gt;Regularization in linear model&lt;/h6&gt;

&lt;p&gt;video and &lt;a href=&quot;https://inria.github.io/scikit-learn-mooc/slides/?file=regularized_linear_models.md#1&quot;&gt;slides&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ridge regression&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ridge&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ridge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;always use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ridge&lt;/code&gt; with a carefully tuned &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alpha&lt;/code&gt;!&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RidgeCV&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RidgeCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alphas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Regularization of linear regression model: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_regularization.ipynb&quot;&gt;linear_models_regularization.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Exercise M4.04: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_ex_04.ipynb&quot;&gt;linear_models_ex_04.ipynb&lt;/a&gt; &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_sol_04.ipynb&quot;&gt;solution&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;linear-model-for-classification&quot;&gt;Linear model for classification&lt;/h6&gt;

&lt;p&gt;Linear model for classification: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/logistic_regression.ipynb&quot;&gt;logistic_regression.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Exercise M4.05: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_ex_04.ipynb&quot;&gt;linear_models_ex_05.ipynb&lt;/a&gt; &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/linear_models_sol_05.ipynb&quot;&gt;solution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Beyond linear separation in classification: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/logistic_regression_non_linear.ipynb&quot;&gt;logistic_regression_non_linear.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;wrap-up-quiz-3&quot;&gt;Wrap-up quiz&lt;/h6&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/jupyter-book/linear_models/module 4 - wrap-up-quizz.ipynb&quot;&gt;module 4 - wrap-up quizz.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In this module, we saw that:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;the predictions of a linear model depend on a weighted sum of the values of the input features added to an intercept parameter;&lt;/li&gt;
    &lt;li&gt;fitting a linear model consists in adjusting both the weight coefficients and the intercept to minimize the prediction errors on the training set;&lt;/li&gt;
    &lt;li&gt;to train linear models successfully it is often required to scale the input features approximately to the same dynamic range;&lt;/li&gt;
    &lt;li&gt;regularization can be used to reduce over-fitting: weight coefficients are constrained to stay small when fitting;&lt;/li&gt;
    &lt;li&gt;the regularization hyperparameter needs to be fine-tuned by cross-validation for each new machine learning problem and dataset;&lt;/li&gt;
    &lt;li&gt;linear models can be used on problems where the target variable is not linearly related to the input features but this requires extra feature engineering work to transform the data in order to avoid under-fitting.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;module-5-decision-tree-models&quot;&gt;Module 5. Decision tree models&lt;/h2&gt;

&lt;h6 id=&quot;intuitions-on-tree-based-models&quot;&gt;Intuitions on tree-based models&lt;/h6&gt;

&lt;p&gt;video and &lt;a href=&quot;https://inria.github.io/scikit-learn-mooc/slides/?file=trees.md#1&quot;&gt;slides&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;decision-tree-in-classification&quot;&gt;Decision tree in classification&lt;/h6&gt;

&lt;p&gt;Build a classification decision tree: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/trees_classification.ipynb&quot;&gt;trees_classification.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Exercise M5.01: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/trees_ex_01.ipynb&quot;&gt;trees_ex_01.ipynb&lt;/a&gt; &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/trees_sol_01.ipynb&quot;&gt;solution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Fit and decision boundaries&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.tree&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;seaborn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create a palette to be used in the scatterplot
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tab:red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;tab:blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;black&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatterplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;penguins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;culmen_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;culmen_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_decision_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox_to_anchor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'upper left'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Decision boundary using a decision tree&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Decision tree&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.tree&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plot_tree&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plot_tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feature_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;culmen_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;impurity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Accuracy&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;Accuracy of the DecisionTreeClassifier: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h6 id=&quot;decision-tree-in-regression&quot;&gt;Decision tree in regression&lt;/h6&gt;

&lt;p&gt;Decision tree for regression: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/trees_regression.ipynb&quot;&gt;trees_regression.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Exercise M5.02: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/trees_ex_02.ipynb&quot;&gt;trees_ex_02.ipynb&lt;/a&gt; &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/trees_sol_02.ipynb&quot;&gt;solution&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;hyperparameters-of-decision-tree&quot;&gt;Hyperparameters of decision tree&lt;/h6&gt;

&lt;p&gt;Importance of decision tree hyperparameters on generalization: &lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/notebooks/trees_hyperparameters.ipynb&quot;&gt;trees_hyperparameters.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;wrap-up-quiz-4&quot;&gt;Wrap-up quiz&lt;/h6&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/castorfou/scikit-learn-mooc/blob/master/jupyter-book/trees/module 5 - wrap-up-quizz.ipynb&quot;&gt;module 5 - wrap-up quizz.ipynb&lt;/a&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[Main take-away&lt;/td&gt;
      &lt;td&gt;Main take-away&lt;/td&gt;
      &lt;td&gt;41026 Courseware&lt;/td&gt;
      &lt;td&gt;FUN-MOOC](https://lms.fun-mooc.fr/courses/course-v1:inria+41026+session01/courseware/6565c007789a4812aea0debb1fb22e0f/0ab58cb806034cdba7bd49e8dd784202/)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;In this module, we presented decision trees in details. We saw that they:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;are suited for both regression and classification problems;&lt;/li&gt;
    &lt;li&gt;are non-parametric models;&lt;/li&gt;
    &lt;li&gt;are not able to extrapolate;&lt;/li&gt;
    &lt;li&gt;are sensible to hyperparameter tuning.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="machine learning" /><category term="scikit-learn" /><summary type="html">This is a MOOC by Inria team, in charge of scikit-learn.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/langfr-220px-Scikit_learn_logo_small.svg.png" /><media:content medium="image" url="https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/langfr-220px-Scikit_learn_logo_small.svg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Reinforcement Learning Specialization - Coursera - course 1 - Fundamentals of Reinforcement Learning</title><link href="https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html" rel="alternate" type="text/html" title="Reinforcement Learning Specialization - Coursera - course 1 - Fundamentals of Reinforcement Learning" /><published>2021-05-03T00:00:00-05:00</published><updated>2021-05-03T00:00:00-05:00</updated><id>https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera</id><content type="html" xml:base="https://castorfou.github.io/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html">&lt;p&gt;Coursera website:  &lt;a href=&quot;https://www.coursera.org/learn/fundamentals-of-reinforcement-learning/home/welcome&quot;&gt;course 1 - Fundamentals of Reinforcement Learning&lt;/a&gt; of &lt;a href=&quot;https://www.coursera.org/specializations/reinforcement-learning&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;my notes on &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html&quot;&gt;course 2 - Sample-based Learning Methods&lt;/a&gt;, &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course3.html&quot;&gt;course 3 - Prediction and Control with Function Approximation&lt;/a&gt;, &lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course4.html&quot;&gt;course 4 - A Complete Reinforcement Learning System (Capstone)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.coursera.org/specializations/reinforcement-learning&quot;&gt;Syllabus&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;4 courses on 16 weeks by Martha White and Adam White.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.coursera.org/learn/fundamentals-of-reinforcement-learning?specialization=reinforcement-learning&quot;&gt;Fundamentals of Reinforcement Learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.coursera.org/learn/sample-based-learning-methods?specialization=reinforcement-learning&quot;&gt;Sample-based Learning Methods&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.coursera.org/learn/prediction-control-function-approximation?specialization=reinforcement-learning&quot;&gt;Prediction and Control with Function Approximation&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.coursera.org/learn/complete-reinforcement-learning-system?specialization=reinforcement-learning&quot;&gt;A Complete Reinforcement Learning System (Capstone)&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;specialization roadmap&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;course 1&lt;/strong&gt; - we begin our study with multi-arm bandit problems. Here, we get our first taste of the complexities of &lt;strong&gt;incremental learning&lt;/strong&gt;, &lt;strong&gt;exploration&lt;/strong&gt;, and &lt;strong&gt;exploitation&lt;/strong&gt;. After that, we move onto &lt;strong&gt;Markov decision processes&lt;/strong&gt; to broaden the class of problems we can solve with reinforcement learning methods. Here we will learn about &lt;strong&gt;balancing short-term and long-term reward&lt;/strong&gt;. We will introduce key ideas like &lt;strong&gt;policies&lt;/strong&gt; and &lt;strong&gt;value functions&lt;/strong&gt; using almost all RL systems. We conclude Course 1 with classic planning methods called &lt;strong&gt;dynamic programming&lt;/strong&gt;. These methods have been used in large industrial control problems and can compute optimal policies given a complete model of the world.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;course 2&lt;/strong&gt; - In Course 2, we built on these ideas and design algorithms for learning &lt;strong&gt;without a model&lt;/strong&gt; of the world. We study three classes of methods designed for learning from trial and error interaction. We start with &lt;strong&gt;Monte Carlo&lt;/strong&gt; methods and then move on to &lt;strong&gt;temporal difference&lt;/strong&gt; learning, including Q learning. We conclude Course 2 with an investigation of methods for &lt;strong&gt;planning&lt;/strong&gt; with learned models.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;course 3&lt;/strong&gt; - In Course 3, we leave the relative comfort of small finite MDPs and investigate RL with &lt;strong&gt;function approximation&lt;/strong&gt;. Here we will see that the main concepts from Courses 1 and 2 transferred to problems with larger &lt;strong&gt;infinite state spaces&lt;/strong&gt;. We will cover &lt;strong&gt;feature construction&lt;/strong&gt;, &lt;strong&gt;neural network learning&lt;/strong&gt;, &lt;strong&gt;policy gradient methods&lt;/strong&gt;, and other particularities of the function approximation setting.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;course 4&lt;/strong&gt; - The final course in this specialization brings everything together in a Capstone project. Throughout this specialization, as in Rich and Andy’s book, we stress a rigorous and scientific approach to RL. We conduct numerous experiments designed to carefully compare algorithms. It takes careful planning and a lot of hard work to produce a meaningful empirical results. In the Capstone, we will walk you through each step of this process so that you can conduct your own scientific experiment. We will explore all the stages from problem specification, all the way to publication quality plots. This is not just academic. In real problems, it’s important to verify and understand your system. After that, you should be ready to test your own new ideas or tackle a new exciting application of RL in your job. We hope you enjoyed the show half as much as we enjoyed making it for you.&lt;/p&gt;

&lt;p&gt;Alberta is in Canada.&lt;/p&gt;

&lt;h2 id=&quot;5321---course-1---week-1---an-introduction-to-sequential-decision-making&quot;&gt;5/3/21 - Course 1 - Week 1 - An introduction to Sequential Decision-Making&lt;/h2&gt;

&lt;p&gt;I have set recommended goals 3 times a week.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;about supervised learning, unsupervised learning and RL&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;You might wonder what’s the difference between supervised learning, unsupervised learning, and reinforcement learning? The differences are quite simple. In supervised learning we assume the learner has access to labeled examples giving the correct answer. In RL, the reward gives the agent some idea of how good or bad its recent actions were. You can think of supervised learning as requiring a teacher that helps you by telling you the correct answer. A reward on the other hand, is like having someone who can identify what good behavior looks like but can’t tell you exactly how to do it. Unsupervised learning sounds like it could be related but really has a very different goal. Unsupervised learning is about extracting underlying structure in data. It’s about the data representation. It can be used to construct representations that make a supervised or RL system better. In fact, as you’ll see later in this course, techniques from both supervised learning and unsupervised learning can be used within RL to aid generalization&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;industrial control&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So I think the place we’re really going to see it take off is an industrial control. In industrial control, we have experts that are really looking for ways to improve the optimal- how well their systems work. So we’re going to see it do things like reduce energy costs or save on other types of costs that we have in these industrial control systems. In the hands of experts, we can really make these algorithms work well in the near future. So I really see it as a tool that’s going to facilitate experts in their work rather than say, doing something like replacing people or automating them away.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reinforcement Learning Textbook&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;as always, &lt;strong&gt;Reinforcement Learning: An introduction (Second Edition) by Richard S. Sutton and Andrew G. Barto&lt;/strong&gt; is THE reference. I didn’t know that Adam White was student from Sutton. Lucky guy ;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;K-armed Bandit problem&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/640/1*Ahv2hWGCZiwTDQX5TIiUjw.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Starts with reading of RLbook p25-36 (Chapter 2 Multi-armed Bandits)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://incompleteideas.net/book/first/ebook/node14.html&quot;&gt;Evaluative&lt;/a&gt; vs instructive feedback. Nonassociative refers to cases where you take one action per state. At the end there is a generalization where bandit problem becomes associative, that is, when actions are taken in more than one situation.&lt;/p&gt;

&lt;p&gt;It is a stationary case meaning that value of actions are fixed during experiences. If the bandit task were nonstationary, that is, the true values of the actions changed over time. In this case exploration is needed even in the deterministic case to make sure one of the nongreedy actions has not changed to become better than the greedy one.&lt;/p&gt;

&lt;p&gt;sample-average action-value estimates&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mtext&gt;sum of rewards when &lt;/mtext&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mtext&gt; taken prior to &lt;/mtext&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mtext&gt;number of times &lt;/mtext&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mtext&gt; taken prior to &lt;/mtext&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mspace linebreak=&quot;newline&quot;&gt;&lt;/mspace&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mn mathvariant=&quot;script&quot;&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mstyle&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msub&gt;&lt;mn mathvariant=&quot;script&quot;&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mstyle&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;Q_t(a) = \frac{\text{sum of rewards when } \mathit{a} \text{ taken prior to }\mathit{t}}{\text{number of times } \mathit{a} \text{ taken prior to }\mathit{t}} \\
Q_t(a)  = \frac{\displaystyle\sum_{i=1}^{t-1} R_i.\mathcal{1}_{A_i=a}}{\displaystyle\sum_{i=1}^{t-1} \mathcal{1}_{A_i=a}}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.25188em;vertical-align:-0.8804400000000001em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.3714399999999998em;&quot;&gt;&lt;span style=&quot;top:-2.314em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord&quot;&gt;number of times &lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord&quot;&gt; taken prior to &lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.677em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord&quot;&gt;sum of rewards when &lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord&quot;&gt; taken prior to &lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8804400000000001em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace newline&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:6.437564000000001em;vertical-align:-2.9687820000000005em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:3.4687820000000005em;&quot;&gt;&lt;span style=&quot;top:-2.11em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.8011130000000004em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.8011130000000004em;&quot;&gt;&lt;span style=&quot;top:-1.872331em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;mrel mtight&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.050005em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-4.300005em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.277669em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathcal&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.32833099999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.3280857142857143em;&quot;&gt;&lt;span style=&quot;top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size3 size1 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.143em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mrel mtight&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2501em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-4.031113em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.8011130000000004em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-5.468782000000001em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.8011130000000004em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.8011130000000004em;&quot;&gt;&lt;span style=&quot;top:-1.872331em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;mrel mtight&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.050005em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-4.300005em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.277669em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.31166399999999994em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathcal&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.32833099999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.3280857142857143em;&quot;&gt;&lt;span style=&quot;top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size3 size1 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.143em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mrel mtight&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2501em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:2.9687820000000005em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;$\epsilon$-greedy action selection&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;&lt;munder&gt;&lt;mo&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;r&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;m&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/munder&gt;&lt;/mi&gt;&lt;mrow&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;A_t=\underset{a}{\mathrm{argmax}}{\text{ }Q_t(a)}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.83333em;vertical-align:-0.15em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.64444em;vertical-align:-0.89444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.43055999999999994em;&quot;&gt;&lt;span style=&quot;top:-2.20556em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot; style=&quot;margin-right:0.01389em;&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.89444em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;With nonstationary problem, we want to give more weights to recent rewards. It can be done with
&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;Q_{n+1}=Q_n+\alpha[R_n-Q_n]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.891661em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8777699999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.0037em;&quot;&gt;α&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
Where &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\alpha&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.0037em;&quot;&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is a constant step-size parameter, &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\alpha \in [0,1]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.5782em;vertical-align:-0.0391em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.0037em;&quot;&gt;α&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;∈&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. So it can be written that way
&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/munderover&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;Q_{n+1}=(1-\alpha)^nQ_1+\displaystyle\sum_{i=1}^{n} \alpha(1-\alpha)^{n-i}R_i&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.891661em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.0037em;&quot;&gt;α&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.664392em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.929066em;vertical-align:-1.277669em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.6513970000000002em;&quot;&gt;&lt;span style=&quot;top:-1.872331em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;mrel mtight&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.050005em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-4.3000050000000005em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.277669em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.0037em;&quot;&gt;α&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.124664em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.0037em;&quot;&gt;α&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.874664em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.31166399999999994em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
. Weighted average because the sum of the weights is 1.&lt;/p&gt;

&lt;p&gt;2 other topics are discussed: &lt;strong&gt;optimistic initial values&lt;/strong&gt; (that can push exploration in 1st steps) and &lt;strong&gt;upper-confidence-bound (UCB)&lt;/strong&gt; action selection. With optimistic initial values the idea is too have high initial value for reward so that the 1st actions are disappointing pushing for explorations. With UCB&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;&lt;munder&gt;&lt;mo&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;r&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;g&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;m&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/munder&gt;&lt;/mi&gt;&lt;mrow&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mo fence=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;msqrt&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;ln&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/msqrt&gt;&lt;mo fence=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;A_t= \underset{a} {\mathrm{argmax}} {\text{ }\bigg[Q_t(a)+c\sqrt{\frac{\ln t}{N_t(a)}}\bigg]}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.83333em;vertical-align:-0.15em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:3.04em;vertical-align:-1.188405em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.43055999999999994em;&quot;&gt;&lt;span style=&quot;top:-2.20556em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot; style=&quot;margin-right:0.01389em;&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.89444em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;delimsizing size3&quot;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mord sqrt&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.851595em;&quot;&gt;&lt;span class=&quot;svg-align&quot; style=&quot;top:-5em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot; style=&quot;padding-left:1em;&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.37144em;&quot;&gt;&lt;span style=&quot;top:-2.314em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10903em;&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.677em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mop&quot;&gt;ln&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.936em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.811595em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;hide-tail&quot; style=&quot;min-width:1.02em;height:3.08em;&quot;&gt;&lt;svg width='400em' height='3.08em' viewBox='0 0 400000 3240' preserveAspectRatio='xMinYMin slice'&gt;&lt;path d='M473,2793
c339.3,-1799.3,509.3,-2700,510,-2702 l0 -0
c3.3,-7.3,9.3,-11,18,-11 H400000v40H1017.7
s-90.5,478,-276.2,1466c-185.7,988,-279.5,1483,-281.5,1485c-2,6,-10,9,-24,9
c-8,0,-12,-0.7,-12,-2c0,-1.3,-5.3,-32,-16,-92c-50.7,-293.3,-119.7,-693.3,-207,-1200
c0,-1.3,-5.3,8.7,-16,30c-10.7,21.3,-21.3,42.7,-32,64s-16,33,-16,33s-26,-26,-26,-26
s76,-153,76,-153s77,-151,77,-151c0.7,0.7,35.7,202,105,604c67.3,400.7,102,602.7,104,
606zM1001 80h400000v40H1017.7z'/&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.188405em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;delimsizing size3&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;blockquote&gt;
  &lt;p&gt;The idea of this upper confidence bound (UCB) action selection is that the square-root term is a measure of the uncertainty or variance in the estimate of a’s value. The quantity being max’ed over is thus a sort of upper bound on the possible true value of action a, with c determining the confidence level. Each time a is selected the uncertainty is presumably reduced: N t (a) increments, and, as it appears in the denominator, the uncertainty term decreases. On the other hand, each time an action other than a is selected, t increases but N t (a) does not; because t appears in the numerator, the uncertainty estimate increases. The use of the natural logarithm means that the increases get smaller over time, but are unbounded; all actions will eventually be selected, but actions with lower value estimates, or that have already been selected frequently, will be selected with decreasing frequency over time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Exploration vs Exploitation trade-off&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;How do we choose when to explore, and when to exploit? Randomly&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/alberta_rl_epsilon_greedy.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Assignement&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;implementation of greedy agent, $\epsilon$-greedy agent. Comparisons. Various $\epsilon$ values, various step-sizes (1/N(a), …)&lt;/p&gt;

&lt;p&gt;notebooks in &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/tree/main/assignements/course%201%20week%201&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;end of C1W1 (course 1 week 1)&lt;/p&gt;

&lt;h2 id=&quot;5721---course-1---week-2---markov-decision-process&quot;&gt;5/7/21 - Course 1 - Week 2 - Markov Decision Process&lt;/h2&gt;

&lt;h6 id=&quot;module-2-learning-objectives&quot;&gt;Module 2 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: Introduction to Markov Decision Processes&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Understand Markov Decision Processes, or MDPs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Describe how the dynamics of an MDP are defined&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understand the graphical representation of a Markov Decision Process&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Explain how many diverse processes can be written in terms of the MDP framework&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: Goal of Reinforcement Learning&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Describe how rewards relate to the goal of an agent&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understand episodes and identify episodic tasks&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 3: Continuing Tasks&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Formulate returns for continuing tasks using discounting&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Describe how returns at successive time steps are related to each other&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understand when to formalize a task as episodic or continuing&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lesson-1-introduction-to-markov-decision-processes&quot;&gt;Lesson 1: Introduction to Markov Decision Processes&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; chapter 3.1 to 3.3 (p47-56) in Sutton’s book&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Finite Markov Decision Processes&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;3.1 - the Agent-Environment Interface&lt;/li&gt;
  &lt;li&gt;3.2 - Goals and Rewards&lt;/li&gt;
  &lt;li&gt;3.3 - Returns and Episodes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In a Markov decision process, the probabilities given by p completely characterize the environment’s dynamics. That is, the probability of each possible value for $S_t$ and  $R_t$ depends only on the immediately preceding state and action, $S_{t-1}$ and $A_{t-1}$ , and, given them, not at all on earlier states and actions.&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;≐&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;{&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;}&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;p(s&amp;#x27;,r|s,a) \doteq Pr\{S_t=s&amp;#x27;, R_t=r|S_{t-1}=s, A_{t-1}=a\}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.051892em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;≐&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05764em;&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.996332em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05764em;&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.891661em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;The &lt;strong&gt;state&lt;/strong&gt; must include information about all aspects of the past agent–environment interaction that make a difference for the future. In general, &lt;strong&gt;actions&lt;/strong&gt; can be any decisions we want to learn how to make, and the states can be anything we can know that might be useful in making them.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;agent–environment&lt;/strong&gt; boundary represents the limit of the agent’s absolute control, not of its knowledge.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Goal&lt;/strong&gt; can be well thought of as the maximization of the expected value of the cumulative sum of a received scalar signal (called &lt;strong&gt;reward&lt;/strong&gt;). The reward signal is your way of communicating to the agent what you want it to achieve, not how you want it achieved.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expected return&lt;/strong&gt; $G_t$ is defined as some specific function of the reward sequence. In the simplest case the return is the sum of the rewards:
&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;≐&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;G_t \doteq R_{t+1}+R_{t+2}+R_{t+3}+...+R_{T}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.83333em;vertical-align:-0.15em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;≐&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.891661em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.891661em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.891661em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.66666em;vertical-align:-0.08333em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.83333em;vertical-align:-0.15em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.32833099999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
where $T$ is the final time step.&lt;/p&gt;

&lt;p&gt;With &lt;em&gt;continuing&lt;/em&gt; tasks, we can have $T=\infty$, we can then introduce &lt;em&gt;discounting&lt;/em&gt;. Agent chooses $A_t$ to maximize the expected discounted return:
&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;≐&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∞&lt;/mi&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;G_t \doteq R_{t+1}+\gamma R_{t+2}+\gamma^2 R_{t+3}+...=\displaystyle\sum_{k=0}^{\infty} \gamma^k R_{t+k+1}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.83333em;vertical-align:-0.15em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;≐&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.891661em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.891661em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05556em;&quot;&gt;γ&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.0224389999999999em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05556em;&quot;&gt;γ&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8141079999999999em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.36687em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.9535100000000005em;vertical-align:-1.302113em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.6513970000000002em;&quot;&gt;&lt;span style=&quot;top:-1.8478869999999998em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;mrel mtight&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.0500049999999996em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-4.300005em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;∞&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.302113em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05556em;&quot;&gt;γ&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8991079999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.3361079999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
where $\gamma$ is called the &lt;em&gt;discount rate&lt;/em&gt;.
&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;G_t = R_{t+1}+\gamma G_{t+1}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.83333em;vertical-align:-0.15em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.891661em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.891661em;vertical-align:-0.208331em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05556em;&quot;&gt;γ&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;strong&gt;Video MDP&lt;/strong&gt; by Martha. By the end of this video: &lt;em&gt;Understand&lt;/em&gt; &lt;strong&gt;Markov Decision Process (MDP)&lt;/strong&gt;, &lt;em&gt;Describe&lt;/em&gt; how the &lt;strong&gt;dynamics of an MDP&lt;/strong&gt; are defined.&lt;/p&gt;

&lt;p&gt;Martha highlights differences between k-armed bandit and MDP. The k-armed bandit agent is presented with the same situation at each time and the same action is always optimal. In many problems, different situations call for different responses. The actions we choose now affect the amount of reward we can get into the future.  In particular if state changes, k-armed bandit don’t adapt. It is why we need MDP.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video examples of MDPs&lt;/strong&gt; by Adam . By the end of this video: Gain experience &lt;strong&gt;formalizing decision-making problems as MDPs&lt;/strong&gt;, Appreciate the &lt;em&gt;flexibility&lt;/em&gt; of the MDP formalism.&lt;/p&gt;

&lt;p&gt;Adam uses 2 examples: robot recycling cans and robot arm.&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-goal-of-reinforcement-learning&quot;&gt;Lesson 2: Goal of Reinforcement Learning&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video the Goal of Reinforcement Learning&lt;/strong&gt; by Adam. By the end of this video: &lt;em&gt;Describe&lt;/em&gt; how rewards relate to the &lt;strong&gt;goal&lt;/strong&gt; of an agent, &lt;em&gt;Identify&lt;/em&gt; &lt;strong&gt;episodic tasks&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;With MDP, agents can have long-term goals.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video the Reward Hypothesis&lt;/strong&gt; by Michael Littman.&lt;/p&gt;

&lt;p&gt;He gives a nice idea when defining reward hypothesis: a contrast between the simplicity of the idea of rewards with the complexity of the real world.&lt;/p&gt;

&lt;h6 id=&quot;lesson-3-continuing-tasks&quot;&gt;Lesson 3: Continuing Tasks&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Continuing Tasks&lt;/strong&gt; by Martha. By the end of this video: &lt;em&gt;Differentiate&lt;/em&gt; between &lt;strong&gt;episodic&lt;/strong&gt; and &lt;strong&gt;continuing tasks&lt;/strong&gt;. &lt;em&gt;Formulate&lt;/em&gt; returns for continuing tasks using &lt;strong&gt;discounting&lt;/strong&gt;. &lt;em&gt;Describe&lt;/em&gt; how &lt;strong&gt;returns at successive time steps&lt;/strong&gt; are related to each other.&lt;/p&gt;

&lt;p&gt;Adam uses a &lt;a href=&quot;http://www.incompleteideas.net/book/the-book.html&quot;&gt;link&lt;/a&gt; to Sutton’s book., This is a 2020 version of this book.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Examples of Episodic and Continuing Tasks&lt;/strong&gt; by Martha. By the end of this video: &lt;em&gt;Understand&lt;/em&gt; when to formalize a task as &lt;strong&gt;episodic or continuing&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Martha gives 2 examples: one of an episodic tasks where episode ends when player is touched by an enemy, one of continuous tasks where an agent accepts or rejects tasks depending on priority and servers available (never ending episode).&lt;/p&gt;

&lt;p&gt;Weekly assessment.&lt;/p&gt;

&lt;p&gt;This is a quizz and a peer-graded assignment. I had to describe 3 MDPs with all its detail (states actions, rewards).&lt;/p&gt;

&lt;h2 id=&quot;51021---course-1---week-3---value-functions--bellman-equations&quot;&gt;5/10/21 - Course 1 - Week 3 - Value Functions &amp;amp; Bellman Equations&lt;/h2&gt;

&lt;h6 id=&quot;module-3-learning-objectives&quot;&gt;Module 3 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: Policies and Value Functions&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Recognize that a policy is a distribution over actions for each possible state&lt;/li&gt;
  &lt;li&gt;Describe the similarities and differences between stochastic and deterministic policies&lt;/li&gt;
  &lt;li&gt;Identify the characteristics of a well-defined policy&lt;/li&gt;
  &lt;li&gt;Generate examples of valid policies for a given MDP&lt;/li&gt;
  &lt;li&gt;Describe the roles of state-value and action-value functions in reinforcement learning&lt;/li&gt;
  &lt;li&gt;Describe the relationship between value functions and policies&lt;/li&gt;
  &lt;li&gt;Create examples of valid value functions for a given MDP&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: Bellman Equations&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Derive the Bellman equation for state-value functions&lt;/li&gt;
  &lt;li&gt;Derive the Bellman equation for action-value functions&lt;/li&gt;
  &lt;li&gt;Understand how Bellman equations relate current and future values&lt;/li&gt;
  &lt;li&gt;Use the Bellman equations to compute value functions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 3: Optimality (Optimal Policies &amp;amp; Value Functions)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define an optimal policy&lt;/li&gt;
  &lt;li&gt;Understand how a policy can be at least as good as every other policy in every state&lt;/li&gt;
  &lt;li&gt;Identify an optimal policy for given MDPs&lt;/li&gt;
  &lt;li&gt;Derive the Bellman optimality equation for state-value functions&lt;/li&gt;
  &lt;li&gt;Derive the Bellman optimality equation for action-value functions&lt;/li&gt;
  &lt;li&gt;Understand how the Bellman optimality equations relate to the previously introduced Bellman equations&lt;/li&gt;
  &lt;li&gt;Understand the connection between the optimal value function and optimal policies&lt;/li&gt;
  &lt;li&gt;Verify the optimal value function for given MDPs&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lesson-1-policies-and-value-functions&quot;&gt;Lesson 1: Policies and Value Functions&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; chapter 3.5 to 3.8 (p58-67) in Sutton’s book&lt;/p&gt;

&lt;p&gt;Almost all reinforcement learning algorithms involve estimating &lt;strong&gt;value functions&lt;/strong&gt;—functions of states (or of state–action pairs) that estimate how good it is for the agent to be in a given state (or how good it is to perform a given action in a given state).&lt;/p&gt;

&lt;p&gt;Searching for additional informations, I have fallen into &lt;a href=&quot;https://shangtongzhang.github.io/&quot;&gt;ShangtongZhang&lt;/a&gt; page and &lt;a href=&quot;https://github.com/ShangtongZhang&quot;&gt;repos&lt;/a&gt;. Only 2 of them but seem to be great: &lt;strong&gt;&lt;a href=&quot;https://github.com/ShangtongZhang/reinforcement-learning-an-introduction&quot;&gt;reinforcement-learning-an-introduction&lt;/a&gt;&lt;/strong&gt; contains implementations in Python of all concepts from Sutton’s book. &lt;strong&gt;&lt;a href=&quot;https://github.com/ShangtongZhang/DeepRL&quot;&gt;DeepRL&lt;/a&gt;&lt;/strong&gt; seems to be a pytorch implementations (DQN, A2C, PPO, …)&lt;/p&gt;

&lt;p&gt;Here we see &lt;strong&gt;Bellman equation&lt;/strong&gt; for state-value function $v_\pi(s)$&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;≐&lt;/mo&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mspace linebreak=&quot;newline&quot;&gt;&lt;/mspace&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/munder&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo fence=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo fence=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mstyle&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;v_\pi(s) \doteq \mathbb{E}[G_t|S_t=s]
\\
v_\pi(s) = \displaystyle\sum_{a} \pi(a|s) \displaystyle\sum_{s&amp;#x27;,r} p(s&amp;#x27;, r|s, a)\big[r+\gamma.v_\pi(s&amp;#x27;)\big]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;≐&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathbb&quot;&gt;E&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05764em;&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace newline&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.480098em;vertical-align:-1.430093em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.050005em;&quot;&gt;&lt;span style=&quot;top:-1.8999949999999999em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.0500049999999996em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.250005em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.050005em;&quot;&gt;&lt;span style=&quot;top:-1.8560149999999997em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.6828285714285715em;&quot;&gt;&lt;span style=&quot;top:-2.786em;margin-right:0.07142857142857144em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size3 size1 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct mtight&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.0500049999999996em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.430093em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;delimsizing size1&quot;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.20001em;vertical-align:-0.35001em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05556em;&quot;&gt;γ&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;delimsizing size1&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;&lt;strong&gt;Bellman equation&lt;/strong&gt; for action-value function $q_\pi(s,a)$&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;≐&lt;/mo&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mspace linebreak=&quot;newline&quot;&gt;&lt;/mspace&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo fence=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;/munder&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo fence=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mstyle&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;q_\pi(s,a) \doteq \mathbb{E}[R_{t+1}+\gamma.G_{t+1}|S_t=s, A_t=a]
\\
q_\pi(s, a) = \displaystyle\sum_{s&amp;#x27;,r} p(s&amp;#x27;, r|s, a) \big[ r + \gamma\displaystyle\sum_{a&amp;#x27;} \pi(s&amp;#x27;, a&amp;#x27;)q_\pi(s&amp;#x27;,a&amp;#x27;) \big]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;≐&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathbb&quot;&gt;E&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05556em;&quot;&gt;γ&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05764em;&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8777699999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace newline&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.480098em;vertical-align:-1.430093em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.050005em;&quot;&gt;&lt;span style=&quot;top:-1.8560149999999997em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.6828285714285715em;&quot;&gt;&lt;span style=&quot;top:-2.786em;margin-right:0.07142857142857144em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size3 size1 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct mtight&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.0500049999999996em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.430093em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;delimsizing size1&quot;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.3439900000000002em;vertical-align:-1.2939850000000002em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05556em;&quot;&gt;γ&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.050005em;&quot;&gt;&lt;span style=&quot;top:-1.8560149999999997em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.6828285714285715em;&quot;&gt;&lt;span style=&quot;top:-2.786em;margin-right:0.07142857142857144em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size3 size1 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.0500049999999996em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.2939850000000002em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;delimsizing size1&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;&lt;strong&gt;Optimal state-value function $v_*$&lt;/strong&gt;:&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;≐&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;&lt;mi&gt;max&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;/mo&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/munder&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∀&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;v_*(s)\doteq \max\limits_{\pi} v_\pi(s), \forall s \in S&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.175696em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;∗&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;≐&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.45em;vertical-align:-0.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.43056em;&quot;&gt;&lt;span style=&quot;top:-2.4em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop&quot;&gt;max&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∀&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;∈&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05764em;&quot;&gt;S&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;&lt;strong&gt;Optimal action-value function $q_*$&lt;/strong&gt;: 
&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;≐&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;&lt;mi&gt;max&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;/mo&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/munder&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;E&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;q_*(s,a) \doteq \max\limits_{\pi} q_\pi(s,a) = \mathbb{E}[R_{t+1}+\gamma.v_*(S_{t+1})|S_t=s, A_t=a]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.175696em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;∗&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;≐&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.45em;vertical-align:-0.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.43056em;&quot;&gt;&lt;span style=&quot;top:-2.4em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop&quot;&gt;max&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathbb&quot;&gt;E&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.00773em;&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05556em;&quot;&gt;γ&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.175696em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;∗&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05764em;&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.301108em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.208331em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05764em;&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8777699999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.2805559999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;We denote all optimal policies by $\pi_*$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bellman optimality equation&lt;/strong&gt; for $v_*$&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;&lt;mi&gt;max&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/munder&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo fence=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo fence=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;v_*(s) = \max\limits_{a} \displaystyle\sum_{s&amp;#x27;, r} p(s&amp;#x27;,r|s, a)\big[ r + \gamma .v_*(s&amp;#x27;) \big]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.175696em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;∗&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.480098em;vertical-align:-1.430093em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.43056em;&quot;&gt;&lt;span style=&quot;top:-2.4em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop&quot;&gt;max&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.050005em;&quot;&gt;&lt;span style=&quot;top:-1.8560149999999997em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.6828285714285715em;&quot;&gt;&lt;span style=&quot;top:-2.786em;margin-right:0.07142857142857144em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size3 size1 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct mtight&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.0500049999999996em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.430093em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;delimsizing size1&quot;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.20001em;vertical-align:-0.35001em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05556em;&quot;&gt;γ&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.175696em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;∗&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;delimsizing size1&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;&lt;strong&gt;Bellman optimality equation&lt;/strong&gt; for $q_*$&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo fence=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;munder&gt;&lt;mo&gt;&lt;mi&gt;max&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;/munder&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo mathvariant=&quot;normal&quot; lspace=&quot;0em&quot; rspace=&quot;0em&quot;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo fence=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;q_*(s,a) = \displaystyle\sum_{s&amp;#x27;,r} p(s&amp;#x27;, r|s, a) \big[ r + \gamma.\max\limits_{a&amp;#x27;} q_*(s&amp;#x27;,a&amp;#x27;) \big]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.175696em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;∗&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.480098em;vertical-align:-1.430093em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.050005em;&quot;&gt;&lt;span style=&quot;top:-1.8560149999999997em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.6828285714285715em;&quot;&gt;&lt;span style=&quot;top:-2.786em;margin-right:0.07142857142857144em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size3 size1 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct mtight&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.0500049999999996em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.430093em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;delimsizing size1&quot;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.5939800000000002em;vertical-align:-0.7439800000000001em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05556em;&quot;&gt;γ&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.43055999999999983em;&quot;&gt;&lt;span style=&quot;top:-2.35602em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.6828285714285715em;&quot;&gt;&lt;span style=&quot;top:-2.786em;margin-right:0.07142857142857144em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size3 size1 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop&quot;&gt;max&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7439800000000001em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.175696em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mbin mtight&quot;&gt;∗&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.801892em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;delimsizing size1&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;&lt;img src=&quot;/home/explore/git/guillaume/blog/images/alberta_rl-backup-diagrams.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Specifying Policies&lt;/strong&gt; by Adam.&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Recognize&lt;/em&gt; that a &lt;strong&gt;policy&lt;/strong&gt; is a &lt;strong&gt;distribution over actions&lt;/strong&gt; for each possible &lt;strong&gt;state&lt;/strong&gt;, &lt;em&gt;describe&lt;/em&gt; the similarities and differences between &lt;strong&gt;stochastic and deterministic policies&lt;/strong&gt;, and &lt;em&gt;generate examples&lt;/em&gt; of &lt;strong&gt;valid policies&lt;/strong&gt; for a given MDP or Markup Decision Process.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Value Functions&lt;/strong&gt; by Adam.&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to&lt;/p&gt;

&lt;p&gt;&lt;em&gt;describe the roles&lt;/em&gt; of the &lt;strong&gt;state-value and&lt;/strong&gt; &lt;strong&gt;action-value functions&lt;/strong&gt; in reinforcement learning, &lt;em&gt;describe the relationship&lt;/em&gt; between &lt;strong&gt;value-functions&lt;/strong&gt; and &lt;strong&gt;policies&lt;/strong&gt;, and &lt;em&gt;create examples&lt;/em&gt; of &lt;strong&gt;value-functions&lt;/strong&gt; for a given MDP.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Rich Sutton and Andy Barto: A brief History of RL&lt;/strong&gt;&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-bellman-equations&quot;&gt;Lesson 2: Bellman Equations&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Bellman Equation Derivation&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;derive&lt;/em&gt; the &lt;strong&gt;Bellman equation&lt;/strong&gt; for &lt;strong&gt;state-value functions&lt;/strong&gt;, &lt;em&gt;derive&lt;/em&gt; the &lt;strong&gt;Bellman equation&lt;/strong&gt; for &lt;strong&gt;action-value functions&lt;/strong&gt;, and &lt;em&gt;understand&lt;/em&gt; how &lt;strong&gt;Bellman equations&lt;/strong&gt; relate &lt;strong&gt;current&lt;/strong&gt; and &lt;strong&gt;future values&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Why Bellman Equations?&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;use&lt;/em&gt; the &lt;strong&gt;Bellman equations&lt;/strong&gt; to compute &lt;strong&gt;value functions&lt;/strong&gt;&lt;/p&gt;

&lt;h6 id=&quot;lesson-3-optimality-optimal-policies--value-functions&quot;&gt;Lesson 3: Optimality (Optimal Policies &amp;amp; Value Functions)&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Optimal Policies&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;define&lt;/em&gt; an &lt;strong&gt;optimal policy&lt;/strong&gt;, &lt;em&gt;understand&lt;/em&gt; how &lt;strong&gt;policy&lt;/strong&gt; can be at least as good as every other policy in every state, and &lt;em&gt;identify&lt;/em&gt; an &lt;strong&gt;optimal policy&lt;/strong&gt; for a given MDP.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Optimal Value Functions&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;derive&lt;/em&gt; the &lt;strong&gt;Bellman optimality equation&lt;/strong&gt; for the &lt;strong&gt;state-value function&lt;/strong&gt;, &lt;em&gt;derive&lt;/em&gt; the &lt;strong&gt;Bellman optimality equation&lt;/strong&gt; for the &lt;strong&gt;action-value function&lt;/strong&gt;, and &lt;em&gt;understand&lt;/em&gt; how the &lt;strong&gt;Bellman optimality equations&lt;/strong&gt; relate to the previously introduced &lt;strong&gt;Bellman equations&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Using Optimal Value Functions to Get Optimal Policies&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;understand&lt;/em&gt; the connection between the &lt;strong&gt;optimal value function&lt;/strong&gt; and &lt;strong&gt;optimal policies&lt;/strong&gt; and &lt;em&gt;verify&lt;/em&gt; the &lt;strong&gt;optimal value function&lt;/strong&gt; for a given MDP&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video week 3 summary&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C1W3_1_policies.png&quot; alt=&quot;Policies&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C1W3_2_value_functions.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C1W3_3_bellman_equations.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C1W3_4_optimal_policies.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C1W3_5_bellman_optimality_equations.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;51821---course-1---week-4---dynamic-programming&quot;&gt;5/18/21 - Course 1 - Week 4 - Dynamic Programming&lt;/h2&gt;

&lt;h6 id=&quot;module-4-learning-objectives&quot;&gt;Module 4 Learning Objectives&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Lesson 1: Policy Evaluation (Prediction)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand the distinction between policy evaluation and control&lt;/li&gt;
  &lt;li&gt;Explain the setting in which dynamic programming can be applied, as well as its limitations&lt;/li&gt;
  &lt;li&gt;Outline the iterative policy evaluation algorithm for estimating state values under a given policy&lt;/li&gt;
  &lt;li&gt;Apply iterative policy evaluation to compute value functions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 2: Policy Iteration (Control)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand the policy improvement theorem&lt;/li&gt;
  &lt;li&gt;Use a value function for a policy to produce a better policy for a given MDP&lt;/li&gt;
  &lt;li&gt;Outline the policy iteration algorithm for finding the optimal policy&lt;/li&gt;
  &lt;li&gt;Understand “the dance of policy and value”&lt;/li&gt;
  &lt;li&gt;Apply policy iteration to compute optimal policies and optimal value functions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lesson 3: Generalized Policy Iteration&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand the framework of generalized policy iteration&lt;/li&gt;
  &lt;li&gt;Outline value iteration, an important example of generalized policy iteration&lt;/li&gt;
  &lt;li&gt;Understand the distinction between synchronous and asynchronous dynamic programming methods&lt;/li&gt;
  &lt;li&gt;Describe brute force search as an alternative method for searching for an optimal policy&lt;/li&gt;
  &lt;li&gt;Describe Monte Carlo as an alternative method for learning a value function&lt;/li&gt;
  &lt;li&gt;Understand the advantage of Dynamic programming and “bootstrapping” over these alternative strategies for finding the optimal policy&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lesson-1-policy-evaluation-prediction&quot;&gt;Lesson 1: Policy Evaluation (Prediction)&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Reading&lt;/strong&gt; chapter &lt;strong&gt;4.1, 4.2, 4.3, 4.4, 4.6, 4.7&lt;/strong&gt; &lt;strong&gt;(pages 73-88)&lt;/strong&gt;  in Sutton’s book (with the help of &lt;a href=&quot;https://github.com/LyWangPX/Reinforcement-Learning-2nd-Edition-by-Sutton-Exercise-Solutions/blob/master/Chapter%204/Solutions_to_Reinforcement_Learning_by_Sutton_Chapter_4_r5.pdf&quot;&gt;Solutions_to_Reinforcement_Learning_by_Sutton_Chapter_4_r5.pdf&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;A common way of obtaining approximate solutions for tasks with &lt;strong&gt;continuous states&lt;/strong&gt; &lt;strong&gt;and actions&lt;/strong&gt; is to &lt;strong&gt;quantize&lt;/strong&gt; the state and action spaces and then apply finite-state DP methods.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Policy Evaluation vs. Control&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video you will be able to &lt;em&gt;understand&lt;/em&gt; the distinction between &lt;strong&gt;policy evaluation&lt;/strong&gt; and &lt;strong&gt;control&lt;/strong&gt;, and &lt;em&gt;explain&lt;/em&gt; the setting in which &lt;strong&gt;dynamic programming&lt;/strong&gt; can be applied as well as its limitations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Iterative Policy Evaluation&lt;/strong&gt; by Martha&lt;/p&gt;

&lt;p&gt;By the end of this video you will be able to &lt;em&gt;outline&lt;/em&gt; the &lt;strong&gt;iterative policy evaluation&lt;/strong&gt; algorithm for estimating state values for a given policy, and &lt;em&gt;apply&lt;/em&gt; iterative policy evaluation to compute value functions.&lt;/p&gt;

&lt;p&gt;The magic here is to turn the bellman equation into an iterative evaluation which converges to $v_\pi$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C1W4_1_iterative_policy_evaluation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;lesson-2-policy-iteration-control&quot;&gt;Lesson 2: Policy Iteration (Control)&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Policy Improvement&lt;/strong&gt; by Marta&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;understand&lt;/em&gt; the &lt;strong&gt;policy improvement theorem&lt;/strong&gt;, and how it can be used to construct improved policies, and &lt;em&gt;use&lt;/em&gt; the value function for a policy to produce a better policy for a given MDP.&lt;/p&gt;

&lt;p&gt;Greedified policy is a strict improvement.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C1W4_1_policy_improvement theorem.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Policy Iteration&lt;/strong&gt; by Marta&lt;/p&gt;

&lt;p&gt;By the end of this video, you will be able to &lt;em&gt;outline&lt;/em&gt; the &lt;strong&gt;policy iteration&lt;/strong&gt; algorithm for finding the optimal policy, &lt;em&gt;understand&lt;/em&gt; the &lt;strong&gt;dance of policy and value&lt;/strong&gt;, how policy iteration reaches the optimal policy by alternating between evaluating policy and improving it, and &lt;em&gt;apply&lt;/em&gt; policy iteration to compute optimal policies and optimal value functions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C1W4_1_policy_iteration.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/C1W4_1_policy_iteration_graph.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;lesson-3-generalized-policy-iteration&quot;&gt;Lesson 3: Generalized Policy Iteration&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Video Flexibility of the Policy Iteration Framework&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;understand&lt;/em&gt; the framework of &lt;strong&gt;generalized policy iteration&lt;/strong&gt;, &lt;em&gt;outline&lt;/em&gt; &lt;strong&gt;value iteration&lt;/strong&gt; and important special case of generalized policy iteration, and &lt;em&gt;differentiate&lt;/em&gt; &lt;strong&gt;synchronous&lt;/strong&gt; and &lt;strong&gt;asynchronous&lt;/strong&gt; dynamic programming methods.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Efficiency of Dynamic Programming&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;By the end of this video, you’ll be able to &lt;em&gt;describe&lt;/em&gt; &lt;strong&gt;Monte Carlo sampling&lt;/strong&gt; as an alternative method for learning a value function. &lt;em&gt;Describe&lt;/em&gt; &lt;strong&gt;brute force-search&lt;/strong&gt; as an alternative method for finding an optimal policy. And &lt;em&gt;understand&lt;/em&gt; the advantages of &lt;strong&gt;dynamic programming&lt;/strong&gt; and &lt;strong&gt;bootstrapping&lt;/strong&gt; over these alternatives.&lt;/p&gt;

&lt;p&gt;The most important takeaway is that bootstrapping can save us from performing a huge amount of unnecessary work by exploiting the connection between the value of a state and its possible successors.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Warren Powell: Approximate Dynamic Programming for Fleet Management (Short)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Video Week 4 Summary&lt;/strong&gt; by Adam&lt;/p&gt;

&lt;p&gt;Reading chapter summary &lt;strong&gt;Chapter 4.8, (pages 88-89)&lt;/strong&gt;&lt;/p&gt;

&lt;h6 id=&quot;assignment&quot;&gt;Assignment&lt;/h6&gt;

&lt;p&gt;Optimal Policies with Dynamic Programming&lt;/p&gt;

&lt;p&gt;notebooks in &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/tree/main/assignements/course%201%20week%204&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;end of C1W4 (course 1 week 4)&lt;/p&gt;

&lt;p&gt;end of course 1 (and with a &lt;a href=&quot;https://github.com/castorfou/Reinforcement-Learning-specialization/blob/main/certificates/course%201.pdf&quot;&gt;certificate&lt;/a&gt; ;) )&lt;/p&gt;</content><author><name></name></author><category term="reinforcement learning" /><category term="deepmind" /><summary type="html">Coursera website: course 1 - Fundamentals of Reinforcement Learning of Reinforcement Learning Specialization</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://castorfou.github.io/guillaume_blog/images/RL.png" /><media:content medium="image" url="https://castorfou.github.io/guillaume_blog/images/RL.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Logbook for May 21</title><link href="https://castorfou.github.io/guillaume_blog/blog/logbook-May.html" rel="alternate" type="text/html" title="Logbook for May 21" /><published>2021-05-01T00:00:00-05:00</published><updated>2021-05-01T00:00:00-05:00</updated><id>https://castorfou.github.io/guillaume_blog/blog/logbook-May</id><content type="html" xml:base="https://castorfou.github.io/guillaume_blog/blog/logbook-May.html">&lt;h2 id=&quot;week-18---may-21&quot;&gt;Week 18 - May 21&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Monday 5/3&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - enrolled - Coursera (University of Alberta) - start of course 1 (Fundamentals of Reinforcement Learning) week 1 (An introduction to Sequential Decision-Making)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tuesday 5/4&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - end of assignement for C1W1&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/Introduction-to-Reinforcement-Learning-with-David-Silver.html&quot;&gt;RL Course by David Silver&lt;/a&gt; Policy Gradient Methods (lecture 7)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Friday 5/7&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C1W2 - Markov Decision Process&lt;/p&gt;

&lt;h2 id=&quot;week-19---may-21&quot;&gt;Week 19 - May 21&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Monday 5/10&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C1W3 - Value Functions &amp;amp; Bellman Equations&lt;/p&gt;

&lt;h2 id=&quot;week-20---may-21&quot;&gt;Week 20 - May 21&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Monday 5/17&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C1W3 - Value Functions &amp;amp; Bellman Equations&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tuesday 5/18&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C1W4 - Dynamic Programming&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Friday 5/21&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C1W4 - Dynamic Programming - assignment completed and end of course 1 ;)&lt;/p&gt;

&lt;p&gt;Start of &lt;a href=&quot;/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn.html&quot;&gt;Machine learning in python with scikit-learn&lt;/a&gt; by Inria&lt;/p&gt;

&lt;h2 id=&quot;week-21---may-21&quot;&gt;Week 21 - May 21&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Tuesday 5/25&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn.html&quot;&gt;Machine learning in python with scikit-learn&lt;/a&gt; end of module 1&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C2W1 - Monte-Carlo&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Wednesday 5/26&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C2W1 - Monte-Carlo - end of week 1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thursday 5/27&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn.html&quot;&gt;Machine learning in python with scikit-learn&lt;/a&gt; start of module 2. Selecting the best model&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/reinforcement-learning-specialization-coursera-course2.html&quot;&gt;Reinforcement Learning Specialization&lt;/a&gt; - C2W2 - Temporal Difference for Prediction - start&lt;/p&gt;

&lt;h2 id=&quot;week-22---may-21&quot;&gt;Week 22 - May 21&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Monday 5/31&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/guillaume_blog/blog/Machine-learning-in-python-with-scikit-learn.html&quot;&gt;Machine learning in python with scikit-learn&lt;/a&gt; start of module 3. Hyperparameter tuning&lt;/p&gt;</content><author><name></name></author><category term="logbook" /><summary type="html">Week 18 - May 21</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://castorfou.github.io/guillaume_blog/images/logbook.jpg" /><media:content medium="image" url="https://castorfou.github.io/guillaume_blog/images/logbook.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">setup wsl2 with cuda and conda</title><link href="https://castorfou.github.io/guillaume_blog/blog/wsl2-cuda-conda.html" rel="alternate" type="text/html" title="setup wsl2 with cuda and conda" /><published>2021-04-09T00:00:00-05:00</published><updated>2021-04-09T00:00:00-05:00</updated><id>https://castorfou.github.io/guillaume_blog/blog/wsl2%20cuda%20conda</id><content type="html" xml:base="https://castorfou.github.io/guillaume_blog/blog/wsl2-cuda-conda.html">&lt;h2 id=&quot;wsl2-and-network--proxychains&quot;&gt;wsl2 and network + proxychains&lt;/h2&gt;

&lt;p&gt;workaround explained in &lt;a href=&quot;https://castorfou.github.io/guillaume_blog/blog/Windows10-fastai-wsl2-cuda.html#Workaround-network-issue-with-WSL2&quot;&gt;this blog entry&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wsl &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; Ubuntu-20.04 &lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt; ~/Applications/wsl-vpnkit/wsl-vpnkit-main/wsl-vpnkit
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;cuda&quot;&gt;cuda&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.nvidia.com/cuda/wsl-user-guide/index.html#installing-nvidia-drivers&quot;&gt;https://docs.nvidia.com/cuda/wsl-user-guide/index.html#installing-nvidia-drivers&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;install nvidia cuda specific driver for WSL: &lt;a href=&quot;https://developer.nvidia.com/cuda/wsl&quot;&gt;https://developer.nvidia.com/cuda/wsl&lt;/a&gt; on windows. (version 470.14_quadro_win10-dch_64bit_international in my case)&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;proxychains wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
&lt;span class=&quot;nb&quot;&gt;sudo mv &lt;/span&gt;cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-key adv &lt;span class=&quot;nt&quot;&gt;--fetch-keys&lt;/span&gt; https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;proxychains add-apt-repository &lt;span class=&quot;s2&quot;&gt;&quot;deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;proxychains apt-get update
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;proxychains apt-get &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;cuda-toolkit-11-2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://christianjmills.com/Using-PyTorch-with-CUDA-on-WSL2/&quot;&gt;https://christianjmills.com/Using-PyTorch-with-CUDA-on-WSL2/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;new version using WSL-ubuntu as distro&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://christianjmills.com/Using-PyTorch-with-CUDA-on-WSL2/&quot;&gt;https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;target_distro=WSLUbuntu&amp;amp;target_version=20&amp;amp;target_type=deblocal&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;proxychains wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin
&lt;span class=&quot;nb&quot;&gt;sudo mv &lt;/span&gt;cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600
proxychains wget https://developer.download.nvidia.com/compute/cuda/11.2.2/local_installers/cuda-repo-wsl-ubuntu-11-2-local_11.2.2-1_amd64.deb
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;dpkg &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; cuda-repo-wsl-ubuntu-11-2-local_11.2.2-1_amd64.deb
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-key add /var/cuda-repo-wsl-ubuntu-11-2-local/7fa2af80.pub
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;proxychains apt-get update
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;proxychains apt-get &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;cuda
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;test cuda&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda activate pytorch
ipython
import torch
torch.cuda.is_available&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conda&quot;&gt;conda&lt;/h2&gt;

&lt;p&gt;from https://docs.conda.io/en/latest/miniconda.html&lt;/p&gt;

&lt;p&gt;download https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh&lt;/p&gt;

&lt;p&gt;and install with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./Miniconda3-latest-Linux-x86_64.sh -p $HOME/miniconda3&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;pycaret&quot;&gt;pycaret&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda create &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; pycaret &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.7
conda activate pycaret

proxychains pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;pycaret shap
proxychains conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; conda-forge  nb_conda jupyter_contrib_nbextensions fire pyfiglet openpyxl
jupyter contrib nbextensions &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--user&lt;/span&gt;
proxychains conda upgrade nbconvert

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;pytorch&quot;&gt;pytorch&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;proxychains conda create &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; pytorch &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.8
proxychains conda activate pytorch
proxychains conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; pytorch &lt;span class=&quot;nv&quot;&gt;pytorch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.7.1 torchvision
proxychains conda &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;jupyter
proxychains conda &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; conda-forge jupyter_contrib_nbextensions
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="wsl" /><category term="cuda" /><category term="conda" /><summary type="html">wsl2 and network + proxychains</summary></entry><entry><title type="html">using SOCKS5 proxy - with git, apt, pip, …</title><link href="https://castorfou.github.io/guillaume_blog/blog/git-avec-proxy-socks.html" rel="alternate" type="text/html" title="using SOCKS5 proxy - with git, apt, pip, …" /><published>2021-04-06T00:00:00-05:00</published><updated>2021-04-06T00:00:00-05:00</updated><id>https://castorfou.github.io/guillaume_blog/blog/git%20avec%20proxy%20socks</id><content type="html" xml:base="https://castorfou.github.io/guillaume_blog/blog/git-avec-proxy-socks.html">&lt;h2 id=&quot;setup-socks5-server&quot;&gt;setup socks5 server&lt;/h2&gt;

&lt;p&gt;using &lt;a href=&quot;https://community.hetzner.com/tutorials/install-and-configure-danted-proxy-socks5&quot;&gt;dante&lt;/a&gt; server&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;dante-server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Conf file&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;nano /etc/danted.conf

logoutput: stderr
internal: enp3s0 port &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 1080
external: enp3s0
socksmethod: none
clientmethod: none
user.privileged: proxy
user.unprivileged: nobody
user.libwrap: nobody
client pass &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        from: 0.0.0.0/0 to: 0.0.0.0/0
        log: error connect disconnect
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
client block &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        from: 0.0.0.0/0 to: 0.0.0.0/0
        log: connect error
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
socks pass &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        from: 0.0.0.0/0 to: 0.0.0.0/0
        log: error connect disconnect
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
socks block &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        from: 0.0.0.0/0 to: 0.0.0.0/0
        log: connect error
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Start and monitor usage&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;service danted restart
&lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; /var/log/syslog
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;git-setup&quot;&gt;Git setup&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; .ssh/config
Host github.com
IdentityFile ~/.ssh/id_rsa_gmail
ProxyCommand /bin/nc &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt; 5 &lt;span class=&quot;nt&quot;&gt;-x&lt;/span&gt; 192.168.50.202:1080 %h %p
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;proxychains&quot;&gt;Proxychains&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;installation&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# to be downloaded from apt mirrors:&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# libproxychains proxychains&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;dpkg &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; libproxychains3_3.1-7_amd64.deb proxychains_3.1-7_all.deb
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;configuration&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;vi /etc/proxychains.conf

&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;ProxyList]
&lt;span class=&quot;c&quot;&gt;# add proxy here ...&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# meanwile&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# defaults set to &quot;tor&quot;&lt;/span&gt;
socks5          192.168.50.202  1080
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;usage&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;proxychains apt update
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;proxychains apt upgrade

proxychains pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;pycaret 

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="git" /><summary type="html">setup socks5 server</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://castorfou.github.io/guillaume_blog/images/git.png" /><media:content medium="image" url="https://castorfou.github.io/guillaume_blog/images/git.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">ANITI’s first Reinforcement Learning Virtual School</title><link href="https://castorfou.github.io/guillaume_blog/blog/Aniti-RLVS-seminaire-RL.html" rel="alternate" type="text/html" title="ANITI’s first Reinforcement Learning Virtual School" /><published>2021-04-01T00:00:00-05:00</published><updated>2021-04-01T00:00:00-05:00</updated><id>https://castorfou.github.io/guillaume_blog/blog/Aniti%20-%20RLVS%20-%20seminaire%20RL</id><content type="html" xml:base="https://castorfou.github.io/guillaume_blog/blog/Aniti-RLVS-seminaire-RL.html">&lt;p&gt;&lt;img src=&quot;https://d1keuthy5s86c8.cloudfront.net/static/ems/upload/img/72947a097165dcd24a6f700e2f28d690.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://rlvs.aniti.fr/&quot;&gt;https://rlvs.aniti.fr/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Schedule is&lt;/p&gt;

&lt;h2 id=&quot;rlvs-schedule&quot;&gt;RLVS schedule&lt;/h2&gt;

&lt;p&gt;This condensed schedule does not include class breaks and social events. Times are Central European Summer Time (UTC+2).&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Schedule&lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;March 25th&lt;/td&gt;
      &lt;td&gt;9:00-9:10&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/opening.html&quot;&gt;Opening remarks&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/sebastien-gerchinovitz.html&quot;&gt;S. Gerchinovitz&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;9:10-9:30&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/rlvs-overview.html&quot;&gt;RLVS Overview&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/emmanuel-rachelson.html&quot;&gt;E. Rachelson&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;9:30-13:00&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/rl-fundamentals.html&quot;&gt;RL fundamentals&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/emmanuel-rachelson.html&quot;&gt;E. Rachelson&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;14:00-16:00&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/deep-learning.html&quot;&gt;Introduction to Deep Learning&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/dennis-wilson.html&quot;&gt;D. Wilson&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;16:30-17:30&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/human-behavioral-agents.html&quot;&gt;Reward Processing Biases in Humans and RL Agents&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/irina-rish.html&quot;&gt;I. Rish&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;17:45-18:45&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/hierarchical.html&quot;&gt;Introduction to Hierarchical Reinforcement Learning&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/doina-precup.html&quot;&gt;D. Precup&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;March 26th&lt;/td&gt;
      &lt;td&gt;10:00-12:00&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/stochastic-bandits.html&quot;&gt;Stochastic bandits&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/tor-lattimore.html&quot;&gt;T. Lattimore&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;14:00-16:00&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/mcts.html&quot;&gt;Monte Carlo Tree Search&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/tor-lattimore.html&quot;&gt;T. Lattimore&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;16:30-17:30&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/clinical.html&quot;&gt;Multi-armed bandits in clinical trials&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/donald-berry.html&quot;&gt;D. A. Berry&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;April 1st&lt;/td&gt;
      &lt;td&gt;9:00-15:00&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/dqn.html&quot;&gt;Deep Q-Networks and its variants&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/bilal-piot.html&quot;&gt;B. Piot&lt;/a&gt;, &lt;a href=&quot;https://rl-vs.github.io/rlvs2021/corentin-tallec.html&quot;&gt;C. Tallec&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;15:15-16:15&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/regularized-mdps.html&quot;&gt;Regularized MDPs&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/matthieu-geist.html&quot;&gt;M. Geist&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;16:30-17:30&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/regret-bound.html&quot;&gt;Regret bounds of model-based reinforcement learning&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/mengdi-wang.html&quot;&gt;M. Wang&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;April 2nd&lt;/td&gt;
      &lt;td&gt;9:00-12:30&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/pg.html&quot;&gt;Policy Gradients and Actor Critic methods&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/olivier-sigaud.html&quot;&gt;O. Sigaud&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;14:00-15:00&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/pg-pitfalls.html&quot;&gt;Pitfalls in Policy Gradient methods&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/olivier-sigaud.html&quot;&gt;O. Sigaud&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;15:30-17:30&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/exploration.html&quot;&gt;Exploration in Deep RL&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/matteo-pirotta.html&quot;&gt;M. Pirotta&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;April 8th&lt;/td&gt;
      &lt;td&gt;9:00-11:00&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/evo-rl.html&quot;&gt;Evolutionary Reinforcement Learning&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/dennis-wilson.html&quot;&gt;D. Wilson&lt;/a&gt;, &lt;a href=&quot;https://rl-vs.github.io/rlvs2021/jean-baptiste-mouret.html&quot;&gt;J.-B. Mouret&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;11:30-12:30&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/evolving-agents.html&quot;&gt;Evolving Agents that Learn More Like Animals&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/sebastian-risi.html&quot;&gt;S. Risi&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;14:00-16:00&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/micro-data.html&quot;&gt;Micro-data Policy Search&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/konstantinos-chatzilygeroudis.html&quot;&gt;K. Chatzilygeroudis&lt;/a&gt;, &lt;a href=&quot;https://rl-vs.github.io/rlvs2021/jean-baptiste-mouret.html&quot;&gt;J.-B. Mouret&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;16:30-17:30&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/efficient-motor.html&quot;&gt;Efficient Motor Skills Learning in Robotics&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/dongheui-lee.html&quot;&gt;D. Lee&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;April 9th&lt;/td&gt;
      &lt;td&gt;9:00-13:00&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/tips-and-tricks.html&quot;&gt;RL tips and tricks&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/antonin-raffin.html&quot;&gt;A. Raffin&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;14:30-15:30&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/symbolic.html&quot;&gt;Symbolic representations and reinforcement learning&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/marta-garnelo.html&quot;&gt;M. Garnelo&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;15:45-16:45&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/model-learning.html&quot;&gt;Leveraging model-learning for extreme generalization&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/leslie-kaelbling.html&quot;&gt;L. P. Kaelbling&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;17:00-18:00&lt;/td&gt;
      &lt;td&gt;RLVS wrap-up&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://rl-vs.github.io/rlvs2021/emmanuel-rachelson.html&quot;&gt;E. Rachelson&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;4121---deep-q-networks-and-its-variants&quot;&gt;(4/1/21) - &lt;a href=&quot;https://whova.com/embedded/session/rlstc_202011/1416824/?view=&quot;&gt;Deep Q-Networks and its variants&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Speaker is Bilal Piot.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deep Q network&lt;/strong&gt; as a solution for a practicable control theory.&lt;/p&gt;

&lt;p&gt;Introduction of ALE (Atari Learning Environment)&lt;/p&gt;

&lt;p&gt;DQN is (almost) end-to-end: from raw observations to actions. Bilal explains the preprocessing part (from 160x210x3 to 84x84 + stacking 4 frames + downsampling to 15 Hz)&lt;/p&gt;

&lt;p&gt;Value Iteration (VI) algorithm: Recurrent algorithm to get Q. $Q_{k+1}=T^*Q$&lt;/p&gt;

&lt;p&gt;But it is not practical in a real-world case. What we can do is use interactions with real world. And estimate $Q^*$ using a regression.&lt;/p&gt;

&lt;p&gt;Would be interesting to have slides. I like the link between regression notations and VI notation.&lt;/p&gt;

&lt;p&gt;From neural Fitted-$Q$ to DQN. Main difference is data collection (in DQN you have updated interactions and it allows exploration, and size of architecture)&lt;/p&gt;

&lt;p&gt;With DQN we have acting part and learning part. Acting is the data collection. (using $\epsilon$-greedy policy)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;hands-on based on DQN tutorial notebook.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;had to  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;export LD_LIBRARY_PATH=/home/explore/miniconda3/envs/aniti/lib/&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Nice introduction to JAX and haiku. Haiku is similar modules in pytorch and can turn NN into pure version. Which is useful for Jax.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;overview of the literature&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://kstatic.googleusercontent.com/files/f6b5f285173d4449285a8e812b8385f45c03f7104e1c41370a73e0c8558ff82d6a69e60962dd91c4972c444fd73bc4f98a06b5487eff5a037a37bc42f97cef3b&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4221---from-policy-gradients-to-actor-critic-methods&quot;&gt;(4/2/21) - &lt;a href=&quot;https://whova.com/embedded/session/rlstc_202011/1416833/?view=&quot;&gt;From Policy Gradients to Actor Critic methods&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Olivier Sigaud is the speaker.&lt;/p&gt;

&lt;p&gt;He has pre-recorded his lecture in videos. I have missed the start so I will have to watch them later.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://whova.com/embedded/session/rlstc_202011/1416836/?view=&quot;&gt;Policy Gradient in pratice&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Don’t become an alchemist ;)&lt;/p&gt;

&lt;p&gt;As stochastic policies, squashed gaussian is interesting because it allows continuous variable + bounds.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://whova.com/embedded/session/rlstc_202011/1416838/?view=#&quot;&gt;Exploration in Deep RL&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;4821---evolutionary-reinforcement-learning&quot;&gt;(4/8/21) - &lt;a href=&quot;https://whova.com/embedded/session/rlstc_202011/1416851/?view=&quot;&gt;Evolutionary Reinforcement Learning&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;pdf version of the slides are available &lt;a href=&quot;https://rl-vs.github.io/rlvs2021/class-material/evolutionary/light-virtual_school_neat_hyperneat.pdf&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;then &lt;a href=&quot;https://whova.com/embedded/session/rlstc_202011/1416848/?view=&quot;&gt;Evolving Agents that Learn More Like Animals&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This morning was more about what we can do when we have infinite calculation power and data.&lt;/p&gt;

&lt;p&gt;Afternoon will be the opposite.&lt;/p&gt;

&lt;h2 id=&quot;4821---micro-data-policy-search&quot;&gt;(4/8/21) - &lt;a href=&quot;https://whova.com/embedded/session/rlstc_202011/1416841/?view=&quot;&gt;Micro-data Policy Search&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Most policy search algorithms require thousands of training episodes to  find an effective policy, which is often infeasible when experiments  takes time or are expensive (for instance, with physical robot or with  an aerodynamics simulator). This class focuses on the extreme other end  of the spectrum: how can an algorithm adapt a policy with only a handful of trials (a dozen) and a few minutes? By analogy with the word  “big-data”, we refer to this challenge as “micro-data reinforcement  learning”. We will describe two main strategies: (1) leverage prior  knowledge on the policy structure (e.g., dynamic movement primitives),  on the policy parameters (e.g., demonstrations), or on the dynamics  (e.g., simulators), and (2) create data-driven surrogate models of the  expected reward (e.g., Bayesian optimization) or the dynamical model  (e.g., model-based policy search), so that the policy optimizer queries  the model instead of the real system. Most of the examples will be about robotic systems, but the principle apply to any other expensive setup.&lt;/p&gt;

&lt;p&gt;all material: &lt;a href=&quot;https://rl-vs.github.io/rlvs2021/micro-data.html&quot;&gt;https://rl-vs.github.io/rlvs2021/micro-data.html&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;4921---rl-in-practice-tips-and-tricks-and-practical-session-with-stable-baselines3&quot;&gt;(4/9/21) - &lt;a href=&quot;https://whova.com/embedded/session/rlstc_202011/1416855/?view=&quot;&gt;RL in Practice: Tips and Tricks and Practical Session With Stable-Baselines3&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;​                        &lt;strong&gt;Abstract:&lt;/strong&gt;
The aim of the session is to  help you do reinforcement learning experiments. The first part covers  general advice about RL, tips and tricks and details three examples  where RL was applied on real robots. The second part will be a practical session using the Stable-Baselines3 library.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pre-requisites:&lt;/strong&gt;
Python programming, RL basics, (recommended: Google account for the practical session in order to use Google Colab).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Additional material:&lt;/strong&gt;
Website: &lt;a href=&quot;https://github.com/DLR-RM/stable-baselines3&quot;&gt;https://github.com/DLR-RM/stable-baselines3&lt;/a&gt;
Doc: &lt;a href=&quot;https://stable-baselines3.readthedocs.io/en/master/&quot;&gt;https://stable-baselines3.readthedocs.io/en/master/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Outline:&lt;/strong&gt;
Part I: RL Tips and Tricks / The Challenges of Applying RL to Real Robots&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Introduction (3 minutes)&lt;/li&gt;
  &lt;li&gt;RL Tips and tricks (45 minutes)
    &lt;ol&gt;
      &lt;li&gt;General Nuts and Bolts of RL experimentation (10 minutes)&lt;/li&gt;
      &lt;li&gt;RL in practice on a custom task (custom environment) (30 minutes)&lt;/li&gt;
      &lt;li&gt;Questions? (5 minutes)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;The Challenges of Applying RL to Real Robots (45 minutes)
    &lt;ol&gt;
      &lt;li&gt;Learning to control an elastic robot - DLR David Neck Example (15 minutes)&lt;/li&gt;
      &lt;li&gt;Learning to drive in minutes and learning to race in hours - Virtual and real racing car (15 minutes)&lt;/li&gt;
      &lt;li&gt;Learning to walk with an elastic quadruped robot - DLR bert example (10 minutes)&lt;/li&gt;
      &lt;li&gt;Questions? (5 minutes+)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Part II: Practical Session with Stable-Baselines3&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Stable-Baselines3 Overview (20 minutes)&lt;/li&gt;
  &lt;li&gt;Questions? (5 minutes)&lt;/li&gt;
  &lt;li&gt;Practical Session - Code along (1h+)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;action space&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When using continuous space, you need to normalize! (normalized action space -1, -1)&lt;/p&gt;

&lt;p&gt;there is a checker for that in stable baselines 3.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;reward&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;start with reward shaping.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;termination condition&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;early stopping makes learning faster (and safer for robots)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/aniti_rl_algo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;for hyperparameter tuning, Antonin recommends Optuna.&lt;/p&gt;

&lt;p&gt;about the Henderson paper: &lt;a href=&quot;https://arxiv.org/abs/1709.06560&quot;&gt;Deep Reinforcement Learning that Matters&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/aniti_rl_slr.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;and then the controller will use latent representation / current speed + history as observation space.&lt;/p&gt;

&lt;p&gt;Learning to drive takes then 10 min, and to race 2 hours.&lt;/p&gt;

&lt;h4 id=&quot;handson&quot;&gt;handson&lt;/h4&gt;

&lt;p&gt;slides: &lt;a href=&quot;https://araffin.github.io/slides/rlvs-sb3-handson/&quot;&gt;https://araffin.github.io/slides/rlvs-sb3-handson/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;notebook: &lt;a href=&quot;https://github.com/araffin/rl-handson-rlvs21&quot;&gt;https://github.com/araffin/rl-handson-rlvs21&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;RL zoo: &lt;a href=&quot;https://github.com/DLR-RM/rl-baselines3-zoo&quot;&gt;https://github.com/DLR-RM/rl-baselines3-zoo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;documentation for SB3 usefull for completing exercises: &lt;a href=&quot;https://stable-baselines3.readthedocs.io/en/master/&quot;&gt;https://stable-baselines3.readthedocs.io/en/master/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;https://excalidraw.com/&lt;/p&gt;</content><author><name></name></author><category term="reinforcement learning" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://castorfou.github.io/guillaume_blog/images/RL.png" /><media:content medium="image" url="https://castorfou.github.io/guillaume_blog/images/RL.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>