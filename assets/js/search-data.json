{
  
    
        "post0": {
            "title": "Generative Adversarial Networks (GANs) Specialization from Coursera",
            "content": "Coursera . Here is the course: Coursera: Gan Specialization . env installation . conda create -n gan python=3.7 conda activate gan conda install -c pytorch pytorch=1.4.0 .",
            "url": "https://castorfou.github.io/guillaume_blog/gan/pytorch/2020/10/01/gan-pytorch-coursera.html",
            "relUrl": "/gan/pytorch/2020/10/01/gan-pytorch-coursera.html",
            "date": " • Oct 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Use fingerprint to authenticate on Ubuntu, and passwordless on some apps",
            "content": "Fingerprint authentication . . Just by activating Fingerprint login, quite surprisingly it has been working directly. . Passwordless commands . Because I have changed my password for a quite complex one, I am interested to launch some sudo commands without prompt of password. . How to run sudo commands without password . Use visudo to update /etc/sudoers. I understand there is some syntax check to avoid mistake when editing this file. You don&#39;t want to be left with a defective sudo system. . I have just added this line. explore is my username. I can add additional commands after a comma (e.g. /bin/systemctl restart httpd.service, /bin/kill) . explore ALL = NOPASSWD: /usr/bin/apt .",
            "url": "https://castorfou.github.io/guillaume_blog/ubuntu/2020/10/01/fingerprint-authentication-sudoers.html",
            "relUrl": "/ubuntu/2020/10/01/fingerprint-authentication-sudoers.html",
            "date": " • Oct 1, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Upgrade ubuntu LTS 18.04 to 20.04",
            "content": "Standard upgrade process . As a LTS user, I want to keep using these long term support version. . !cat /etc/issue . Ubuntu 18.04.5 LTS n l . A good way to do it is by using do-release-upgrade tool. Full explanation at: 18.04 to 20.04. . sudo do-release-upgrade Checking for a new Ubuntu release There is no development version of an LTS available. To upgrade to the latest non-LTS develoment release set Prompt=normal in /etc/update-manager/release-upgrades. . Waiting for blockers to be fixed . There is a last blocker before releasing Ubuntu 20.04.1 LTS. . . Expected around 1st of October 2020. . (2020-09-28) blockers are fixed, upgrade in progress . Unfortunately the upgrade process went uneventful. Nothing broke, nothing to learn ;) . It took minutes to do the upgrade. . . Ubuntu releases-code names .",
            "url": "https://castorfou.github.io/guillaume_blog/ubuntu/2020/09/28/upgrade-ubuntu-18.04-to-20.04.html",
            "relUrl": "/ubuntu/2020/09/28/upgrade-ubuntu-18.04-to-20.04.html",
            "date": " • Sep 28, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Multiple subplots and animations with matplotlib",
            "content": "Subplots . What I want it to display multiple plots, with a given max rows. And to display my plots depending only on these parameters. . from fastai.tabular.all import * %matplotlib inline # fastai v1 backward compatibility import matplotlib.pyplot as plt import torch import torch.nn as nn import numpy as np . def my_hidden_f(x): return 4*x**3+2*x**2-12*x+5+10*torch.rand(x.shape) n=100 time = torch.ones(n,1) time[:,0].uniform_(-3.14,3.14) speed=my_hidden_f(time) plt.scatter(time[:,0], speed) plt.scatter(tensor(-1.5), my_hidden_f(tensor([-1.5])), color=&#39;red&#39;) def f(t, params): a,b,c,d = params return a*(t**3) + (b*t**2) + c*t + d def mse(preds, targets): return ((preds-targets)**2).mean() def show_preds(preds, ax=None): if ax is None: ax=plt.subplots()[1] ax.scatter(time, speed) ax.scatter(time, to_np(preds), color=&#39;red&#39;) ax.set_ylim(-50,150) lr = 1e-4 def apply_step(params, prn=True): preds = f(time, params) loss = mse(preds, speed) loss.backward() params.data -= lr * params.grad.data params.grad = None if prn: print(loss.item()) return preds . params = torch.randn(4).requires_grad_() #nbr of iterations max_iter = 1000 #nbr of curves visible nbr_graph = 4 #max number of curves on one row max_columns = 5 #nbr of rows max_rows = (nbr_graph-1) // max_columns + 1 #nbr of iter per plot graph_iteration = max_iter //(nbr_graph-1) _,axs = plt.subplots(nrows=max_rows,ncols=max_columns,figsize=(3*max_columns,3*max_rows)) i=-1 ax_index= ((i+1) // graph_iteration ) // (max_columns), ((i+1) // graph_iteration ) % (max_columns) if (max_rows ==1): ax_index= ((i+1) // graph_iteration ) % (max_columns) show_preds(apply_step(params, prn=False), axs[ax_index]) axs[ax_index].set_title(&#39;iter 0&#39;) for i in range(max_iter): preds=apply_step(params, prn=False) if ((i+1) % graph_iteration == 0): ax_index= ((i+1) // graph_iteration ) // (max_columns), ((i+1) // graph_iteration ) % (max_columns) if (max_rows ==1): ax_index= ((i+1) // graph_iteration ) % (max_columns) show_preds(preds, axs[ax_index]) axs[ax_index].set_title(&#39;iter &#39;+str(i+1)) plt.tight_layout() . Animation . import . %matplotlib inline # fastai v1 backward compatibility import matplotlib.pyplot as plt import torch import torch.nn as nn import numpy as np def tensor(*argv): return torch.tensor(argv) # TEST assert torch.all(tensor(1,2) == torch.tensor([1,2])), &#39;Backward compatibility with fastai v1&#39; . function and plot . n=100 x = torch.ones(n,1) x.uniform_(-3.14,3.14) def my_function(x, a): return ((torch.cat((x**3, x**2, x, torch.ones(n,1) ), 1))@a).reshape((n)) a=tensor(4., 2., -12., 5.) y = my_function(x, a) a = tensor(-1.,-2., 6., -8) y_hat = my_function(x, a) plt.scatter(x[:,0], y) plt.scatter(x[:,0],y_hat); def mse(y_hat, y): return ((y_hat-y)**2).mean() . gradient descent . a = nn.Parameter(a); a def update(): y_hat = my_function(x, a) loss = mse(y, y_hat) if t % 10 == 0: print(loss) loss.backward() with torch.no_grad(): a.sub_(lr * a.grad) a.grad.zero_() lr = 1e-3 for t in range(100): update() . tensor(1967.0251, grad_fn=&lt;MeanBackward0&gt;) tensor(559.2718, grad_fn=&lt;MeanBackward0&gt;) tensor(365.7207, grad_fn=&lt;MeanBackward0&gt;) tensor(282.6393, grad_fn=&lt;MeanBackward0&gt;) tensor(245.4054, grad_fn=&lt;MeanBackward0&gt;) tensor(227.3450, grad_fn=&lt;MeanBackward0&gt;) tensor(217.3324, grad_fn=&lt;MeanBackward0&gt;) tensor(210.7267, grad_fn=&lt;MeanBackward0&gt;) tensor(205.5912, grad_fn=&lt;MeanBackward0&gt;) tensor(201.1171, grad_fn=&lt;MeanBackward0&gt;) . animation . from matplotlib import animation, rc rc(&#39;animation&#39;, html=&#39;jshtml&#39;) a = nn.Parameter(tensor(-1.,1)) a=tensor(4., 2., -12., 5.) y = my_function(x, a) a = tensor(-1.,-2., 6., -8) y_hat = my_function(x, a) a = nn.Parameter(a); a fig = plt.figure() plt.scatter(x[:,0], y, c=&#39;orange&#39;) line = plt.scatter(x[:,0], y_hat.detach()) plt.close() def animate(i): line.set_offsets(np.c_[x[:,0], (my_function(x,a)).detach()]) update() return line, animation.FuncAnimation(fig, animate, np.arange(0, 300), interval=5) . &lt;/input&gt; Once Loop Reflect",
            "url": "https://castorfou.github.io/guillaume_blog/matplotlib/2020/09/26/Matplotlib-multiple-subplots-and-animations.html",
            "relUrl": "/matplotlib/2020/09/26/Matplotlib-multiple-subplots-and-animations.html",
            "date": " • Sep 26, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastai book Deep Learning for Coders with fastai and Pytorch",
            "content": "Paper version of fastai book . Of course the 1st tep is to purchase this great book: . . I have liked what Jeremy Howard said about why this is important to purchase it (in video 1). Fastai is offering full access to the book as notebooks. So that we can run all codes from them. . Get notebook version of fastai book . ~/git/guillaume$ git clone https://github.com/fastai/fastbook.git . . I have now a perfect combo between paper book and notebooks. . Video courses based on fastai book . Rachel Thomas and Jeremy Howard have done some great videos about learning fastai (and pytorch). . They tend to do it every year. But this year is quite special due to fastai book. . Here are all the 1st 7 videos: https://course.fast.ai/videos/?lesson=1 . Fastai forums . This is the natural source of information and interactions with other students. . There is a category Part 1 (2020) which seems perfect: https://forums.fast.ai/c/part1-v4/46 . Personal git organization . ~/git/guillaume$ ll fastai/ &lt;-- from https://github.com/fastai/fastai fastai_experiments/ &lt;-- I will keep all experiments I will do here fastbook/ &lt;-- from https://github.com/fastai/fastbook.git guillaume_blog/ &lt;-- from git@github.com:castorfou/guillaume_blog.git . fastai_experiments likely to have 1 notebook per chapter or video. . update jupyter to include extensions (toc, ...) . conda install -c conda-forge jupyter_contrib_nbextensions . I like table of content, others are quite usefull as well (scratchpad, ExecuteTime...). . Install some libraries to run book examples . conda install -c fastai fastbook . It will install graphviz, nbdev, and other libraries. . And most of them can be loaded by calling from utils import * . Launch jupyter notebook and start expermenting . cd ~/git/guillaume conda activate fastai jupyter notebook . And launch several tabs at: blog entries, fastai experiments, fastai courses and fastai videos. . And I keep track of progress with git. .",
            "url": "https://castorfou.github.io/guillaume_blog/fastai/jupyter/fastbook/2020/09/24/fastai-book.html",
            "relUrl": "/fastai/jupyter/fastbook/2020/09/24/fastai-book.html",
            "date": " • Sep 24, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Setup ubuntu box with fastai",
            "content": "Install miniconda . Get miniconda Linux installer. . Check sha256sum: sha256sum Miniconda3-latest-Linux-x86_64.sh . Run install: ./Miniconda3-latest-Linux-x86_64.sh -p $HOME/miniconda3 . Install fastai . conda create -n fastai python=3.8 conda activate fastai conda install -c fastai -c pytorch fastai . Install jupyter within fastai environment . conda activate fastai conda install jupyter . Test fastai installation (valid for v1) . With fastai v1, there was an easy way to check installation: . conda activate fastai python -m fastai.utils.show_install . get git repo to learn from fastai . From git folder, . git clone https://github.com/fastai/fastai . Test fastai v2 installation . From python environment: . from fastai.vision.all import * . From jupyter notebook . from fastai.vision.all import * . Install nvidia drivers for ubuntu . I tried by downloading a driver from nvidia website. But I was unable to install it (nvidia-drm-drv.c:662:44: error: &#39;DRIVER_PRIME&#39; undeclared here (not in a function); did you mean &#39;DRIVER_PCI_DMA&#39;?) . sudo ubuntu-drivers autoinstall . then rebooting fixed the issue. . Run courses from fastai github repo . just run fastai/dev_nbs/course/lesson1-pets.ipynb . And everything is just fined ;) . install nbdev . This is for rendering reasons: To get a prettier result with hyperlinks to source code and documentation, install nbdev: pip install nbdev . !pip install nbdev . Collecting nbdev Downloading nbdev-1.0.18-py3-none-any.whl (57 kB) |████████████████████████████████| 57 kB 1.5 MB/s eta 0:00:01 Requirement already satisfied: fastcore&gt;=1.0.5 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (1.0.13) Requirement already satisfied: packaging in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (20.4) Requirement already satisfied: jupyter-client in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (6.1.6) Requirement already satisfied: nbconvert&lt;6 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.6.1) Requirement already satisfied: nbformat&gt;=4.4.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.0.7) Collecting fastscript&gt;=1.0.0 Downloading fastscript-1.0.0-py3-none-any.whl (11 kB) Requirement already satisfied: pyyaml in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.3.1) Requirement already satisfied: pip in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (20.2.2) Requirement already satisfied: ipykernel in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.3.4) Requirement already satisfied: pyparsing&gt;=2.0.2 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from packaging-&gt;nbdev) (2.4.7) Requirement already satisfied: six in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from packaging-&gt;nbdev) (1.15.0) Requirement already satisfied: pyzmq&gt;=13 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (19.0.2) Requirement already satisfied: tornado&gt;=4.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (6.0.4) Requirement already satisfied: python-dateutil&gt;=2.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (2.8.1) Requirement already satisfied: traitlets in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (4.3.3) Requirement already satisfied: jupyter-core&gt;=4.6.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (4.6.3) Requirement already satisfied: pandocfilters&gt;=1.4.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (1.4.2) Requirement already satisfied: pygments in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (2.7.1) Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.8.4) Requirement already satisfied: defusedxml in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.6.0) Requirement already satisfied: bleach in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (3.2.1) Requirement already satisfied: jinja2&gt;=2.4 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (2.11.2) Requirement already satisfied: testpath in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.4.4) Requirement already satisfied: entrypoints&gt;=0.2.2 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.3) Requirement already satisfied: jsonschema!=2.5.0,&gt;=2.4 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbformat&gt;=4.4.0-&gt;nbdev) (3.0.2) Requirement already satisfied: ipython-genutils in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbformat&gt;=4.4.0-&gt;nbdev) (0.2.0) Requirement already satisfied: ipython&gt;=5.0.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipykernel-&gt;nbdev) (7.18.1) Requirement already satisfied: decorator in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from traitlets-&gt;jupyter-client-&gt;nbdev) (4.4.2) Requirement already satisfied: webencodings in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from bleach-&gt;nbconvert&lt;6-&gt;nbdev) (0.5.1) Requirement already satisfied: MarkupSafe&gt;=0.23 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jinja2&gt;=2.4-&gt;nbconvert&lt;6-&gt;nbdev) (1.1.1) Requirement already satisfied: pyrsistent&gt;=0.14.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (0.17.3) Requirement already satisfied: attrs&gt;=17.4.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (20.2.0) Requirement already satisfied: setuptools in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (49.6.0.post20200814) Requirement already satisfied: backcall in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.2.0) Requirement already satisfied: pexpect&gt;4.3; sys_platform != &#34;win32&#34; in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (4.8.0) Requirement already satisfied: pickleshare in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.7.5) Requirement already satisfied: jedi&gt;=0.10 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.17.2) Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (3.0.7) Requirement already satisfied: ptyprocess&gt;=0.5 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from pexpect&gt;4.3; sys_platform != &#34;win32&#34;-&gt;ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.6.0) Requirement already satisfied: parso&lt;0.8.0,&gt;=0.7.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jedi&gt;=0.10-&gt;ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.7.0) Requirement already satisfied: wcwidth in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.2.5) Installing collected packages: fastscript, nbdev Successfully installed fastscript-1.0.0 nbdev-1.0.18 .",
            "url": "https://castorfou.github.io/guillaume_blog/fastai/cuda/linux/2020/09/23/Setup-ubuntu-box-with-fastai.html",
            "relUrl": "/fastai/cuda/linux/2020/09/23/Setup-ubuntu-box-with-fastai.html",
            "date": " • Sep 23, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Fastai on WSL 2 with Cuda",
            "content": "This is based on what is explained in https://forums.fast.ai/t/fastai-on-wsl-2-ubuntu-0-7-0-or-any-version/76651 . install update of nvidia drivers . Based on Deep Learning Course Forums Platform: Windows 10 using WSL2 w/GPU fastai users . create nvidia account | download quadro driver from https://developer.nvidia.com/cuda/wsl/download (460.15) | install | . (xgboost) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog$ nvidia-smi.exe Mon Sep 21 16:00:46 2020 +--+ | NVIDIA-SMI 460.15 Driver Version: 460.15 CUDA Version: 11.1 | |-+-+-+ | GPU Name TCC/WDDM | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Quadro M1000M WDDM | 00000000:01:00.0 On | N/A | | N/A 59C P0 N/A / N/A | 905MiB / 4096MiB | 0% Default | +-+-+-+ . install of WSL2 and convert existing images . Open a PowerShell window as an Administrator . Run wsl --set-default-version 2 . update KB . . --set-default-version 2 is not a valid option. KB4566116 should be installed . This can be downloaded from Catalog Microsoft Update . update kernel version . If you see this message after running the command: WSL 2 requires an update to its kernel component. For information please visit https://aka.ms/wsl2kernel. You still need to install the MSI Linux kernel update package. . Download from https://docs.microsoft.com/en-us/windows/wsl/install-win10#step-4download-the-linux-kernel-update-package . set default WSL to be version 2 . PS C: WINDOWS system32&gt; wsl --set-default-version 2 . convert existing images . PS C: WINDOWS system32&gt; wsl --list --verbose NAME STATE VERSION * Ubuntu-18.04 Running 1 PS C: WINDOWS system32&gt; wsl --set-version Ubuntu-18.04 2 La conversion est en cours. Cette opération peut prendre quelques minutes... Pour plus d’informations sur les différences de clés avec WSL 2, visitez https://aka.ms/wsl2 La conversion est terminée. . It took a while (~1 hour) for my unique ubuntu image. . And at the end it has worked. . PS C: WINDOWS system32&gt; wsl --list --verbose NAME STATE VERSION * Ubuntu-18.04 Stopped 2 . install of nvidia drivers under ubuntu . [Installation instructions)(https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1804&amp;target_type=deblocal) . wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.3-450.51.06-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.3-450.51.06-1_amd64.deb sudo apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub sudo apt-get update sudo apt-get -y install cuda . !cat /usr/local/cuda/version.txt . CUDA Version 11.0.228 . !/usr/local/cuda/samples/4_Finance/BlackScholes/BlackScholes . [/usr/local/cuda/samples/4_Finance/BlackScholes/BlackScholes] - Starting... CUDA error at ../../common/inc/helper_cuda.h:777 code=35(cudaErrorInsufficientDriver) &#34;cudaGetDeviceCount(&amp;device_count)&#34; . There is an error when launching CUDA samples. Googling that error maybe my video card is running on low driver version? . I have posted on nvidia (cuda+wsl) forum: https://forums.developer.nvidia.com/t/cuda-sample-throwing-error/142537/18 . (update 09-22: it is not possible to have cuda on wsl2 if not in Windows Insider build from Dev Channel. (20145 or higher)) . . because I am in version 1909 (18363.1049), it won&#39;t work for me. ;( . cuda for WSL . Here is a link that could be interesting: https://docs.nvidia.com/cuda/wsl-user-guide/index.html . According to this, I should not have installed cuda but cuda-toolkit. Do not choose the cuda, cuda-11-0, or cuda-drivers meta-packages under WSL 2 since these packages will result in an attempt to install the Linux NVIDIA driver under WSL 2. . Is it causing my issue? . apt-get install -y cuda-toolkit-11-0 . !/usr/local/cuda/bin/nvcc --version . nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2020 NVIDIA Corporation Built on Wed_Jul_22_19:09:09_PDT_2020 Cuda compilation tools, release 11.0, V11.0.221 Build cuda_11.0_bu.TC445_37.28845127_0 . install a new distro (ubuntu 20.04) . Because I cannot use windows store, I have to manually install https://docs.microsoft.com/fr-fr/windows/wsl/install-manual . Installation by just launching Ubuntu_2004.2020.424.0_x64.appx. . I have now 2 distros, . PS C: WINDOWS system32&gt; wsl --list -v NAME STATE VERSION * Ubuntu-18.04 Running 2 Ubuntu-20.04 Running 2 . WSL2 and network . There is a change of network architecture between WSL 1 and WSL 2. In WSL 2, a new network interface is available: . Carte Ethernet vEthernet (WSL) : Suffixe DNS propre à la connexion. . . : Adresse IPv6 de liaison locale. . . . .: Adresse IPv4. . . . . . . . . . . . . .: 192.168.81.193 Masque de sous-réseau. . . . . . . . . : 255.255.255.240 Passerelle par défaut. . . . . . . . . : . Revert image to WSL1 to get back network access . PS C: WINDOWS system32&gt; wsl --set-version Ubuntu-18.04 1 La conversion est en cours. Cette opération peut prendre quelques minutes... La conversion est terminée. . PS C: WINDOWS system32&gt; wsl --list -v NAME STATE VERSION * Ubuntu-18.04 Stopped 1 Ubuntu-20.04 Stopped 2 . access to linux files from windows . For running state distros: . Files are available at wsl$ . . For stopped state distros: . Files are available at C: Users &lt;users&gt; AppData Local Packages CanonicalGroupLimited.Ubuntu* LocalState rootfs .",
            "url": "https://castorfou.github.io/guillaume_blog/wsl/fastai/wsl2/cuda/2020/09/21/Windows10-fastai-wsl2-cuda.html",
            "relUrl": "/wsl/fastai/wsl2/cuda/2020/09/21/Windows10-fastai-wsl2-cuda.html",
            "date": " • Sep 21, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Autodetect Home / Office network + Proxy",
            "content": "IP detection . Command to get IP address is as follow: . IP=`ifconfig | grep &#39;inet &#39;| grep -v &#39;127.0.0.1&#39; | cut -d: -f2 | awk &#39;{ print $2}&#39;` . I can then check how IP is setup: . empty: no network attached, in that case nothing to do | HOME_IP=192.168.1.241: based on MAC I give fixed IP to my computers (out of DHCP scope) | S8_IP=192.168.: hotspot from samsung is using 192.168. addresses | OFFICE_IP=10.: office network uses 10. addresses | . Detect if variable IP is set: . if [ -z &quot;$IP&quot; ]; then echo &quot;Not connected to any network&quot; fi . Network detection and proxy settings . Depending on my network, I have to set or unset proxy. . Here is the 1st version: . (xgboost) guillaume@LL11LPC0PQARQ:~$ cat my_ip.sh #!/bin/bash IP=`ifconfig | grep &#39;inet &#39;| grep -v &#39;127.0.0.1&#39; | cut -d: -f2 | awk &#39;{ print $2}&#39;` HOME_IP=192.168.1.241 OFFICE_IP=10. S8_IP=192.168. # Set Proxy function setproxy() { echo &quot;Calling setproxy&quot; export {http,https,ftp}_proxy=&quot;http://proxy_ip:80&quot; export {HTTP,HTTPS,FTP}_PROXY=&quot;http://proxy_ip:80&quot; } # Unset Proxy function unsetproxy() { echo &quot;Calling unsetproxy&quot; unset {http,https,ftp}_proxy unset {HTTP,HTTPS,FTP}_PROXY } if [ -z &quot;$IP&quot; ]; then echo &quot;Not connected to any network&quot; else echo &quot;Connected and IP address is: $IP&quot; if [[ &quot;$IP&quot; == &quot;$HOME_IP&quot; ]]; then echo &quot;Connected at home from freebox pop --&gt; no proxy&quot; unsetproxy else if [[ &quot;$IP&quot; == &quot;$S8_IP&quot;* ]]; then echo &quot;Connected with mobile phone --&gt; no proxy&quot; unsetproxy fi if [[ &quot;$IP&quot; == &quot;$OFFICE_IP&quot;* ]]; then echo &quot;Connected from Office --&gt; proxy&quot; setproxy fi fi fi . Call this script: source . If I want these environment variables to be available from parent shell, I have to call my script with source. . (xgboost) guillaume@LL11LPC0PQARQ:~$ source my_ip.sh Connected and IP address is: 10.xxx.xxx.xxx 192.168.1.241 Connected from Office --&gt; proxy Calling setproxy . And I will auto launch this script each time I open a terminal by adding source my_ip.sh at the end of .bashrc . git and keep dot configuration files: config . Another great practice from Jeremy Howard: From https://developer.atlassian.com/blog/2016/02/best-way-to-store-dotfiles-git-bare-repo/ and https://www.atlassian.com/git/tutorials/dotfiles . I will create a blog entry about that later. . config add .bashrc my_ip.sh config commit -m &#39;detect network and set proxy&#39; config push . wget: proxy / no proxy . I store proxy conf files under ~/proxy_files/ . For wget: 2 files . $ cat proxy_files/.wgetrc_noproxy use_proxy=no $ cat proxy_files/.wgetrc_proxy use_proxy=yes http_proxy=proxy_ip:80 https_proxy=proxy_ip:80 . And enabling proxy for wget: ln -sf ~/proxy_files/.wgetrc_proxy ~/.wgetrc . Disabling proxy for wget: ln -sf ~/proxy_files/.wgetrc_noproxy ~/.wgetrc . So the updated functions setproxy and unsetproxy are: . # Set Proxy function setproxy() { echo &quot;Calling setproxy&quot; export {http,https,ftp}_proxy=&quot;http://proxy_ip:80&quot; export {HTTP,HTTPS,FTP}_PROXY=&quot;http://proxy_ip:80&quot; #proxy for wget ln -sf ~/proxy_files/.wgetrc_proxy ~/.wgetrc } # Unset Proxy function unsetproxy() { echo &quot;Calling unsetproxy&quot; unset {http,https,ftp}_proxy unset {HTTP,HTTPS,FTP}_PROXY #no proxy for wget ln -sf ~/proxy_files/.wgetrc_noproxy ~/.wgetrc } . apt-get: proxy / no proxy . I store proxy conf files under ~/proxy_files/ . For apt, 1 file . $ cat proxy_files/apt_proxy.conf Acquire { HTTP::proxy &quot;http://proxy_ip:80&quot;; HTTPS::proxy &quot;http://proxy_ip:80&quot;; } . And enabling proxy for apt: sudo ln -sf ~/proxy_files/apt_proxy.conf /etc/apt/apt.conf.d/proxy.conf . Disabling proxy for wget: sudo rm -f /etc/apt/apt.conf.d/proxy.conf . . Refactor to avoid password request each time it is launched . So the updated functions setproxy and unsetproxy are: . # Set Proxy function setproxy() { echo &quot;Calling setproxy&quot; export {http,https,ftp}_proxy=&quot;http://proxy_ip:80&quot; export {HTTP,HTTPS,FTP}_PROXY=&quot;http://proxy_ip:80&quot; #proxy for wget ln -sf ~/proxy_files/.wgetrc_proxy ~/.wgetrc #proxy for apt sudo ln -sf ~/proxy_files/apt_proxy.conf /etc/apt/apt.conf.d/proxy.conf } # Unset Proxy function unsetproxy() { echo &quot;Calling unsetproxy&quot; unset {http,https,ftp}_proxy unset {HTTP,HTTPS,FTP}_PROXY #no proxy for wget ln -sf ~/proxy_files/.wgetrc_noproxy ~/.wgetrc #no proxy for apt sudo rm -f /etc/apt/apt.conf.d/proxy.conf } . Sept-21 2020: IP detection to be changed after WSL2 . With WSL2, IP address is from 172 network. . This looks like a virtual internal address. More detail at that address: https://github.com/microsoft/WSL/issues/4150. . . to update IP detection .",
            "url": "https://castorfou.github.io/guillaume_blog/wsl/linux/bash/2020/09/15/autodetect-home-office-network-and-proxy-settings.html",
            "relUrl": "/wsl/linux/bash/2020/09/15/autodetect-home-office-network-and-proxy-settings.html",
            "date": " • Sep 15, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Fast read Excel files with pandas",
            "content": "Problem description . initial settings . measure_time decorator . from functools import wraps from time import time def measure_time(func): @wraps(func) def _time_it(*args, **kwargs): start = int(round(time() * 1000)) try: return func(*args, **kwargs) finally: end_ = int(round(time() * 1000)) - start print(f&quot;Total execution time: {end_ if end_ &gt; 0 else 0} ms&quot;) return _time_it . read big excel file with pandas . big_excel_file = root_data+&#39;/pandas-caching/big_excel_file.xlsx&#39; . @measure_time def load_excel(file): dataframe = pd.read_excel(file) return dataframe . dataframe = load_excel(big_excel_file) . Total execution time: 36196 ms . . Waouh, 36 sec to read this file! . read converted csv file (turned to csv from excel using excel) . csv_file = root_data+&#39;/pandas-caching/big_csv_file_turned_from_excel.csv&#39; . @measure_time def load_csv(file): dataframe = pd.read_csv(file, sep=&#39;;&#39;, decimal=&#39;,&#39;) return dataframe . df_csv = load_csv(csv_file) . Total execution time: 836 ms . . Much better, 0.8 sec! . Caching library . import os def read_CachedXLS(filename, forceReload = False, **options): &quot;&quot;&quot; Part d&#39;un fichier excel natif (filename). Si le dataframe caché correspondant n&#39;existe pas encore, alors sauve le dataframe caché au format csv dans le rep source. (s&#39;il existe et si forceReload==True, alors écrase le dataframe caché existant par une nouvelle version) Lit le dataframe caché correspondant avec les **options et retourne le dataframe. Examples -- &gt;&gt;&gt; filename = &#39;/mnt/z/data/Stam-CC/ExportData 25625.xlsx&#39; forceReload = False option={&#39;dayfirst&#39;:True, &#39;parse_dates&#39;:[&#39;Fecha de Medida&#39;, &#39;Fecha de Fabricacion&#39;], &#39;sheetname&#39;:0} getCachedXLSRaw(filename, forceRelead, **option).info() Parameters - filename : string Emplacement du fichier XLS. Avec l&#39;extension. Format complet Ex: &#39;/mnt/z/data/Stam-CC/ExportData 25625.xlsx&#39; forceReload : boolean, optional, default value = False Si forceReload == True, le fichier sera relu et sauvé même s&#39;il existe déjà en cache options : **keyword args, optional Arguments de lecture du fichier XLS : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html Ex: sheetname=1 Returns - dataframe Dataframe correspondant &quot;&quot;&quot; #split pour ne garder que le nom sans le chemin de filename : Stam-CC/ExportData 25625 --&gt; ExportData 25625 dataframe_filename = os.path.dirname(filename)+&#39;/&#39;+os.path.basename(filename)+&#39;.csv&#39; #bug de pandas.to_csv quand il y a des espaces ? dataframe_filename = dataframe_filename.replace(&quot; &quot;, &quot;_&quot;) dataframe=[] xls_toget = False #print(dataframe_filename) if (forceReload and os.path.exists(dataframe_filename)): print(&quot;Cached file &quot;+dataframe_filename+&quot; déjà existant mais forceReload=True - FORCE RELOAD&quot;) xls_toget = True if (not os.path.exists(dataframe_filename)): print(&quot;Cached file &quot;+dataframe_filename+&quot; inexistant - read_CachedXLS&quot;) xls_toget = True if (xls_toget): dataframe = pd.read_excel(filename, **options) dataframe.to_csv(dataframe_filename) else: print(&quot;Cached file &quot;+dataframe_filename+&quot; existe en cache, relecture&quot;) #index_col pour ignorer les n° de lignes excel options[&#39;sep&#39;]=&#39;,&#39; options[&#39;decimal&#39;]=&#39;.&#39; options[&#39;skiprows&#39;]=0 options.pop(&#39;sheet_name&#39;) dataframe = pd.read_csv(dataframe_filename,**options) return dataframe . option={&#39;sheet_name&#39;:0} read_CachedXLS(big_excel_file, **option) print(&quot;et voila&quot;) . Cached file /mnt/z/data//pandas-caching/big_excel_file.xlsx.csv existe en cache, relecture et voila .",
            "url": "https://castorfou.github.io/guillaume_blog/pandas/2020/09/14/fast-read-excel-pandas.html",
            "relUrl": "/pandas/2020/09/14/fast-read-excel-pandas.html",
            "date": " • Sep 14, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Git push to github without password",
            "content": "By default everytime I push to github, I have a prompt asking for password. . (xgboost) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog$ git push Username for &#39;https://github.com&#39;: castorfou Password for &#39;https://castorfou@github.com&#39;: Everything up-to-date . Would be great if I could leverage ssh keys to authenticate. . Update remote from https to ssh . From https://stackoverflow.com/questions/14762034/push-to-github-without-a-password-using-ssh-key, . For example, a GitHub project like Git will have an HTTPS URL: https://github.com/&lt;Username&gt;/&lt;Project&gt;.git And the SSH one: git@github.com:&lt;Username&gt;/&lt;Project&gt;.git You can do: git remote set-url origin git@github.com:&lt;Username&gt;/&lt;Project&gt;.git to change the URL. . In my case I have . (xgboost) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog$ git remote -v origin https://github.com/castorfou/guillaume_blog.git (fetch) origin https://github.com/castorfou/guillaume_blog.git (push) . I have just to modify: . git remote set-url origin git@github.com:castorfou/guillaume_blog.git . Results . It looks like working: . (xgboost) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog$ git push Counting objects: 4, done. Delta compression using up to 8 threads. Compressing objects: 100% (4/4), done. Writing objects: 100% (4/4), 1.59 KiB | 812.00 KiB/s, done. Total 4 (delta 2), reused 0 (delta 0) remote: Resolving deltas: 100% (2/2), completed with 2 local objects. To github.com:castorfou/guillaume_blog.git 4013108..ae78b99 master -&gt; master . Drawback: doesn&#39;t work behing a firewall . . To find a solution to use a proxy . Here are 2 ways to be tested: https://stackoverflow.com/questions/1728934/accessing-a-git-repository-via-ssh-behind-a-firewall https://stackoverflow.com/questions/18604719/how-to-configure-git-to-clone-repo-from-github-behind-a-proxy-server?noredirect=1&amp;lq=1 .",
            "url": "https://castorfou.github.io/guillaume_blog/git/2020/09/11/git-commit-without-password.html",
            "relUrl": "/git/2020/09/11/git-commit-without-password.html",
            "date": " • Sep 11, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Blog from jupyter notebook",
            "content": "That will be great if I can simply write blog entries using Jupyter Notebook. . I usually paste inner images into jupyter cells. But this feature is not available yet into fastpages. So for the moment I won&#39;t include images into these posts. . That way I could simply use markdown and insert images . And directly see rendered impact before commiting and pushing to my blog. . get local repo from github . As I am behind a proxy most of my time when working from office, the easiest way for me is to work from WSL. . WSL . I won&#39;t detail how to install WSL on Windows. . I use ubuntu images (18.04) on my PC. . set unset proxy in WSL . I have just added some bash commands at the end of my .bashrc file. . # Set Proxy function setproxy() { export {http,https,ftp}_proxy=&quot;http://&lt;my proxy ip address&gt;:80&quot; export {HTTP,HTTPS,FTP}_PROXY=&quot;http://&lt;my proxy ip address&gt;:80&quot; } # Unset Proxy function unsetproxy() { unset {http,https,ftp}_proxy unset {HTTP,HTTPS,FTP}_PROXY } . git clone castorfou.github.io . I keep most of my local repos under ~/git/ . cd ~/git setproxy git clone https://github.com/castorfou/castorfou.github.io.git . create a blog entry with Jupyter Notebook . commit and push to github . (base) guillaume@LL11LPC0PQARQ:~$ cd git (base) guillaume@LL11LPC0PQARQ:~/git$ cd castorfou.github.io/ (base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git add . (base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git commit -m &#39;new blog entry: blog from jupyter&#39; [master 6b7460a] new blog entry: blog from jupyter 4 files changed, 516 insertions(+) create mode 100644 _posts/.ipynb_checkpoints/2020-09-10-blog-from-jupyter-checkpoint.ipynb create mode 100644 _posts/2020-09-10-blog-from-jupyter.ipynb create mode 100644 _posts/2020-09-10-blog-from-jupyter.py create mode 100644 _posts/Untitled.txt (base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git push fatal: unable to access &#39;https://github.com/castorfou/castorfou.github.io.git/&#39;: gnutls_handshake() failed: The TLS connection was non-properly terminated. . error: gnutls_handshake() failed: The TLS connection was non-properly terminated. . Just googling this error gives some insight: https://github.community/t/unable-to-push-to-repo-gnutls-handshake-failed/885 . It is likely some local firewell issue. . . To be fixed later . switch to mobile wifi without need of proxy . (base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ unsetproxy (base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git push Username for &#39;https://github.com&#39;: castorfou Password for &#39;https://castorfou@github.com&#39;: Counting objects: 7, done. Delta compression using up to 8 threads. Compressing objects: 100% (6/6), done. Writing objects: 100% (7/7), 141.26 KiB | 10.09 MiB/s, done. Total 7 (delta 1), reused 0 (delta 0) remote: Resolving deltas: 100% (1/1), completed with 1 local object. remote: remote: GitHub found 3 vulnerabilities on castorfou/castorfou.github.io&#39;s default branch (2 high, 1 moderate). To find out more, visit: remote: https://github.com/castorfou/castorfou.github.io/network/alerts remote: To https://github.com/castorfou/castorfou.github.io.git 6adeb02..6b7460a master -&gt; master . check entries into blog . double entries . Double entries: one for the notebook (.ipynb) and one for the auto python export (.py). I will have to update my jupyter settings to avoid this python file creation. In the meantime I can just delete the python file, and commit. . . Change settings of jupyter + .gitignore to avoid these double entries . cannot open notebook into browser . Clicking just ask me to download the notebook, it doesn&#39;t display it into the browser. . checking .gitignore . Just by looking into .gitignore, there is an interesting entry: . *.swp ~* *~ _site .sass-cache .jekyll-cache .jekyll-metadata vendor _notebooks/.ipynb_checkpoints . Wait what is in this last line. . Let&#39;s create _notebooks directory and move my notebook in that directory. . notebooks from _notebooks not rendered . No entries, I guess there is some additional settings to do... . . Why notebooks are not rendered by Jekyl . test entry from md using local repo . There is no problem with that. . Creating a local md file in _poststhen pushing to github is creating the right entry blog. . following fastpages troubleshooting guide . upgrade fastpages . Try the automated upgrade as described in https://github.com/fastai/fastpages/blob/master/_fastpages_docs/UPGRADE.md . Unfortunately I don&#39;t see . I have to follow the manual upgrade. . manual fastpages upgrade . I am surprised because the 1st step from manual upgrade is to copy the fastpages repo. It is what I did 2 days ago. I doubt having an outdated version of fastpages. . fastai forum: fastpages category . I will browse through nbdev &amp; faspages category in fastai forums. I should see people with the same issue. . I have created an entry, into fastai forums: Fastpages - cannot see build process of GitHub Actions . And quite immediately Hamel Hussain answered guiding to the write direction: . I misread the Settings instruction: my github repo should explicitely NOT include my github username and I did exactly the opposite. . . I have to create a new repo: guillaume_blog . nothing visible from Actions tab . And another surprising subject: at github in Actions tab. I have a kind of default page. I expect something like an execution journal of Actions. . Page build failure . Received a notification by email: . The page build failed for the master branch with the following error: . Page build failed. For more information, see https://docs.github.com/github/working-with-github-pages/troubleshooting-jekyll-build-errors-for-github-pages-sites#troubleshooting-build-errors. . For information on troubleshooting Jekyll see: . https://docs.github.com/articles/troubleshooting-jekyll-builds . If you have any questions you can submit a request on the Contact GitHub page at https://support.github.com/contact?repo_id=293820308&amp;page_build_id=202240535 . Move to another repo . repo creation . It was just a matter of creating a new repo: . actions monitoring . Monitoring is effective . merge pull request . actions around ssh keys . Following the steps: . Create keys using ssh utility | Enter Secret Key | Enter Deploy Key | . merge PR . There are conflicts to be fixed before that. . And it works: https://castorfou.github.io/guillaume_blog/ . Get local repo . cd ~/git unsetproxy git clone https://github.com/castorfou/guillaume_blog.git .",
            "url": "https://castorfou.github.io/guillaume_blog/fastpages/jupyter/notebooks/2020/09/10/blog-from-jupyter-sans-images.html",
            "relUrl": "/fastpages/jupyter/notebooks/2020/09/10/blog-from-jupyter-sans-images.html",
            "date": " • Sep 10, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Blogging from github",
            "content": "Blogging from github . fastai and fastpages . I am a big fan of fastai’s spirit and even more of their leaders: . Jeremy Howards | Rachel Thomas | Sylvain Gugger who is know at huggingface. | . They are commited to beautiful ideas, and are inspiring people. I like their courses. I like their softwares. For sure I will discuss about fastai. They have created fastpages. It turns github into a blogging platform. I don’t have the full detail but it is explained in fastpages github repo It is based on github actions, and by just creating a repo from a fastpages template https://github.com/fastai/fast_template/generate and giving a couple of settings, you are ready to go. . And here I have to thank Hamel Husain. He is from github company and I think he is behing github actions and helped fastai to release fastpages. I don’t know Hamel but he looks like a humble, terribly skilled guy, with tons of energy. Thanks Hamel. . my blog . My main audience is the future me. (maybe not entirely true otherwise I would have written in French) In 1 year, I want to turn back to this blog and I would like to see all the learning peaces I went through. I want this platform to be as easy as possible. . fastpages . For the moment it cannot be easier. I have setup the about page. And each blog entry is just a new markdown page into _posts. github _posts: . . By commiting this page, there are internal actions being run automatically (through github actions magic) and after a couple of minutes the new blog pages are generated (using Jekyl and ruby if I am not wrong). For the moment I use github web interface. But I guess it is easier to have a local repo of my blog, create new entries and when satisfied git push to github. (to be tested later) . github accounts . For a reason I used my personal github account (guillaume.ramelet@gmail.com) and not my professional one (guillaume.ramelet@michelin.com). I will see later if I have to move to another account. I had some troubles to setup actions into github. For a reason I thought it was available only for organization account. So I have turned my michelin github account to an organization, and I cannot login anymore. To be fixed later. . markdown . Ok I am not a huge fan of markdown. I use it as a basic text system specially within notebooks. But it is not as easy to insert images. Currently I screenshot what I want to share, insert into images folder of my repo and reference this image from my blog post using markdown language. I definitely have to improve my practice of markdown, and there are multiple cheatsheets to be used. . jupyter . There are options within fastpages to blog from jupyter notebooks. I have to do it. My intent will be to use this place to share my knowledge. Today most of my knowledge comes from experiences I make within jupyter. If I could directly blog from that it will be great. . comments . OK as the sole reader this is maybe a minor concern but there is no commenting system associated with fastpages. I cannot get any feedback from these entries. Would love to get advices, create discussions within that blog. Not for today. .",
            "url": "https://castorfou.github.io/guillaume_blog/blog/fastpages/git/2020/09/09/blogging-from-github.html",
            "relUrl": "/blog/fastpages/git/2020/09/09/blogging-from-github.html",
            "date": " • Sep 9, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Becoming a datascientist",
            "content": "March 2019 . This journey has started about 1 year ago. . No wait, that was dormant for a long time before that. I guess I have to go back to my studying time: at that time my days were full of maths and computers. And my days were flying as crazy. It happens to me (to you?) when you’re just in a middle of something you like very much. 10 hours looks like 1. And the opposite is true as well. . 2000 - 2004: software development . Most of my days and weekends at that time were dedicated to code in Java and bash. Java mainly for server-side developpement in J2EE at Unilog Management. Bash from time to time to automate some tasks on my personal PC. At that time it was mainly about learning what is an operating system. I had started with LFS (Linux From Scratch). And in 2002 with Gentoo which was a much more powerful way to mimic LFS. . 2004 - 2009: project management . Strange period. I don’t remember exactly why but I had a shift in my professional orientation. I moved away from software development and turned into a project manager. In 2005 I entered into Michelin company. And sofwtare technical matters at that time were considered as unimportant (and embarrassing subjects) Fortunately in 2009 I have been started my agile journey. A lot to learn, and it was less about software than human relations and empathy. It was like a start from scratch. . 2009 - 2015: agile journey . Quite a new world for me. I had some basic knowledge by following Jono Bacon. At that time he was a community manager|release leader at Ubuntu. And was reporting progress using burndown charts. In 2009 I launched a project to create an employee portal (closed to what netvibes and igoogle were at that time). Using standard java portal technologies and more importantly using agile approach. A lot to learn about Agile, Scrum, and endless discussions about how to introduce Agile into a non-Agile organization. In 2010 I started another more ambitious project, with many colleagues (~30 persons) and a vague vision. It was about to create a product lifecycle management solution for semi-finished products. . 2015 - 2017: lean journey . In 2015, I met lean approaches for office. I was immediately convinced there was powerful and deep roots within lean. And it could bring a lot to people and organizations. I turned into a lean coach, to work with teams identifying what they could improve, how they could work better, with more pleasure. . 2017 - 2019: Welcome to USA! . Nice opportunity at that time to move from Clermont-Ferrand (France) to Greenville, South Carolina (USA). I have loved every part of it. Except maybe that 2 years were too short to make a full tour of this amazing country. It is crazy to think how different we are when we look like the same. . 2019 - : back to France and turning as a datascientist . Sept 2019 - back to France and for 4 months to prepare for a complete new position: datascientist for Manufacturing within Michelin. I spent many days to learn from various sources specially datacamp and Andrew Ng. That was just the beginning. My intent was to move away from project management, team leadership and focus about what I can do by myself. I wanted to return to math domains without giving up an IT landscape. My colleague Francois Deheeger told me about data science and Artificial Intelligence. That looked as interesting as terrifying. I was in. I was not afraid to learn a new language, and to restart my career from scratch. .",
            "url": "https://castorfou.github.io/guillaume_blog/me/2020/09/08/becoming-datascientist.html",
            "relUrl": "/me/2020/09/08/becoming-datascientist.html",
            "date": " • Sep 8, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About . This blog . This is more a journal where I am adding entries about my (baby steps) learnings. It is likely to be centered around python, git, data-science, … I have been strongly inspired by Rachel Thomas explaining why I should blog. Specially when starting such a journey to turn a datascientist. . My intent would be to regularly add entries to this blog. Ideally at least once a week. Maybe only short ones, the point being to stick on this frequent activity. If it takes days to write posts I am pretty sure I won’t do it. Those entries are personnal thoughts and not those of my employer Michelin. . Me . I am 44 (in 2020). Father of 3. Working for a French tire company. I am French and for sure English is not my mother tongue. .",
          "url": "https://castorfou.github.io/guillaume_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://castorfou.github.io/guillaume_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}