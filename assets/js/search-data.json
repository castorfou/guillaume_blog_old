{
  
    
        "post0": {
            "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
            "content": "From http://introtodeeplearning.com/ . I keep all content (lectures, notebooks) in github . This is done with google contribution, and therefore all examples are in tensorflow. I will try to adapt notebooks in PyTorch. . 2/5/21 - Intro to Deep Learning - lecture 1 . Lecturer: Alexander Amini . Intro is just jaw-dropping! . 2020 intro was top. . 2021 intro is just awesome. . It is a standard overview of simple deep learning concepts: Perceptron, multi-perceptron, dense layers, loss, gradient-descent, backprop, SGD, regularization, dropout, early stoppping . (to continue to adapt labs (notebooks) to Pytorch) . 2/15/21 - Deep Sequence Modeling - lecture 2 . New lecturer: Ava Soleimany . Nice introduction to sequence modeling with Many-to-One, One-to-Many, Many-to-Many. . RNN and implementation in TensorFlow. And NLP examples: next word problem. (and NLP concepts such as Vocabulary, Indexing, Embedding) . And what we need for sequeence modeling: . handle variable-length sequences | track long-term dependencies | maintain information about order | share parameters accross the sequence | . Backpropagation through time and problem of exploding/vanishing gradients. . Against exploding: gradient clipping. Against vanishing: 3 ways explained - activation functions, weight init, network arch. . Gated cell: to control what information is passed through. Ex: LSTM Long Short Term Memory. They support something closed to Forget Store Update Output. Ava explains graphically which part of LSTM cells is providing which function. . And then examples: Music generation (to generate 4th movement of last symphony from Schubert!), sentiment classification, machine translation. . And something about Attention mechanisms which provide learnable memory access. .",
            "url": "https://castorfou.github.io/guillaume_blog/deep%20learning/mit/tensorflow/2021/02/05/learning-MIT-6.S191-2021.html",
            "relUrl": "/deep%20learning/mit/tensorflow/2021/02/05/learning-MIT-6.S191-2021.html",
            "date": " • Feb 5, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Reinforcement learning readings",
            "content": "1/26/21 - Reinforcement learning for real-world robotics . from https://www.youtube.com/watch?v=Obek04C8L5E&amp;feature=youtu.be . at 26’ idea that you can tackle over-optimism models by using ensemble models. See paper at 2018 Model-Ensemble Trust-Region Policy Optimization . 1/26/21 - Reinforcement Learning algorithms — an intuitive overview . from https://medium.com/@SmartLabAI/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc . . give an overview of various RL models. Model-based vs model-free. . And papers and codes. . 1/26/21 - Reinforcement learning, partie 1 : introduction (in French) . There is a reference to an introduction paper: from Sutton, Richard S., and Andrew G. Barto « Reinforcement learning : an introduction. » (2011). (I have an updated version from 2015) . There is a reference to a blog article [2] Steeve Huang. “Introduction to Various Reinforcement Learning Algorithms. Part I” (Q-Learning, SARSA, DQN, DDPG)”. (2018) . And the paper for OpenAI Gym [3] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, Wojciech Zaremba. “OpenAI Gym”. (2016) . 1/27/21 - Reinforcement learning : an introduction . as a ref. from Reinforcement learning, partie 1 : introduction (in French) . I like this summary about RL . Reinforcement learning is a computational approach to understanding and automating goal-directed learning and decision-making. It is distinguished from other computational approaches by its emphasis on learning by an agent from direct interaction with its environment, without relying on exemplary supervision or complete models of the environment. In our opinion, reinforcement learning is the first field to seriously address the computational issues that arise when learning from interaction with an environment in order to achieve long-term goals. Reinforcement learning uses a formal framework defining the interaction between a learning agent and its environment in terms of states, actions, and rewards. This framework is intended to be a simple way of representing essential features of the artificial intelligence problem. These features include a sense of cause and effect, a sense of uncertainty and nondeterminism, and the existence of explicit goals. . There is some history about RL. Bellman equation and dynamic programming are at the beginning of RL. . I read about HJB equation from Huyên PHAM (from a French Math magazine). It is funny to see why dynamic programming has been named that way, and how to deal with management. . The class of methods for solving optimal control problems by solving this equation came to be known as dynamic programming (Bellman, 1957a). Bellman (1957b) also introduced the discrete stochastic version of the optimal control problem known as Markovian decision processes (MDPs), and Ronald Howard (1960) devised the policy iteration method for MDPs. All of these are essential elements underlying the theory and algorithms of modern reinforcement learning. . All the vocabulary around RL is coming from dynamic programming and MDP. . Markov decision process - Wikipedia . . Interesting to read that the famous cart pole experiment (learning to balance a pole hinged to a movable cart) came from Michie and Chambers in 1968, 53 years ago! (and derived from tic-tac-toe experiment) . I don’t understand the subtlety behind the move from “learning with a teacher” to “learning with a critic” following the modified Least-Mean-Square (LMS) algorithm; Widrow and Hoff (1973) . And some explanations about temporal-difference. I have just understood that a convergence effort happened (in 1989) by Chris Watkin who brought together temporal-difference and optimal control by developing Q-learning. . After this introduction, here is the content: . 1st part is about finite markov decision processes—and its main ideas including Bellman equations and value functions. . 2nd part is about describing three fundamental classes of methods for solving finite Markov decision problems: dynamic programming, Monte Carlo methods, and temporal-difference learning. Each class of methods has its strengths and weaknesses. Dynamic programming methods are well developed mathematically, but require a complete and accurate model of the environment. Monte Carlo methods don’t require a model and are conceptually simple, but are not suited for step-by-step incremental computation. Finally, temporal-difference methods require no model and are fully incremental, but are more complex to analyze. . 3rd part is about combining these methods to offer a complete and unified solution to the tabular reinforcement learning problem. . We can think of terms agent, environment, and action as engineers’ terms controller, controlled system (or plant), and control signal. . . Explanation about agent vs environment. Often not the same as physical boundaries of a robot: this boundary represents the limit of the agent’s absolute control, not of its knowledge. Many different agents can be operated at once. . The agent’s goal is to maximize the total mount of reward it receives. . I should re-read the full chapter3 because a lot of concepts coming from MDP is exposed, and their links to RL. At the end I should be able to answer most of end-of-chapter exercises. Have clearer view about how to define what are my agents/environment in my case; how to define actions (low-level definition (e.g. V in level1 electrical grid vs high level decision)); everything related to q* and Q-learning. . dynamic programming (DP) (chap4 - 103-126) . What is key here is to have an exact way to describe your environment. Which is not always feasible. And we need computer power to go through all states, compute value function. There is a balance between policy evaluation and policy improvement but this is not crystal clear to me. And I don’t understand asynchronous DP. I haven’t developed enough intuitions behind DP, and I am unable to answer exercises. I understand though that reinforcement learning can solve some problems by approximating part of it (evaluation, environment, …) . monte carlo (MC) methods (chap5 - 127-156) . first-visit vs every-visit methods. First-visit has been widely studied. Blackjack example. Explanation of Monte Carlo ES (exploratory starts); and how to avoid this unlikely assumption thanks to on-policy or off-policy methods (on-policy estimate the value of a policy while using it for control. In off-policy methods these two functions are separated (behavior and target)). . One issue with MC methods is to ensure sufficient exploration. One approach is to start with a random state-action pair, could work with simulated episodes but unlikely to learn from real experience. . MC methods do not bootstrap (i.e. they don’t update their value estimates based on other value estimates) (TODO learn more about bootstrapping) . temporal-difference (TD) learning (chap6 - 157-180) . TD learning is a combination of Monte Carlo ideas and dynamic programming (DP) ideas. Like DP, TD methods update estimates based in part on other learned estimates, without waiting for a final outcome (they bootstrap, or said differently they learn a guess from a guess). . If you consider optimization as a 2 phases approach: prediction problem (ie policy evaluation) and control problem (ie optimal policy), DP, TD, MC differences are at the prediction problem. On control problem they use variations of generalized policy iteration (GPI). . TD methods combine the sampling of Monte Carlo with the bootstrapping of DP. . Example based on Driving Home. In TD you update prediction at each step, not waiting for the final return as in MC. .",
            "url": "https://castorfou.github.io/guillaume_blog/reinforcement%20learning/2021/01/26/reinforcement-learning-readings.html",
            "relUrl": "/reinforcement%20learning/2021/01/26/reinforcement-learning-readings.html",
            "date": " • Jan 26, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "seaborn cheatsheet",
            "content": "Introduction to Data Visualization with Seaborn . pdf lectures in github . Introduction to Seaborn . Introduction to Seaborn . # Getting started import seaborn as sns import matplotlib.pyplot as plt # Example 1: Scatter plot import seaborn as sns import matplotlib.pyplot as plt height = [62, 64, 69, 75, 66, 68, 65, 71, 76, 73] weight = [120, 136, 148, 175, 137, 165, 154, 172, 200, 187] sns.scatterplot(x=height, y=weight) plt.show() # Example 2: Create a count plot import seaborn as sns import matplotlib.pyplot as plt gender = [&quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;] sns.countplot(x=gender) plt.show() . Using pandas with Seaborn . # Using DataFrames with countplot() import pandas as pd import matplotlib.pyplot as plt import seaborn as sns df = pd.read_csv(&quot;masculinity.csv&quot;) sns.countplot(x=&quot;how_masculine&quot;, data=df) plt.show() . Adding a third variable with hue . # Tips dataset import pandas as pd import seaborn as sns tips = sns.load_dataset(&quot;tips&quot;) tips.head() # A basic scatter plot import matplotlib.pyplot as plt import seaborn as sns sns.scatterplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips) plt.show() # A scatter plot with hue import matplotlib.pyplot as plt import seaborn as sns sns.scatterplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips, hue=&quot;smoker&quot;) plt.show() # Setting hue order import matplotlib.pyplot as plt import seaborn as sns sns.scatterplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips, hue=&quot;smoker&quot;, hue_order=[&quot;Yes&quot;,&quot;No&quot;]) plt.show() # Specifying hue colors import matplotlib.pyplot as plt import seaborn as sns hue_colors = {&quot;Yes&quot;: &quot;black&quot;, &quot;No&quot;: &quot;red&quot;} sns.scatterplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips, hue=&quot;smoker&quot;, palette=hue_colors) plt.show() # Using HTML hex color codes with hue import matplotlib.pyplot as plt import seaborn as sns hue_colors = {&quot;Yes&quot;: &quot;#808080&quot;, &quot;No&quot;: &quot;#00FF00&quot;} sns.scatterplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips, hue=&quot;smoker&quot;, palette=hue_colors) plt.show() # Using hue with count plots import matplotlib.pyplot as plt import seaborn as sns sns.countplot(x=&quot;smoker&quot;, data=tips, hue=&quot;sex&quot;) plt.show() . Visualizing Two Quantitative Variables . Introduction to relational plots and subplots . # Using relplot() import seaborn as sns import matplotlib.pyplot as plt sns.relplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips, kind=&quot;scatter&quot;) plt.show() # Subplots in columns import seaborn as sns import matplotlib.pyplot as plt sns.relplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips, kind=&quot;scatter&quot;, col=&quot;smoker&quot;) plt.show() # Subplots in rows import seaborn as sns import matplotlib.pyplot as plt sns.relplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips, kind=&quot;scatter&quot;, row=&quot;smoker&quot;) plt.show() # Subplots in rows and columns import seaborn as sns import matplotlib.pyplot as plt sns.relplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips, kind=&quot;scatter&quot;, col=&quot;smoker&quot;, row=&quot;time&quot;) plt.show() # Wrapping columns import seaborn as sns import matplotlib.pyplot as plt sns.relplot(x=&quot;total_bill&quot;,y=&quot;tip&quot;,data=tips,kind=&quot;scatter&quot;,col=&quot;day&quot;,col_wrap=2) plt.show() # Ordering columns import seaborn as sns import matplotlib.pyplot as plt sns.relplot(x=&quot;total_bill&quot;,y=&quot;tip&quot;,data=tips,kind=&quot;scatter&quot;,col=&quot;day&quot;,col_wrap=2,col_order=[&quot;Thur&quot;,&quot;Fri&quot;,&quot;Sat&quot;,&quot;Sun&quot;]) plt.show() . Customizing scatter plots . # Subgroups with point size import seaborn as sns import matplotlib.pyplot as plt sns.relplot(x=&quot;total_bill&quot;,y=&quot;tip&quot;,data=tips,kind=&quot;scatter&quot;,size=&quot;size&quot;) plt.show() # Point size and hue import seaborn as sns import matplotlib.pyplot as plt sns.relplot(x=&quot;total_bill&quot;,y=&quot;tip&quot;,data=tips,kind=&quot;scatter&quot;,size=&quot;size&quot;,hue=&quot;size&quot;) plt.show() # Subgroups with point style import seaborn as sns import matplotlib.pyplot as plt sns.relplot(x=&quot;total_bill&quot;,y=&quot;tip&quot;,data=tips,kind=&quot;scatter&quot;,hue=&quot;smoker&quot;,style=&quot;smoker&quot;) plt.show() # Changing point transparency import seaborn as sns import matplotlib.pyplot as plt # Set alpha to be between 0 and 1 sns.relplot(x=&quot;total_bill&quot;,y=&quot;tip&quot;,data=tips,kind=&quot;scatter&quot;,alpha=0.4) plt.show() . Introduction to line plots . # Line plot import matplotlib.pyplot as plt import seaborn as sns sns.relplot(x=&quot;hour&quot;, y=&quot;NO_2_mean&quot;,data=air_df_mean,kind=&quot;line&quot;) plt.show() # Subgroups by location import matplotlib.pyplot as plt import seaborn as sns sns.relplot(x=&quot;hour&quot;, y=&quot;NO_2_mean&quot;,data=air_df_loc_mean,kind=&quot;line&quot;,style=&quot;location&quot;,hue=&quot;location&quot;) plt.show() # Adding markers import matplotlib.pyplot as plt import seaborn as sns sns.relplot(x=&quot;hour&quot;, y=&quot;NO_2_mean&quot;,data=air_df_loc_mean,kind=&quot;line&quot;,style=&quot;location&quot;,hue=&quot;location&quot;,markers=True) plt.show() # Turning off line style import matplotlib.pyplot as plt import seaborn as sns sns.relplot(x=&quot;hour&quot;, y=&quot;NO_2_mean&quot;,data=air_df_loc_mean,kind=&quot;line&quot;,style=&quot;location&quot;,hue=&quot;location&quot;,markers=True,dashes=False) plt.show() # Multiple observations per x-value # Line plot import matplotlib.pyplot as plt import seaborn as sns sns.relplot(x=&quot;hour&quot;, y=&quot;NO_2&quot;,data=air_df,kind=&quot;line&quot;) plt.show() # Replacing confidence interval with standard deviation import matplotlib.pyplot as plt import seaborn as sns sns.relplot(x=&quot;hour&quot;, y=&quot;NO_2&quot;,data=air_df,kind=&quot;line&quot;,ci=&quot;sd&quot;) plt.show() # Turning off confidence interval import matplotlib.pyplot as plt import seaborn as sns sns.relplot(x=&quot;hour&quot;, y=&quot;NO_2&quot;,data=air_df,kind=&quot;line&quot;,ci=None) plt.show() . Visualizing a Categorical and a Quantitative Variable . Count plots and bar plots . # countplot() vs. catplot() import matplotlib.pyplot as plt import seaborn as sns sns.catplot(x=&quot;how_masculine&quot;,data=masculinity_data,kind=&quot;count&quot;) plt.show() # Changing the order import matplotlib.pyplot as plt import seaborn as sns category_order = [&quot;No answer&quot;,&quot;Not at all&quot;,&quot;Not very&quot;,&quot;Somewhat&quot;,&quot;Very&quot;] sns.catplot(x=&quot;how_masculine&quot;,data=masculinity_data,kind=&quot;count&quot;,order=category_order) plt.show() # Bar plots import matplotlib.pyplot as plt import seaborn as sns sns.catplot(x=&quot;day&quot;,y=&quot;total_bill&quot;,data=tips,kind=&quot;bar&quot;) plt.show() # Turning off confidence intervals import matplotlib.pyplot as plt import seaborn as sns sns.catplot(x=&quot;day&quot;,y=&quot;total_bill&quot;,data=tips,kind=&quot;bar&quot;,ci=None) plt.show() # Changing the orientation import matplotlib.pyplot as plt import seaborn as sns sns.catplot(x=&quot;total_bill&quot;,y=&quot;day&quot;,data=tips,kind=&quot;bar&quot;) plt.show() . Box plots . # How to create a box plot import matplotlib.pyplot as plt import seaborn as sns g = sns.catplot(x=&quot;time&quot;,y=&quot;total_bill&quot;,data=tips,kind=&quot;box&quot;) plt.show() # Change the order of categories import matplotlib.pyplot as plt import seaborn as sns g = sns.catplot(x=&quot;time&quot;,y=&quot;total_bill&quot;,data=tips,kind=&quot;box&quot;,order=[&quot;Dinner&quot;,&quot;Lunch&quot;]) plt.show() # Omitting the outliers using `sym` import matplotlib.pyplot as plt import seaborn as sns g = sns.catplot(x=&quot;time&quot;,y=&quot;total_bill&quot;,data=tips,kind=&quot;box&quot;,sym=&quot;&quot;) plt.show() # Changing the whiskers using `whis` import matplotlib.pyplot as plt import seaborn as sns g = sns.catplot(x=&quot;time&quot;,y=&quot;total_bill&quot;,data=tips,kind=&quot;box&quot;,whis=[0, 100]) plt.show() . Point plots . # Creating a point plot import matplotlib.pyplot as plt import seaborn as sns sns.catplot(x=&quot;age&quot;,y=&quot;masculinity_important&quot;,data=masculinity_data,hue=&quot;feel_masculine&quot;,kind=&quot;point&quot;) plt.show() # Disconnecting the points import matplotlib.pyplot as plt import seaborn as sns sns.catplot(x=&quot;age&quot;,y=&quot;masculinity_important&quot;,data=masculinity_data,hue=&quot;feel_masculine&quot;,kind=&quot;point&quot;,join=False) plt.show() # Displaying the median import matplotlib.pyplot as plt import seaborn as sns from numpy import median sns.catplot(x=&quot;smoker&quot;,y=&quot;total_bill&quot;,data=tips,kind=&quot;point&quot;,estimator=median) plt.show() # Customizing the confidence intervals import matplotlib.pyplot as plt import seaborn as sns sns.catplot(x=&quot;smoker&quot;,y=&quot;total_bill&quot;,data=tips,kind=&quot;point&quot;,capsize=0.2) plt.show() # Turning off confidence intervals import matplotlib.pyplot as plt import seaborn as sns sns.catplot(x=&quot;smoker&quot;,y=&quot;total_bill&quot;,data=tips,kind=&quot;point&quot;,ci=None) plt.show() . Customizing Seaborn Plots . Changing plot style and color . # Figure style: &quot;whitegrid&quot; sns.set_style(&quot;whitegrid&quot;) sns.catplot(x=&quot;age&quot;,y=&quot;masculinity_important&quot;,data=masculinity_data,hue=&quot;feel_masculine&quot;,kind=&quot;point&quot;) plt.show() # Other styles: sns.set_style(&quot;ticks&quot;) sns.set_style(&quot;dark&quot;) sns.set_style(&quot;darkgrid&quot;) # Example (diverging palette) sns.set_palette(&quot;RdBu&quot;) category_order = [&quot;No answer&quot;,&quot;Not at all&quot;,&quot;Not very&quot;,&quot;Somewhat&quot;,&quot;Very&quot;] sns.catplot(x=&quot;how_masculine&quot;,data=masculinity_data,kind=&quot;count&quot;,order=category_order) plt.show() # Custom palettes custom_palette = [&quot;red&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;blue&quot;,&quot;yellow&quot;, &quot;purple&quot;] sns.set_palette(custom_palette) # Custom palettes custom_palette = [&#39;#FBB4AE&#39;, &#39;#B3CDE3&#39;, &#39;#CCEBC5&#39;,&#39;#DECBE4&#39;, &#39;#FED9A6&#39;, &#39;#FFFFCC&#39;,&#39;#E5D8BD&#39;, &#39;#FDDAEC&#39;, &#39;#F2F2F2&#39;] sns.set_palette(custom_palette) # Larger context: &quot;talk&quot; #Smallest to largest: &quot;paper&quot;, &quot;notebook&quot;, &quot;talk&quot;, &quot;poster&quot; sns.set_context(&quot;talk&quot;) . Adding titles and labels: Part 1 . # Adding a title to FacetGrid g = sns.catplot(x=&quot;Region&quot;,y=&quot;Birthrate&quot;,data=gdp_data,kind=&quot;box&quot;) g.fig.suptitle(&quot;New Title&quot;) plt.show() # Adjusting height of title in FacetGrid g = sns.catplot(x=&quot;Region&quot;,y=&quot;Birthrate&quot;,data=gdp_data,kind=&quot;box&quot;) g.fig.suptitle(&quot;New Title&quot;,y=1.03) plt.show() . Adding titles and labels: Part 2 . # Adding a title to AxesSubplot g = sns.boxplot(x=&quot;Region&quot;,y=&quot;Birthrate&quot;,data=gdp_data) g.set_title(&quot;New Title&quot;,y=1.03) # Titles for subplots g = sns.catplot(x=&quot;Region&quot;,y=&quot;Birthrate&quot;,data=gdp_data,kind=&quot;box&quot;,col=&quot;Group&quot;) g.fig.suptitle(&quot;New Title&quot;,y=1.03) g.set_titles(&quot;This is {col_name}&quot;) # Adding axis labels g = sns.catplot(x=&quot;Region&quot;,y=&quot;Birthrate&quot;,data=gdp_data,kind=&quot;box&quot;) g.set(xlabel=&quot;New X Label&quot;,ylabel=&quot;New Y Label&quot;) plt.show() # Rotating x-axis tick labels g = sns.catplot(x=&quot;Region&quot;,y=&quot;Birthrate&quot;,data=gdp_data,kind=&quot;box&quot;) plt.xticks(rotation=90) plt.show() . Intermediate Data Visualization with Seaborn . pdf lectures in github . Seaborn Introduction . Introduction to Seaborn . # Seaborn distplot import seaborn as sns sns.distplot(df[&#39;alcohol&#39;]) . Using the distribution plot . # Creating a histogram sns.distplot(df[&#39;alcohol&#39;], kde=False, bins=10) # Alternative data distributions sns.distplot(df[&#39;alcohol&#39;], hist=False, rug=True) # Further Customizations sns.distplot(df[&#39;alcohol&#39;], hist=False,rug=True, kde_kws={&#39;shade&#39;:True}) . Regression Plots in Seaborn . # Introduction to regplot sns.regplot(x=&quot;alcohol&quot;, y=&quot;pH&quot;, data=df) # lmplot faceting sns.lmplot(x=&quot;quality&quot;, y=&quot;alcohol&quot;,data=df, hue=&quot;type&quot;) sns.lmplot(x=&quot;quality&quot;, y=&quot;alcohol&quot;,data=df, col=&quot;type&quot;) . Customizing Seaborn Plots . Using Seaborn Styles . # Setting Styles # Seaborn has default configurations that can be applied with sns.set() # These styles can override matplotlib and pandas plots as well sns.set() # Theme examples with sns.set_style() for style in [&#39;white&#39;,&#39;dark&#39;,&#39;whitegrid&#39;,&#39;darkgrid&#39;,&#39;ticks&#39;]: sns.set_style(style) sns.distplot(df[&#39;Tuition&#39;]) plt.show() # Removing axes with despine() sns.set_style(&#39;white&#39;) sns.distplot(df[&#39;Tuition&#39;]) sns.despine(left=True) . Colors in Seaborn . # Defining a color for a plot sns.set(color_codes=True) sns.distplot(df[&#39;Tuition&#39;], color=&#39;g&#39;) # Palettes for p in sns.palettes.SEABORN_PALETTES: sns.set_palette(p) sns.distplot(df[&#39;Tuition&#39;]) # Displaying Palettes for p in sns.palettes.SEABORN_PALETTES: sns.set_palette(p) sns.palplot(sns.color_palette()) plt.show() # Defining Custom Palettes # Circular colors = when the data is not ordered sns.palplot(sns.color_palette(&quot;Paired&quot;, 12)) # Sequential colors = when the data has a consistent range from high to low sns.palplot(sns.color_palette(&quot;Blues&quot;, 12)) # Diverging colors = when both the low and high values are interesting sns.palplot(sns.color_palette(&quot;BrBG&quot;, 12)) . Customizing with matplotlib . # Matplotlib Axes fig, ax = plt.subplots() sns.distplot(df[&#39;Tuition&#39;], ax=ax) ax.set(xlabel=&quot;Tuition 2013-14&quot;) # Further Customizations fig, ax = plt.subplots() sns.distplot(df[&#39;Tuition&#39;], ax=ax) ax.set(xlabel=&quot;Tuition 2013-14&quot;,ylabel=&quot;Distribution&quot;, xlim=(0, 50000),title=&quot;2013-14 Tuition and Fees Distribution&quot;) # Combining Plots fig, (ax0, ax1) = plt.subplots(nrows=1,ncols=2, sharey=True, figsize=(7,4)) sns.distplot(df[&#39;Tuition&#39;], ax=ax0) sns.distplot(df.query(&#39;State == &quot;MN&quot;&#39;)[&#39;Tuition&#39;], ax=ax1) ax1.set(xlabel=&quot;Tuition (MN)&quot;, xlim=(0, 70000)) ax1.axvline(x=20000, label=&#39;My Budget&#39;, linestyle=&#39;--&#39;) ax1.legend() . Additional Plot Types . Categorical Plot Types . # Plots of each observation - stripplot sns.stripplot(data=df, y=&quot;DRG Definition&quot;, x=&quot;Average Covered Charges&quot;, jitter=True) # Plots of each observation - swarmplot sns.swarmplot(data=df, y=&quot;DRG Definition&quot;, x=&quot;Average Covered Charges&quot;) # Abstract representations - boxplot sns.boxplot(data=df, y=&quot;DRG Definition&quot;, x=&quot;Average Covered Charges&quot;) # Abstract representation - violinplot sns.violinplot(data=df, y=&quot;DRG Definition&quot;, x=&quot;Average Covered Charges&quot;) # Abstract representation - lvplot sns.lvplot(data=df, y=&quot;DRG Definition&quot;, x=&quot;Average Covered Charges&quot;) # Statistical estimates - barplot sns.barplot(data=df, y=&quot;DRG Definition&quot;, x=&quot;Average Covered Charges&quot;, hue=&quot;Region&quot;) # Statistical estimates - pointplot sns.pointplot(data=df, y=&quot;DRG Definition&quot;, x=&quot;Average Covered Charges&quot;, hue=&quot;Region&quot;) # Statistical estimates - countplot sns.countplot(data=df, y=&quot;DRG_Code&quot;, hue=&quot;Region&quot;) . Regression Plots . # Plotting with regplot() sns.regplot(data=df, x=&#39;temp&#39;, y=&#39;total_rentals&#39;, marker=&#39;+&#39;) # Evaluating regression with residplot() sns.residplot(data=df, x=&#39;temp&#39;, y=&#39;total_rentals&#39;) # Polynomial regression sns.regplot(data=df, x=&#39;temp&#39;, y=&#39;total_rentals&#39;, order=2) # residplot with polynomial regression sns.residplot(data=df, x=&#39;temp&#39;, y=&#39;total_rentals&#39;, order=2) # Categorical values sns.regplot(data=df, x=&#39;mnth&#39;, y=&#39;total_rentals&#39;, x_jitter=.1, order=2) # Estimators sns.regplot(data=df, x=&#39;mnth&#39;, y=&#39;total_rentals&#39;, x_estimator=np.mean, order=2) # Binning the data sns.regplot(data=df,x=&#39;temp&#39;,y=&#39;total_rentals&#39;, x_bins=4) . Matrix plots . # Getting data in the right format pd.crosstab(df[&quot;mnth&quot;], df[&quot;weekday&quot;], values=df[&quot;total_rentals&quot;],aggfunc=&#39;mean&#39;).round(0) # Build a heatmap sns.heatmap(pd.crosstab(df[&quot;mnth&quot;], df[&quot;weekday&quot;], values=df[&quot;total_rentals&quot;], aggfunc=&#39;mean&#39;) ) # Customize a heatmap sns.heatmap(df_crosstab, annot=True, fmt=&quot;d&quot;, cmap=&quot;YlGnBu&quot;, cbar=False, linewidths=.5) # Centering a heatmap sns.heatmap(df_crosstab, annot=True, fmt=&quot;d&quot;, cmap=&quot;YlGnBu&quot;, cbar=True, center=df_crosstab.loc[9, 6]) # Plotting a correlation matrix sns.heatmap(df.corr()) . Creating Plots on Data Aware Grids . Using FacetGrid, factorplot and lmplot . # FacetGrid Categorical Example g = sns.FacetGrid(df, col=&quot;HIGHDEG&quot;) g.map(sns.boxplot, &#39;Tuition&#39;, order=[&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;]) # factorplot() sns.factorplot(x=&quot;Tuition&quot;, data=df, col=&quot;HIGHDEG&quot;, kind=&#39;box&#39;) # FacetGrid for regression # FacetGrid() can also be used for sca er or regression plots g = sns.FacetGrid(df, col=&quot;HIGHDEG&quot;) g.map(plt.scatter, &#39;Tuition&#39;, &#39;SAT_AVG_ALL&#39;) # lmplot # lmplot plots sca er and regression plots on a FacetGrid sns.lmplot(data=df, x=&quot;Tuition&quot;, y=&quot;SAT_AVG_ALL&quot;, col=&quot;HIGHDEG&quot;, fit_reg=False) # lmplot with regression sns.lmplot(data=df, x=&quot;Tuition&quot;, y=&quot;SAT_AVG_ALL&quot;, col=&quot;HIGHDEG&quot;, row=&#39;REGION&#39;) . Using PairGrid and pairplot . # Creating a PairGrid g = sns.PairGrid(df, vars=[&quot;Fair_Mrkt_Rent&quot;, &quot;Median_Income&quot;]) g = g.map(plt.scatter) # Customizing the PairGrid diagonals g = sns.PairGrid(df, vars=[&quot;Fair_Mrkt_Rent&quot;, &quot;Median_Income&quot;]) g = g.map_diag(plt.hist) g = g.map_offdiag(plt.scatter) # Pairplot sns.pairplot(df, vars=[&quot;Fair_Mrkt_Rent&quot;, &quot;Median_Income&quot;], kind=&#39;reg&#39;, diag_kind=&#39;hist&#39;) # Customizing a pairplot sns.pairplot(df.query(&#39;BEDRMS &lt; 3&#39;),vars=[&quot;Fair_Mrkt_Rent&quot;,&quot;Median_Income&quot;, &quot;UTILITY&quot;],hue=&#39;BEDRMS&#39;, palette=&#39;husl&#39;, plot_kws={&#39;alpha&#39;: 0.5}) . Using JointGrid and jointplot . # Basic JointGrid g = sns.JointGrid(data=df, x=&quot;Tuition&quot;,y=&quot;ADM_RATE_ALL&quot;) g.plot(sns.regplot, sns.distplot) # Advanced JointGrid g = sns.JointGrid(data=df, x=&quot;Tuition&quot;,y=&quot;ADM_RATE_ALL&quot;) g = g.plot_joint(sns.kdeplot) g = g.plot_marginals(sns.kdeplot, shade=True) g = g.annotate(stats.pearsonr) # jointplot() sns.jointplot(data=df, x=&quot;Tuition&quot;,y=&quot;ADM_RATE_ALL&quot;, kind=&#39;hex&#39;) # Customizing a jointplot g = (sns.jointplot(x=&quot;Tuition&quot;, y=&quot;ADM_RATE_ALL&quot;, kind=&#39;scatter&#39;, xlim=(0, 25000), marginal_kws=dict(bins=15,rug=True), data=df.query(&#39;UG &lt; 2500 &amp; Ownership == &quot;Public&quot;&#39;)) .plot_joint(sns.kdeplot)) .",
            "url": "https://castorfou.github.io/guillaume_blog/visualization/seaborn/cheatsheet/2021/01/19/seaborn-cheatsheet.html",
            "relUrl": "/visualization/seaborn/cheatsheet/2021/01/19/seaborn-cheatsheet.html",
            "date": " • Jan 19, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Java installation on Ubuntu 20.04",
            "content": "Following these instructions: https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04-fr. . Current configuration . !java --version . openjdk 11.0.9.1 2020-11-04 OpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.20.04) OpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.20.04, mixed mode, sharing) . Download Oracle JDK 11 . From https://launchpad.net/~linuxuprising/+archive/ubuntu/java/+packages, I can identify the focal version: . oracle-java11-installer-local - 11.0.9-1~linuxuprising0 (changes file) logix2 2020-10-22 Published Focal Java . I download the given version from Oracle website: https://www.oracle.com/java/technologies/javase-jdk11-downloads.html. Java SE Development Kit 11.0.9 Linux x64 Compressed Archive . And yes you have to login with an oracle account to download it. . Installation via linuxuprising/java . sudo add-apt-repository ppa:linuxuprising/java sudo apt update sudo mkdir -p /var/cache/oracle-jdk11-installer-local/ sudo cp ~/Downloads/jdk-11.0.9_linux-x64_bin.tar.gz /var/cache/oracle-jdk11-installer-local/ sudo apt install oracle-java11-installer-local . After accepting the license agreement, installation is running . Check . $ sudo update-alternatives --config java There are 2 choices for the alternative java (providing /usr/bin/java). Selection Path Priority Status 0 /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1111 auto mode 1 /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1111 manual mode * 2 /usr/lib/jvm/java-11-oracle/bin/java 1091 manual mode . Environment variable . Enter /usr/lib/jvm/java-11-oracle as your JAVA_HOME variable in /etc/environment . $ cat /etc/environment PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin&quot; JAVA_HOME=&quot;/usr/lib/jvm/java-11-oracle&quot; $ source /etc/environment $ echo $JAVA_HOME /usr/lib/jvm/java-11-oracle .",
            "url": "https://castorfou.github.io/guillaume_blog/ubuntu/java/2021/01/14/java-installation-on-ubuntu-20.04.html",
            "relUrl": "/ubuntu/java/2021/01/14/java-installation-on-ubuntu-20.04.html",
            "date": " • Jan 14, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "matplotlib cheatsheet",
            "content": "Introduction to Data Visualization with Matplotlib . matplotlib cheatsheet in pdf . pdf lecture in github . Introduction to Matplotlib . Introduction to data visualization with Matplotlib . # Introducing the pyplot interface import matplotlib.pyplot as plt fig, ax = plt.subplots() plt.show() # Adding data to axes ax.plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-TAVG-NORMAL&quot;]) plt.show() . Customizing your plots . # Adding markers ax.plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-PRCP-NORMAL&quot;], marker=&quot;o&quot;) plt.show() # Choosing markers ax.plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-PRCP-NORMAL&quot;], marker=&quot;v&quot;) plt.show() . markers . # Setting the linestyle fig, ax = plt.subplots() ax.plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-TAVG-NORMAL&quot;], marker=&quot;v&quot;, linestyle=&quot;--&quot;) plt.show() . line style . # Eliminating lines with linestyle fig, ax = plt.subplots() ax.plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-TAVG-NORMAL&quot;], marker=&quot;v&quot;, linestyle=&quot;None&quot;) plt.show() # Choosing color fig, ax = plt.subplots() ax.plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-TAVG-NORMAL&quot;], marker=&quot;v&quot;, linestyle=&quot;--&quot;, color=&quot;r&quot;) plt.show() # Customizing the axes labels ax.set_xlabel(&quot;Time (months)&quot;) plt.show() # Setting the y axis label ax.set_xlabel(&quot;Time (months)&quot;) ax.set_ylabel(&quot;Average temperature (Fahrenheit degrees)&quot;) plt.show() # Adding a title ax.set_title(&quot;Weather in Seattle&quot;) plt.show() . Small multiples . # Small multiples with plt.subplots fig, ax = plt.subplots(3, 2) plt.show() # Adding data to subplots ax.shape (3, 2) ax[0, 0].plot(seattle_weather[&quot;MONTH&quot;],seattle_weather[&quot;MLY-PRCP-NORMAL&quot;],color=&#39;b&#39;) plt.show() # Subplots with data fig, ax = plt.subplots(2, 1) ax[0].plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-PRCP-NORMAL&quot;],color=&#39;b&#39;) ax[0].plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-PRCP-25PCTL&quot;],linestyle=&#39;--&#39;, color=&#39;b&#39;) ax[0].plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-PRCP-75PCTL&quot;],linestyle=&#39;--&#39;, color=&#39;b&#39;) ax[1].plot(austin_weather[&quot;MONTH&quot;], austin_weather[&quot;MLY-PRCP-NORMAL&quot;],color=&#39;r&#39;) ax[1].plot(austin_weather[&quot;MONTH&quot;], austin_weather[&quot;MLY-PRCP-25PCTL&quot;],linestyle=&#39;--&#39;, color=&#39;r&#39;) ax[1].plot(austin_weather[&quot;MONTH&quot;], austin_weather[&quot;MLY-PRCP-75PCTL&quot;],linestyle=&#39;--&#39;, color=&#39;r&#39;) ax[0].set_ylabel(&quot;Precipitation (inches)&quot;) ax[1].set_ylabel(&quot;Precipitation (inches)&quot;) ax[1].set_xlabel(&quot;Time (months)&quot;) plt.show() # Sharing the y-axis range fig, ax = plt.subplots(2, 1, sharey=True) . Plotting time-series . Plotting time-series data . # DateTimeIndex climate_change.index DatetimeIndex([&#39;1958-03-06&#39;, &#39;1958-04-06&#39;, &#39;1958-05-06&#39;, &#39;1958-06-06&#39;, dtype=&#39;datetime64[ns]&#39;, name=&#39;date&#39;, length=706, freq=None) # Plotting time-series data import matplotlib.pyplot as plt fig, ax = plt.subplots() ax.plot(climate_change.index, climate_change[&#39;co2&#39;]) ax.set_xlabel(&#39;Time&#39;) ax.set_ylabel(&#39;CO2 (ppm)&#39;) plt.show() # Zooming in on a decade sixties = climate_change[&quot;1960-01-01&quot;:&quot;1969-12-31&quot;] fig, ax = plt.subplots() ax.plot(sixties.index, sixties[&#39;co2&#39;]) ax.set_xlabel(&#39;Time&#39;) ax.set_ylabel(&#39;CO2 (ppm)&#39;) plt.show() # Zooming in on one year sixty_nine = climate_change[&quot;1969-01-01&quot;:&quot;1969-12-31&quot;] fig, ax = plt.subplots() ax.plot(sixty_nine.index, sixty_nine[&#39;co2&#39;]) ax.set_xlabel(&#39;Time&#39;) ax.set_ylabel(&#39;CO2 (ppm)&#39;) plt.show() . Plotting time-series with different variables . # Plotting two time-series together import matplotlib.pyplot as plt fig, ax = plt.subplots() ax.plot(climate_change.index, climate_change[&quot;co2&quot;]) ax.plot(climate_change.index, climate_change[&quot;relative_temp&quot;]) ax.set_xlabel(&#39;Time&#39;) ax.set_ylabel(&#39;CO2 (ppm) / Relative temperature&#39;) plt.show() # Using twin axes fig, ax = plt.subplots() ax.plot(climate_change.index, climate_change[&quot;co2&quot;]) ax.set_xlabel(&#39;Time&#39;) ax.set_ylabel(&#39;CO2 (ppm)&#39;) ax2 = ax.twinx() ax2.plot(climate_change.index, climate_change[&quot;relative_temp&quot;]) ax2.set_ylabel(&#39;Relative temperature (Celsius)&#39;) plt.show() # Separating variables by color fig, ax = plt.subplots() ax.plot(climate_change.index, climate_change[&quot;co2&quot;], color=&#39;blue&#39;) ax.set_xlabel(&#39;Time&#39;) ax.set_ylabel(&#39;CO2 (ppm)&#39;, color=&#39;blue&#39;) ax2 = ax.twinx() ax2.plot(climate_change.index, climate_change[&quot;relative_temp&quot;], color=&#39;red&#39;) ax2.set_ylabel(&#39;Relative temperature (Celsius)&#39;, color=&#39;red&#39;) plt.show() # Coloring the ticks fig, ax = plt.subplots() ax.plot(climate_change.index, climate_change[&quot;co2&quot;], color=&#39;blue&#39;) ax.set_xlabel(&#39;Time&#39;) ax.set_ylabel(&#39;CO2 (ppm)&#39;, color=&#39;blue&#39;) ax.tick_params(&#39;y&#39;, colors=&#39;blue&#39;) ax2 = ax.twinx() ax2.plot(climate_change.index, climate_change[&quot;relative_temp&quot;], color=&#39;red&#39;) ax2.set_ylabel(&#39;Relative temperature (Celsius)&#39;, color=&#39;red&#39;) ax2.tick_params(&#39;y&#39;, colors=&#39;red&#39;) plt.show() # A function that plots time-series def plot_timeseries(axes, x, y, color, xlabel, ylabel): axes.plot(x, y, color=color) axes.set_xlabel(xlabel) axes.set_ylabel(ylabel, color=color) axes.tick_params(&#39;y&#39;, colors=color) # Using our function fig, ax = plt.subplots() plot_timeseries(ax, climate_change.index, climate_change[&#39;co2&#39;],&#39;blue&#39;, &#39;Time&#39;, &#39;CO2 (ppm)&#39;) ax2 = ax.twinx() plot_timeseries(ax, climate_change.index,climate_change[&#39;relative_temp&#39;],&#39;red&#39;, &#39;Time&#39;, &#39;Relative temperature (Celsius)&#39;) plt.show() . Annotating time-series data . # Annotation fig, ax = plt.subplots() plot_timeseries(ax, climate_change.index, climate_change[&#39;co2&#39;], &#39;blue&#39;, &#39;Time&#39;, &#39;CO2 (ppm)&#39;) ax2 = ax.twinx() plot_timeseries(ax2, climate_change.index, climate_change[&#39;relative_temp&#39;], &#39;red&#39;, &#39;Time&#39;, &#39;Relative temperature (Celsius)&#39;) ax2.annotate(&quot;&gt;1 degree&quot;, xy=[pd.TimeStamp(&quot;2015-10-06&quot;), 1]) plt.show() # Positioning the text ax2.annotate(&quot;&gt;1 degree&quot;, xy=(pd.Timestamp(&#39;2015-10-06&#39;), 1), xytext=(pd.Timestamp(&#39;2008-10-06&#39;), -0.2)) # Adding arrows to annotation ax2.annotate(&quot;&gt;1 degree&quot;, xy=(pd.Timestamp(&#39;2015-10-06&#39;), 1), xytext=(pd.Timestamp(&#39;2008-10-06&#39;), -0.2), arrowprops={}) # Customizing arrow properties ax2.annotate(&quot;&gt;1 degree&quot;, xy=(pd.Timestamp(&#39;2015-10-06&#39;), 1), xytext=(pd.Timestamp(&#39;2008-10-06&#39;), -0.2), arrowprops={&quot;arrowstyle&quot;:&quot;-&gt;&quot;, &quot;color&quot;:&quot;gray&quot;}) . Customizing annotations . Quantitative comparisons and statistical visualizations . Quantitative comparisons: bar-charts . # Olympic medals: visualizing the data medals = pd.read_csv(&#39;medals_by_country_2016.csv&#39;, index_col=0) fig, ax = plt.subplots() ax.bar(medals.index, medals[&quot;Gold&quot;]) plt.show() # Interlude: rotate the tick labels fig, ax = plt.subplots() ax.bar(medals.index, medals[&quot;Gold&quot;]) ax.set_xticklabels(medals.index, rotation=90) ax.set_ylabel(&quot;Number of medals&quot;) plt.show() # Olympic medals: visualizing the other medals : stacked bar chart fig, ax = plt.subplots ax.bar(medals.index, medals[&quot;Gold&quot;]) ax.bar(medals.index, medals[&quot;Silver&quot;], bottom=medals[&quot;Gold&quot;]) ax.set_xticklabels(medals.index, rotation=90) ax.set_ylabel(&quot;Number of medals&quot;) plt.show() # Olympic medals: visualizing all three fig, ax = plt.subplots ax.bar(medals.index, medals[&quot;Gold&quot;]) ax.bar(medals.index, medals[&quot;Silver&quot;], bottom=medals[&quot;Gold&quot;]) ax.bar(medals.index, medals[&quot;Bronze&quot;], bottom=medals[&quot;Gold&quot;] + medals[&quot;Silver&quot;]) ax.set_xticklabels(medals.index, rotation=90) ax.set_ylabel(&quot;Number of medals&quot;) plt.show() # Adding a legend fig, ax = plt.subplots ax.bar(medals.index, medals[&quot;Gold&quot;], label=&quot;Gold&quot;) ax.bar(medals.index, medals[&quot;Silver&quot;], bottom=medals[&quot;Gold&quot;], label=&quot;Silver&quot;) ax.bar(medals.index, medals[&quot;Bronze&quot;], bottom=medals[&quot;Gold&quot;] + medals[&quot;Silver&quot;], label=&quot;Bronze&quot;) ax.set_xticklabels(medals.index, rotation=90) ax.set_ylabel(&quot;Number of medals&quot;) ax.legend() plt.show() . Quantitative comparisons: histograms . # Introducing histograms fig, ax = plt.subplots() ax.hist(mens_rowing[&quot;Height&quot;]) ax.hist(mens_gymnastic[&quot;Height&quot;]) ax.set_xlabel(&quot;Height (cm)&quot;) ax.set_ylabel(&quot;# of observations&quot;) plt.show() # Labels are needed ax.hist(mens_rowing[&quot;Height&quot;], label=&quot;Rowing&quot;) ax.hist(mens_gymnastic[&quot;Height&quot;], label=&quot;Gymnastics&quot;) ax.set_xlabel(&quot;Height (cm)&quot;) ax.set_ylabel(&quot;# of observations&quot;) ax.legend() plt.show() # Customizing histograms: setting the number of bins ax.hist(mens_rowing[&quot;Height&quot;], label=&quot;Rowing&quot;, bins=5) ax.hist(mens_gymnastic[&quot;Height&quot;], label=&quot;Gymnastics&quot;, bins=5) ax.set_xlabel(&quot;Height (cm)&quot;) ax.set_ylabel(&quot;# of observations&quot;) ax.legend() plt.show() # Customizing histograms: setting bin boundaries ax.hist(mens_rowing[&quot;Height&quot;], label=&quot;Rowing&quot;, bins=[150, 160, 170, 180, 190, 200, 210]) ax.hist(mens_gymnastic[&quot;Height&quot;], label=&quot;Gymnastics&quot;, bins=[150, 160, 170, 180, 190, 200, 210]) ax.set_xlabel(&quot;Height (cm)&quot;) ax.set_ylabel(&quot;# of observations&quot;) ax.legend() plt.show() # Customizing histograms: transparency ax.hist(mens_rowing[&quot;Height&quot;], label=&quot;Rowing&quot;, bins=[150, 160, 170, 180, 190, 200, 210], histtype=&quot;step&quot;) ax.hist(mens_gymnastic[&quot;Height&quot;], label=&quot;Gymnastics&quot;, bins=[150, 160, 170, 180, 190, 200, 210], histtype=&quot;step&quot;) ax.set_xlabel(&quot;Height (cm)&quot;) ax.set_ylabel(&quot;# of observations&quot;) ax.legend() plt.show() . Statistical plotting . # Adding error bars to bar charts fig, ax = plt.subplots() ax.bar(&quot;Rowing&quot;,mens_rowing[&quot;Height&quot;].mean(), yerr=mens_rowing[&quot;Height&quot;].std()) ax.bar(&quot;Gymnastics&quot;,mens_gymnastics[&quot;Height&quot;].mean(), yerr=mens_gymnastics[&quot;Height&quot;].std()) ax.set_ylabel(&quot;Height (cm)&quot;) plt.show() # Adding error bars to plots fig, ax = plt.subplots() ax.errorbar(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-TAVG-NORMAL&quot;], yerr=seattle_weather[&quot;MLY-TAVG-STDDEV&quot;]) ax.errorbar(austin_weather[&quot;MONTH&quot;], austin_weather[&quot;MLY-TAVG-NORMAL&quot;], yerr=austin_weather[&quot;MLY-TAVG-STDDEV&quot;]) ax.set_ylabel(&quot;Temperature (Fahrenheit)&quot;) plt.show() # Adding boxplots fig, ax = plt.subplots() ax.boxplot([mens_rowing[&quot;Height&quot;], mens_gymnastics[&quot;Height&quot;]]) ax.set_xticklabels([&quot;Rowing&quot;, &quot;Gymnastics&quot;]) ax.set_ylabel(&quot;Height (cm)&quot;) plt.show() . Quantitative comparisons: scatter plots . # Introducing scatter plots fig, ax = plt.subplots() ax.scatter(climate_change[&quot;co2&quot;], climate_change[&quot;relative_temp&quot;]) ax.set_xlabel(&quot;CO2 (ppm)&quot;) ax.set_ylabel(&quot;Relative temperature (Celsius)&quot;) plt.show() # Customizing scatter plots eighties = climate_change[&quot;1980-01-01&quot;:&quot;1989-12-31&quot;] nineties = climate_change[&quot;1990-01-01&quot;:&quot;1999-12-31&quot;] fig, ax = plt.subplots() ax.scatter(eighties[&quot;co2&quot;], eighties[&quot;relative_temp&quot;], color=&quot;red&quot;, label=&quot;eighties&quot;) ax.scatter(nineties[&quot;co2&quot;], nineties[&quot;relative_temp&quot;], color=&quot;blue&quot;, label=&quot;nineties&quot;) ax.legend() ax.set_xlabel(&quot;CO2 (ppm)&quot;) ax.set_ylabel(&quot;Relative temperature (Celsius)&quot;) plt.show() # Encoding a third variable by color fig, ax = plt.subplots() ax.scatter(climate_change[&quot;co2&quot;], climate_change[&quot;relative_temp&quot;], c=climate_change.index) ax.set_xlabel(&quot;CO2 (ppm)&quot;) ax.set_ylabel(&quot;Relative temperature (Celsius)&quot;) plt.show() . Sharing visualizations with others . Preparing your figures to share with others . # Choosing a style plt.style.use(&quot;ggplot&quot;) fig, ax = plt.subplots() ax.plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-TAVG-NORMAL&quot; ax.plot(austin_weather[&quot;MONTH&quot;], austin_weather[&quot;MLY-TAVG-NORMAL&quot;]) ax.set_xlabel(&quot;Time (months)&quot;) ax.set_ylabel(&quot;Average temperature (Fahrenheit degrees)&quot;) plt.show() # Back to the default plt.style.use(&quot;default&quot;) . available styles . # The &quot;bmh&quot; style plt.style.use(&quot;bmh&quot;) fig, ax = plt.subplots() ax.plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-TAVG-NORMAL&quot; ax.plot(austin_weather[&quot;MONTH&quot;], austin_weather[&quot;MLY-TAVG-NORMAL&quot;]) ax.set_xlabel(&quot;Time (months)&quot;) ax.set_ylabel(&quot;Average temperature (Fahrenheit degrees)&quot;) plt.show() # Seaborn styles plt.style.use(&quot;seaborn-colorblind&quot;) fig, ax = plt.subplots() ax.plot(seattle_weather[&quot;MONTH&quot;], seattle_weather[&quot;MLY-TAVG-NORMAL&quot; ax.plot(austin_weather[&quot;MONTH&quot;], austin_weather[&quot;MLY-TAVG-NORMAL&quot;]) ax.set_xlabel(&quot;Time (months)&quot;) ax.set_ylabel(&quot;Average temperature (Fahrenheit degrees)&quot;) plt.show() . Saving your visualizations . # Saving the figure to file fig, ax = plt.subplots() ax.bar(medals.index, medals[&quot;Gold&quot;]) ax.set_xticklabels(medals.index, rotation=90) ax.set_ylabel(&quot;Number of medals&quot;) fig.savefig(&quot;gold_medals.png&quot;) # Different file formats fig.savefig(&quot;gold_medals.jpg&quot;) fig.savefig(&quot;gold_medals.jpg&quot;, quality=50) fig.savefig(&quot;gold_medals.svg&quot;) # Resolution fig.savefig(&quot;gold_medals.png&quot;, dpi=300) # Size fig.set_size_inches([5, 3]) # Another aspect ratio fig.set_size_inches([3, 5]) . Automating figures from data . # Getting unique values of a column sports = summer_2016_medals[&quot;Sport&quot;].unique() # Bar-chart of heights for all sports fig, ax = plt.subplots() for sport in sports: sport_df = summer_2016_medals[summer_2016_medals[&quot;Sport&quot;] == spor ax.bar(sport, sport_df[&quot;Height&quot;].mean(), yerr=sport_df[&quot;Height&quot;].std()) ax.set_ylabel(&quot;Height (cm)&quot;) ax.set_xticklabels(sports, rotation=90) plt.show() .",
            "url": "https://castorfou.github.io/guillaume_blog/visualization/matplotlib/cheatsheet/2021/01/13/matplotlib-cheatsheet.html",
            "relUrl": "/visualization/matplotlib/cheatsheet/2021/01/13/matplotlib-cheatsheet.html",
            "date": " • Jan 13, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Push large files to github: git-lfs",
            "content": "Where is the problem . I am currently following deep learning specialization from Andrew Ng on coursera. . In the course 4 about CNNs, there are some pre-trained yolo models that we use to do object detection. And these models come as large .h5 files. . Because I run all programming assignments locally and keep everything (lectures + codes) on my local repo, when I pushed to github I got this error: . (base) explore@explore-ThinkPad-P53:~/git/guillaume/deeplearning_specialization$ git push Enumerating objects: 247, done. Counting objects: 100% (247/247), done. Delta compression using up to 12 threads Compressing objects: 100% (239/239), done. Writing objects: 100% (242/242), 707.06 MiB | 4.74 MiB/s, done. Total 242 (delta 6), reused 0 (delta 0) remote: Resolving deltas: 100% (6/6), completed with 3 local objects. remote: warning: File notebooks/C4W3/nb_images/pred_video.mp4 is 85.44 MB; this is larger than GitHub&#39;s recommended maximum file size of 50.00 MB remote: warning: File notebooks/C4W3/nb_images/road_video.mp4 is 81.71 MB; this is larger than GitHub&#39;s recommended maximum file size of 50.00 MB remote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com. remote: error: Trace: 2d1944991c30279b831124b51e4aac57a17a860f2ef789b4e32801fb65282244 remote: error: See http://git.io/iEPt8g for more information. remote: error: File notebooks/C4W2/ResNet50.h5 is 270.32 MB; this exceeds GitHub&#39;s file size limit of 100.00 MB remote: error: File notebooks/C4W3/model_data/yolo.h5 is 194.69 MB; this exceeds GitHub&#39;s file size limit of 100.00 MB To github.com:castorfou/deeplearning_specialization.git ! [remote rejected] master -&gt; master (pre-receive hook declined) . Solution: git-lfs . As explained in https://github.com/git-lfs/git-lfs/wiki/Tutorial, there is (always) a way to do it properly. . First it is a matter of installing git-lfs: . sudo apt-get install git-lfs . Then to setup git lfs . git lfs install . And then to &quot;migrate&quot; big files to lfs: . git lfs migrate import --include=&quot;*.mp4&quot; . git lfs migrate import --include=&quot;*.h5&quot; . And now to git push . (base) explore@explore-ThinkPad-P53:~/git/guillaume/deeplearning_specialization$ git push Uploading LFS objects: 100% (25/25), 954 MB | 37 MB/s, done. Enumerating objects: 311, done. Counting objects: 100% (311/311), done. Delta compression using up to 12 threads Compressing objects: 100% (273/273), done. Writing objects: 100% (276/276), 60.49 MiB | 5.59 MiB/s, done. Total 276 (delta 18), reused 0 (delta 0) remote: Resolving deltas: 100% (18/18), completed with 16 local objects. To github.com:castorfou/deeplearning_specialization.git d0d2dc2..004fa09 master -&gt; master .",
            "url": "https://castorfou.github.io/guillaume_blog/git/2020/12/02/push-big-files-to-github.html",
            "relUrl": "/git/2020/12/02/push-big-files-to-github.html",
            "date": " • Dec 2, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Open Jupyter Notebook with http launch instead of redirect file",
            "content": "Where is the problem? . Default configuration when launching jupyter notebook is to create a redirect file. . Here is the explanation from config file ~/.jupyter/jupyter_notebook_config.py. . ## Disable launching browser by redirect file # # For versions of notebook &gt; 5.7.2, a security feature measure was added that # prevented the authentication token used to launch the browser from being # visible. This feature makes it difficult for other users on a multi-user # system from running code in your Jupyter session as you. # # However, some environments (like Windows Subsystem for Linux (WSL) and # Chromebooks), launching a browser using a redirect file can lead the browser # failing to load. This is because of the difference in file structures/paths # between the runtime and the browser. # # Disabling this setting to False will disable this behavior, allowing the # browser to launch by using a URL and visible token (as before). #c.NotebookApp.use_redirect_file = True . And when launching jupyter notebook from WSL . (xgboost) guillaume@LL11LPC0PQARQ:~/git/d059-vld-ic$ jupyter notebook [I 13:09:57.346 NotebookApp] The port 8888 is already in use, trying another port. [I 13:09:57.370 NotebookApp] [jupyter_nbextensions_configurator] enabled 0.4.1 [I 13:09:57.371 NotebookApp] Serving notebooks from local directory: /mnt/d/git/d059-vld-ic [I 13:09:57.372 NotebookApp] The Jupyter Notebook is running at: [I 13:09:57.373 NotebookApp] http://localhost:8889/?token=c3f77aea548937f5f563e0306d982d4332d26b0ed623e662 [I 13:09:57.373 NotebookApp] or http://127.0.0.1:8889/?token=c3f77aea548937f5f563e0306d982d4332d26b0ed623e662 [I 13:09:57.374 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). [C 13:10:00.384 NotebookApp] To access the notebook, open this file in a browser: file:///home/guillaume/.local/share/jupyter/runtime/nbserver-828-open.html Or copy and paste one of these URLs: http://localhost:8889/?token=c3f77aea548937f5f563e0306d982d4332d26b0ed623e662 or http://127.0.0.1:8889/?token=c3f77aea548937f5f563e0306d982d4332d26b0ed623e662 . . Solution . As given in https://stackoverflow.com/questions/57679894/how-to-change-jupyter-launch-from-file-to-url, . update jupyter config file to change #c.NotebookApp.use_redirect_file = True to c.NotebookApp.use_redirect_file = False . .",
            "url": "https://castorfou.github.io/guillaume_blog/jupyter/wsl/2020/10/21/open-jupyter-from-http-link.html",
            "relUrl": "/jupyter/wsl/2020/10/21/open-jupyter-from-http-link.html",
            "date": " • Oct 21, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "GAN Specialization course 2 week 3 - Apply and certificate",
            "content": "Notes . tbd later . Certificate . . About next steps . For the moment I am hesitating to follow last course for gans. This is a deep dive into gan, with lots of theory (papers) associated to it. My 1st goal was to know better about it and this is met. My 2nd one was to figure out how to use this kind of generative networks for other area such as tabular data + prescription issues. I am not sure this is applicable (or not yet). . Maybe it is better for now to resume my learning sessions with Jeremy Howard on fastai v2. .",
            "url": "https://castorfou.github.io/guillaume_blog/gan/pytorch/2020/10/15/gan-course2-week3-certificate.html",
            "relUrl": "/gan/pytorch/2020/10/15/gan-course2-week3-certificate.html",
            "date": " • Oct 15, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Variables traces using show_guts decorator",
            "content": "show_guts decorator . Adaptaton from https://stackoverflow.com/questions/24165374/printing-a-functions-local-variable-names-and-values . Update to python 3. . import sys import threading def show_guts(f): sentinel = object() gutsdata = threading.local() gutsdata.captured_locals = None gutsdata.tracing = False def trace_locals(frame, event, arg): if event.startswith(&#39;c_&#39;): # C code traces, no new hook return if event == &#39;call&#39;: # start tracing only the first call if gutsdata.tracing: return None gutsdata.tracing = True return trace_locals if event == &#39;line&#39;: # continue tracing return trace_locals # event is either exception or return, capture locals, end tracing gutsdata.captured_locals = frame.f_locals.copy() return None def wrapper(*args, **kw): # preserve existing tracer, start our trace old_trace = sys.gettrace() sys.settrace(trace_locals) retval = sentinel try: retval = f(*args, **kw) finally: # reinstate existing tracer, report, clean up sys.settrace(old_trace) for key, val in gutsdata.captured_locals.items(): print(&#39;{}: {!r}&#39;.format(key, val)) if retval is not sentinel: print(&#39;Returned: {!r}&#39;.format(retval)) gutsdata.captured_locals = None gutsdata.tracing = False return retval return wrapper . use example . import torch from torch import nn from tqdm.auto import tqdm from torchvision import transforms from torchvision.utils import make_grid from torchvision.datasets import CelebA from torch.utils.data import DataLoader import matplotlib.pyplot as plt . @show_guts def get_score(current_classifications, original_classifications, target_indices, other_indices, penalty_weight): &#39;&#39;&#39; Function to return the score of the current classifications, penalizing changes to other classes with an L2 norm. Parameters: current_classifications: the classifications associated with the current noise original_classifications: the classifications associated with the original noise target_indices: the index of the target class other_indices: the indices of the other classes penalty_weight: the amount that the penalty should be weighted in the overall score &#39;&#39;&#39; # Steps: 1) Calculate the change between the original and current classifications (as a tensor) # by indexing into the other_indices you&#39;re trying to preserve, like in x[:, features]. # 2) Calculate the norm (magnitude) of changes per example. # 3) Multiply the mean of the example norms by the penalty weight. # This will be your other_class_penalty. # Make sure to negate the value since it&#39;s a penalty! # 4) Take the mean of the current classifications for the target feature over all the examples. # This mean will be your target_score. #### START CODE HERE #### change_original_classification = (current_classifications[:,other_indices] - original_classifications[:,other_indices]) # Calculate the norm (magnitude) of changes per example and multiply by penalty weight other_class_penalty = - torch.mean(torch.norm(change_original_classification, dim=1) * penalty_weight) # Take the mean of the current classifications for the target feature target_score = torch.mean(current_classifications) #### END CODE HERE #### return target_score + other_class_penalty . rows = 10 current_class = torch.tensor([[1] * rows, [2] * rows, [3] * rows, [4] * rows]).T.float() original_class = torch.tensor([[1] * rows, [2] * rows, [3] * rows, [4] * rows]).T.float() # Must be 3 assert get_score(current_class, original_class, [1, 3] , [0, 2], 0.2).item() == 3 . current_classifications: tensor([[1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.]]) original_classifications: tensor([[1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.], [1., 2., 3., 4.]]) target_indices: [1, 3] other_indices: [0, 2] penalty_weight: 0.2 change_original_classification: tensor([[0., 0.], [0., 0.], [0., 0.], [0., 0.], [0., 0.], [0., 0.], [0., 0.], [0., 0.], [0., 0.], [0., 0.]]) other_class_penalty: tensor(-0.) target_score: tensor(2.5000) Returned: tensor(2.5000) . AssertionError Traceback (most recent call last) &lt;ipython-input-5-c7e77f2e4ae1&gt; in &lt;module&gt; 4 5 # Must be 3 -&gt; 6 assert get_score(current_class, original_class, [1, 3] , [0, 2], 0.2).item() == 3 AssertionError: .",
            "url": "https://castorfou.github.io/guillaume_blog/python/2020/10/07/decorator-trace-variables.html",
            "relUrl": "/python/2020/10/07/decorator-trace-variables.html",
            "date": " • Oct 7, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Conda activate from bash scripts",
            "content": "Can&#39;t execute conda activate from bash script . Good description of the problem in conda github. . Calling conda activate from a bash script will raise some errors: . CommandNotFoundError: Your shell has not been properly configured to use &#39;conda activate&#39;. To initialize your shell, run $ conda init &lt;SHELL_NAME&gt; Currently supported shells are: - bash - fish - tcsh - xonsh - zsh - powershell See &#39;conda init --help&#39; for more information and options. . source ~/your_conda/etc/profile.d/conda.sh . It is just a matter of sourcing the conda bash settings before calling conda activate. . In m case I have installed conda in ~/miniconda3, I just have to call source ~/miniconda3/etc/profile.d/conda.sh . Example to run my blogging environment . #!/bin/bash source ~/miniconda3/etc/profile.d/conda.sh cd ~/git/guillaume/guillaume_blog/_notebooks conda activate fastai jupyter notebook .",
            "url": "https://castorfou.github.io/guillaume_blog/conda/bash/2020/10/07/conda-activate-from-bash-script.html",
            "relUrl": "/conda/bash/2020/10/07/conda-activate-from-bash-script.html",
            "date": " • Oct 7, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "GAN Specialization course 1 week 2 - Deep Convolutional GAN",
            "content": "My notes . .",
            "url": "https://castorfou.github.io/guillaume_blog/gan/pytorch/2020/10/06/gan-specialization-course1-week2-Deep_convolutional_GAN.html",
            "relUrl": "/gan/pytorch/2020/10/06/gan-specialization-course1-week2-Deep_convolutional_GAN.html",
            "date": " • Oct 6, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Upgrade ubuntu LTS 18.04 to 20.04",
            "content": "Standard upgrade process . As a LTS user, I want to keep using these long term support version. . !cat /etc/issue . Ubuntu 18.04.5 LTS n l . A good way to do it is by using do-release-upgrade tool. Full explanation at: 18.04 to 20.04. . sudo do-release-upgrade Checking for a new Ubuntu release There is no development version of an LTS available. To upgrade to the latest non-LTS develoment release set Prompt=normal in /etc/update-manager/release-upgrades. . Waiting for blockers to be fixed . There is a last blocker before releasing Ubuntu 20.04.1 LTS. . . Expected around 1st of October 2020. . (2020-09-28) blockers are fixed, upgrade in progress . Unfortunately the upgrade process went uneventful. Nothing broke, nothing to learn ;) . It took minutes to do the upgrade. . . Ubuntu releases-code names .",
            "url": "https://castorfou.github.io/guillaume_blog/ubuntu/2020/09/28/upgrade-ubuntu-18.04-to-20.04.html",
            "relUrl": "/ubuntu/2020/09/28/upgrade-ubuntu-18.04-to-20.04.html",
            "date": " • Sep 28, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Fastai book Deep Learning for Coders with fastai and Pytorch",
            "content": "Paper version of fastai book . Of course the 1st tep is to purchase this great book: . . I have liked what Jeremy Howard said about why this is important to purchase it (in video 1). Fastai is offering full access to the book as notebooks. So that we can run all codes from them. . Get notebook version of fastai book . ~/git/guillaume$ git clone https://github.com/fastai/fastbook.git . . I have now a perfect combo between paper book and notebooks. . Video courses based on fastai book . Rachel Thomas and Jeremy Howard have done some great videos about learning fastai (and pytorch). . They tend to do it every year. But this year is quite special due to fastai book. . Here are all the 1st 7 videos: https://course.fast.ai/videos/?lesson=1 . Fastai forums . This is the natural source of information and interactions with other students. . There is a category Part 1 (2020) which seems perfect: https://forums.fast.ai/c/part1-v4/46 . Personal git organization . ~/git/guillaume$ ll fastai/ &lt;-- from https://github.com/fastai/fastai fastai_experiments/ &lt;-- I will keep all experiments I will do here fastbook/ &lt;-- from https://github.com/fastai/fastbook.git guillaume_blog/ &lt;-- from git@github.com:castorfou/guillaume_blog.git . fastai_experiments likely to have 1 notebook per chapter or video. . update jupyter to include extensions (toc, ...) . conda install -c conda-forge jupyter_contrib_nbextensions . I like table of content, others are quite usefull as well (scratchpad, ExecuteTime...). . Install some libraries to run book examples . conda install -c fastai fastbook . It will install graphviz, nbdev, and other libraries. . And most of them can be loaded by calling from utils import * . Launch jupyter notebook and start expermenting . cd ~/git/guillaume conda activate fastai jupyter notebook . And launch several tabs at: blog entries, fastai experiments, fastai courses and fastai videos. . And I keep track of progress with git. .",
            "url": "https://castorfou.github.io/guillaume_blog/fastai/jupyter/fastbook/2020/09/24/fastai-book.html",
            "relUrl": "/fastai/jupyter/fastbook/2020/09/24/fastai-book.html",
            "date": " • Sep 24, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Setup ubuntu box with fastai",
            "content": "Install miniconda . Get miniconda Linux installer. . Check sha256sum: sha256sum Miniconda3-latest-Linux-x86_64.sh . Run install: ./Miniconda3-latest-Linux-x86_64.sh -p $HOME/miniconda3 . Install fastai . conda create -n fastai python=3.8 conda activate fastai conda install -c fastai -c pytorch fastai . Install jupyter within fastai environment . conda activate fastai conda install jupyter . Test fastai installation (valid for v1) . With fastai v1, there was an easy way to check installation: . conda activate fastai python -m fastai.utils.show_install . get git repo to learn from fastai . From git folder, . git clone https://github.com/fastai/fastai . Test fastai v2 installation . From python environment: . from fastai.vision.all import * . From jupyter notebook . from fastai.vision.all import * . Install nvidia drivers for ubuntu . I tried by downloading a driver from nvidia website. But I was unable to install it (nvidia-drm-drv.c:662:44: error: &#39;DRIVER_PRIME&#39; undeclared here (not in a function); did you mean &#39;DRIVER_PCI_DMA&#39;?) . sudo ubuntu-drivers autoinstall . then rebooting fixed the issue. . Run courses from fastai github repo . just run fastai/dev_nbs/course/lesson1-pets.ipynb . And everything is just fined ;) . install nbdev . This is for rendering reasons: To get a prettier result with hyperlinks to source code and documentation, install nbdev: pip install nbdev . !pip install nbdev . Collecting nbdev Downloading nbdev-1.0.18-py3-none-any.whl (57 kB) |████████████████████████████████| 57 kB 1.5 MB/s eta 0:00:01 Requirement already satisfied: fastcore&gt;=1.0.5 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (1.0.13) Requirement already satisfied: packaging in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (20.4) Requirement already satisfied: jupyter-client in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (6.1.6) Requirement already satisfied: nbconvert&lt;6 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.6.1) Requirement already satisfied: nbformat&gt;=4.4.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.0.7) Collecting fastscript&gt;=1.0.0 Downloading fastscript-1.0.0-py3-none-any.whl (11 kB) Requirement already satisfied: pyyaml in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.3.1) Requirement already satisfied: pip in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (20.2.2) Requirement already satisfied: ipykernel in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.3.4) Requirement already satisfied: pyparsing&gt;=2.0.2 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from packaging-&gt;nbdev) (2.4.7) Requirement already satisfied: six in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from packaging-&gt;nbdev) (1.15.0) Requirement already satisfied: pyzmq&gt;=13 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (19.0.2) Requirement already satisfied: tornado&gt;=4.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (6.0.4) Requirement already satisfied: python-dateutil&gt;=2.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (2.8.1) Requirement already satisfied: traitlets in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (4.3.3) Requirement already satisfied: jupyter-core&gt;=4.6.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (4.6.3) Requirement already satisfied: pandocfilters&gt;=1.4.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (1.4.2) Requirement already satisfied: pygments in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (2.7.1) Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.8.4) Requirement already satisfied: defusedxml in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.6.0) Requirement already satisfied: bleach in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (3.2.1) Requirement already satisfied: jinja2&gt;=2.4 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (2.11.2) Requirement already satisfied: testpath in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.4.4) Requirement already satisfied: entrypoints&gt;=0.2.2 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.3) Requirement already satisfied: jsonschema!=2.5.0,&gt;=2.4 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbformat&gt;=4.4.0-&gt;nbdev) (3.0.2) Requirement already satisfied: ipython-genutils in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbformat&gt;=4.4.0-&gt;nbdev) (0.2.0) Requirement already satisfied: ipython&gt;=5.0.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipykernel-&gt;nbdev) (7.18.1) Requirement already satisfied: decorator in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from traitlets-&gt;jupyter-client-&gt;nbdev) (4.4.2) Requirement already satisfied: webencodings in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from bleach-&gt;nbconvert&lt;6-&gt;nbdev) (0.5.1) Requirement already satisfied: MarkupSafe&gt;=0.23 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jinja2&gt;=2.4-&gt;nbconvert&lt;6-&gt;nbdev) (1.1.1) Requirement already satisfied: pyrsistent&gt;=0.14.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (0.17.3) Requirement already satisfied: attrs&gt;=17.4.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (20.2.0) Requirement already satisfied: setuptools in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (49.6.0.post20200814) Requirement already satisfied: backcall in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.2.0) Requirement already satisfied: pexpect&gt;4.3; sys_platform != &#34;win32&#34; in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (4.8.0) Requirement already satisfied: pickleshare in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.7.5) Requirement already satisfied: jedi&gt;=0.10 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.17.2) Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (3.0.7) Requirement already satisfied: ptyprocess&gt;=0.5 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from pexpect&gt;4.3; sys_platform != &#34;win32&#34;-&gt;ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.6.0) Requirement already satisfied: parso&lt;0.8.0,&gt;=0.7.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jedi&gt;=0.10-&gt;ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.7.0) Requirement already satisfied: wcwidth in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.2.5) Installing collected packages: fastscript, nbdev Successfully installed fastscript-1.0.0 nbdev-1.0.18 .",
            "url": "https://castorfou.github.io/guillaume_blog/fastai/cuda/linux/2020/09/23/Setup-ubuntu-box-with-fastai.html",
            "relUrl": "/fastai/cuda/linux/2020/09/23/Setup-ubuntu-box-with-fastai.html",
            "date": " • Sep 23, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Git push to github without password",
            "content": "By default everytime I push to github, I have a prompt asking for password. . (xgboost) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog$ git push Username for &#39;https://github.com&#39;: castorfou Password for &#39;https://castorfou@github.com&#39;: Everything up-to-date . Would be great if I could leverage ssh keys to authenticate. . Update remote from https to ssh . From https://stackoverflow.com/questions/14762034/push-to-github-without-a-password-using-ssh-key, . For example, a GitHub project like Git will have an HTTPS URL: https://github.com/&lt;Username&gt;/&lt;Project&gt;.git And the SSH one: git@github.com:&lt;Username&gt;/&lt;Project&gt;.git You can do: git remote set-url origin git@github.com:&lt;Username&gt;/&lt;Project&gt;.git to change the URL. . In my case I have . (xgboost) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog$ git remote -v origin https://github.com/castorfou/guillaume_blog.git (fetch) origin https://github.com/castorfou/guillaume_blog.git (push) . I have just to modify: . git remote set-url origin git@github.com:castorfou/guillaume_blog.git . Results . It looks like working: . (xgboost) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog$ git push Counting objects: 4, done. Delta compression using up to 8 threads. Compressing objects: 100% (4/4), done. Writing objects: 100% (4/4), 1.59 KiB | 812.00 KiB/s, done. Total 4 (delta 2), reused 0 (delta 0) remote: Resolving deltas: 100% (2/2), completed with 2 local objects. To github.com:castorfou/guillaume_blog.git 4013108..ae78b99 master -&gt; master . Drawback: doesn&#39;t work behing a firewall . . To find a solution to use a proxy . Here are 2 ways to be tested: https://stackoverflow.com/questions/1728934/accessing-a-git-repository-via-ssh-behind-a-firewall https://stackoverflow.com/questions/18604719/how-to-configure-git-to-clone-repo-from-github-behind-a-proxy-server?noredirect=1&amp;lq=1 .",
            "url": "https://castorfou.github.io/guillaume_blog/git/2020/09/11/git-commit-without-password.html",
            "relUrl": "/git/2020/09/11/git-commit-without-password.html",
            "date": " • Sep 11, 2020"
        }
        
    
  
    
        ,"post15": {
            "title": "Blog from jupyter notebook",
            "content": "That will be great if I can simply write blog entries using Jupyter Notebook. . I usually paste inner images into jupyter cells. But this feature is not available yet into fastpages. So for the moment I won&#39;t include images into these posts. . That way I could simply use markdown and insert images . And directly see rendered impact before commiting and pushing to my blog. . get local repo from github . As I am behind a proxy most of my time when working from office, the easiest way for me is to work from WSL. . WSL . I won&#39;t detail how to install WSL on Windows. . I use ubuntu images (18.04) on my PC. . set unset proxy in WSL . I have just added some bash commands at the end of my .bashrc file. . # Set Proxy function setproxy() { export {http,https,ftp}_proxy=&quot;http://&lt;my proxy ip address&gt;:80&quot; export {HTTP,HTTPS,FTP}_PROXY=&quot;http://&lt;my proxy ip address&gt;:80&quot; } # Unset Proxy function unsetproxy() { unset {http,https,ftp}_proxy unset {HTTP,HTTPS,FTP}_PROXY } . git clone castorfou.github.io . I keep most of my local repos under ~/git/ . cd ~/git setproxy git clone https://github.com/castorfou/castorfou.github.io.git . create a blog entry with Jupyter Notebook . commit and push to github . (base) guillaume@LL11LPC0PQARQ:~$ cd git (base) guillaume@LL11LPC0PQARQ:~/git$ cd castorfou.github.io/ (base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git add . (base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git commit -m &#39;new blog entry: blog from jupyter&#39; [master 6b7460a] new blog entry: blog from jupyter 4 files changed, 516 insertions(+) create mode 100644 _posts/.ipynb_checkpoints/2020-09-10-blog-from-jupyter-checkpoint.ipynb create mode 100644 _posts/2020-09-10-blog-from-jupyter.ipynb create mode 100644 _posts/2020-09-10-blog-from-jupyter.py create mode 100644 _posts/Untitled.txt (base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git push fatal: unable to access &#39;https://github.com/castorfou/castorfou.github.io.git/&#39;: gnutls_handshake() failed: The TLS connection was non-properly terminated. . error: gnutls_handshake() failed: The TLS connection was non-properly terminated. . Just googling this error gives some insight: https://github.community/t/unable-to-push-to-repo-gnutls-handshake-failed/885 . It is likely some local firewell issue. . . To be fixed later . switch to mobile wifi without need of proxy . (base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ unsetproxy (base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git push Username for &#39;https://github.com&#39;: castorfou Password for &#39;https://castorfou@github.com&#39;: Counting objects: 7, done. Delta compression using up to 8 threads. Compressing objects: 100% (6/6), done. Writing objects: 100% (7/7), 141.26 KiB | 10.09 MiB/s, done. Total 7 (delta 1), reused 0 (delta 0) remote: Resolving deltas: 100% (1/1), completed with 1 local object. remote: remote: GitHub found 3 vulnerabilities on castorfou/castorfou.github.io&#39;s default branch (2 high, 1 moderate). To find out more, visit: remote: https://github.com/castorfou/castorfou.github.io/network/alerts remote: To https://github.com/castorfou/castorfou.github.io.git 6adeb02..6b7460a master -&gt; master . check entries into blog . double entries . Double entries: one for the notebook (.ipynb) and one for the auto python export (.py). I will have to update my jupyter settings to avoid this python file creation. In the meantime I can just delete the python file, and commit. . . Change settings of jupyter + .gitignore to avoid these double entries . cannot open notebook into browser . Clicking just ask me to download the notebook, it doesn&#39;t display it into the browser. . checking .gitignore . Just by looking into .gitignore, there is an interesting entry: . *.swp ~* *~ _site .sass-cache .jekyll-cache .jekyll-metadata vendor _notebooks/.ipynb_checkpoints . Wait what is in this last line. . Let&#39;s create _notebooks directory and move my notebook in that directory. . notebooks from _notebooks not rendered . No entries, I guess there is some additional settings to do... . . Why notebooks are not rendered by Jekyl . test entry from md using local repo . There is no problem with that. . Creating a local md file in _poststhen pushing to github is creating the right entry blog. . following fastpages troubleshooting guide . upgrade fastpages . Try the automated upgrade as described in https://github.com/fastai/fastpages/blob/master/_fastpages_docs/UPGRADE.md . Unfortunately I don&#39;t see . I have to follow the manual upgrade. . manual fastpages upgrade . I am surprised because the 1st step from manual upgrade is to copy the fastpages repo. It is what I did 2 days ago. I doubt having an outdated version of fastpages. . fastai forum: fastpages category . I will browse through nbdev &amp; faspages category in fastai forums. I should see people with the same issue. . I have created an entry, into fastai forums: Fastpages - cannot see build process of GitHub Actions . And quite immediately Hamel Hussain answered guiding to the write direction: . I misread the Settings instruction: my github repo should explicitely NOT include my github username and I did exactly the opposite. . . I have to create a new repo: guillaume_blog . nothing visible from Actions tab . And another surprising subject: at github in Actions tab. I have a kind of default page. I expect something like an execution journal of Actions. . Page build failure . Received a notification by email: . The page build failed for the master branch with the following error: . Page build failed. For more information, see https://docs.github.com/github/working-with-github-pages/troubleshooting-jekyll-build-errors-for-github-pages-sites#troubleshooting-build-errors. . For information on troubleshooting Jekyll see: . https://docs.github.com/articles/troubleshooting-jekyll-builds . If you have any questions you can submit a request on the Contact GitHub page at https://support.github.com/contact?repo_id=293820308&amp;page_build_id=202240535 . Move to another repo . repo creation . It was just a matter of creating a new repo: . actions monitoring . Monitoring is effective . merge pull request . actions around ssh keys . Following the steps: . Create keys using ssh utility | Enter Secret Key | Enter Deploy Key | . merge PR . There are conflicts to be fixed before that. . And it works: https://castorfou.github.io/guillaume_blog/ . Get local repo . cd ~/git unsetproxy git clone https://github.com/castorfou/guillaume_blog.git .",
            "url": "https://castorfou.github.io/guillaume_blog/fastpages/jupyter/notebooks/2020/09/10/blog-from-jupyter-sans-images.html",
            "relUrl": "/fastpages/jupyter/notebooks/2020/09/10/blog-from-jupyter-sans-images.html",
            "date": " • Sep 10, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "Blogging from github",
            "content": "Blogging from github . fastai and fastpages . I am a big fan of fastai’s spirit and even more of their leaders: . Jeremy Howards | Rachel Thomas | Sylvain Gugger who is know at huggingface. | . They are commited to beautiful ideas, and are inspiring people. I like their courses. I like their softwares. For sure I will discuss about fastai. They have created fastpages. It turns github into a blogging platform. I don’t have the full detail but it is explained in fastpages github repo It is based on github actions, and by just creating a repo from a fastpages template https://github.com/fastai/fast_template/generate and giving a couple of settings, you are ready to go. . And here I have to thank Hamel Husain. He is from github company and I think he is behing github actions and helped fastai to release fastpages. I don’t know Hamel but he looks like a humble, terribly skilled guy, with tons of energy. Thanks Hamel. . my blog . My main audience is the future me. (maybe not entirely true otherwise I would have written in French) In 1 year, I want to turn back to this blog and I would like to see all the learning peaces I went through. I want this platform to be as easy as possible. . fastpages . For the moment it cannot be easier. I have setup the about page. And each blog entry is just a new markdown page into _posts. github _posts: . . By commiting this page, there are internal actions being run automatically (through github actions magic) and after a couple of minutes the new blog pages are generated (using Jekyl and ruby if I am not wrong). For the moment I use github web interface. But I guess it is easier to have a local repo of my blog, create new entries and when satisfied git push to github. (to be tested later) . github accounts . For a reason I used my personal github account (guillaume.ramelet@gmail.com) and not my professional one (guillaume.ramelet@michelin.com). I will see later if I have to move to another account. I had some troubles to setup actions into github. For a reason I thought it was available only for organization account. So I have turned my michelin github account to an organization, and I cannot login anymore. To be fixed later. . markdown . Ok I am not a huge fan of markdown. I use it as a basic text system specially within notebooks. But it is not as easy to insert images. Currently I screenshot what I want to share, insert into images folder of my repo and reference this image from my blog post using markdown language. I definitely have to improve my practice of markdown, and there are multiple cheatsheets to be used. . jupyter . There are options within fastpages to blog from jupyter notebooks. I have to do it. My intent will be to use this place to share my knowledge. Today most of my knowledge comes from experiences I make within jupyter. If I could directly blog from that it will be great. . comments . OK as the sole reader this is maybe a minor concern but there is no commenting system associated with fastpages. I cannot get any feedback from these entries. Would love to get advices, create discussions within that blog. Not for today. .",
            "url": "https://castorfou.github.io/guillaume_blog/blog/fastpages/git/2020/09/09/blogging-from-github.html",
            "relUrl": "/blog/fastpages/git/2020/09/09/blogging-from-github.html",
            "date": " • Sep 9, 2020"
        }
        
    
  
    
        ,"post17": {
            "title": "Becoming a datascientist",
            "content": "March 2019 . This journey has started about 1 year ago. . No wait, that was dormant for a long time before that. I guess I have to go back to my studying time: at that time my days were full of maths and computers. And my days were flying as crazy. It happens to me (to you?) when you’re just in a middle of something you like very much. 10 hours looks like 1. And the opposite is true as well. . 2000 - 2004: software development . Most of my days and weekends at that time were dedicated to code in Java and bash. Java mainly for server-side developpement in J2EE at Unilog Management. Bash from time to time to automate some tasks on my personal PC. At that time it was mainly about learning what is an operating system. I had started with LFS (Linux From Scratch). And in 2002 with Gentoo which was a much more powerful way to mimic LFS. . 2004 - 2009: project management . Strange period. I don’t remember exactly why but I had a shift in my professional orientation. I moved away from software development and turned into a project manager. In 2005 I entered into Michelin company. And sofwtare technical matters at that time were considered as unimportant (and embarrassing subjects) Fortunately in 2009 I have been started my agile journey. A lot to learn, and it was less about software than human relations and empathy. It was like a start from scratch. . 2009 - 2015: agile journey . Quite a new world for me. I had some basic knowledge by following Jono Bacon. At that time he was a community manager|release leader at Ubuntu. And was reporting progress using burndown charts. In 2009 I launched a project to create an employee portal (closed to what netvibes and igoogle were at that time). Using standard java portal technologies and more importantly using agile approach. A lot to learn about Agile, Scrum, and endless discussions about how to introduce Agile into a non-Agile organization. In 2010 I started another more ambitious project, with many colleagues (~30 persons) and a vague vision. It was about to create a product lifecycle management solution for semi-finished products. . 2015 - 2017: lean journey . In 2015, I met lean approaches for office. I was immediately convinced there was powerful and deep roots within lean. And it could bring a lot to people and organizations. I turned into a lean coach, to work with teams identifying what they could improve, how they could work better, with more pleasure. . 2017 - 2019: Welcome to USA! . Nice opportunity at that time to move from Clermont-Ferrand (France) to Greenville, South Carolina (USA). I have loved every part of it. Except maybe that 2 years were too short to make a full tour of this amazing country. It is crazy to think how different we are when we look like the same. . 2019 - : back to France and turning as a datascientist . Sept 2019 - back to France and for 4 months to prepare for a complete new position: datascientist for Manufacturing within Michelin. I spent many days to learn from various sources specially datacamp and Andrew Ng. That was just the beginning. My intent was to move away from project management, team leadership and focus about what I can do by myself. I wanted to return to math domains without giving up an IT landscape. My colleague Francois Deheeger told me about data science and Artificial Intelligence. That looked as interesting as terrifying. I was in. I was not afraid to learn a new language, and to restart my career from scratch. .",
            "url": "https://castorfou.github.io/guillaume_blog/me/2020/09/08/becoming-datascientist.html",
            "relUrl": "/me/2020/09/08/becoming-datascientist.html",
            "date": " • Sep 8, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About . This blog . This is more a journal where I am adding entries about my (baby steps) learnings. It is likely to be centered around python, git, data-science, … I have been strongly inspired by Rachel Thomas explaining why I should blog. Specially when starting such a journey to turn a datascientist. . My intent would be to regularly add entries to this blog. Ideally at least once a week. Maybe only short ones, the point being to stick on this frequent activity. If it takes days to write posts I am pretty sure I won’t do it. Those entries are personnal thoughts and not those of my employer Michelin. . Me . I am 44 (in 2020). Father of 3. Working for a French tire company. I am French and for sure English is not my mother tongue. .",
          "url": "https://castorfou.github.io/guillaume_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://castorfou.github.io/guillaume_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}